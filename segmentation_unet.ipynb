{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation with pytorch using U-net\n",
    "\n",
    "U-net was first developed in 2015 by Ronneberger et al., as a segmentation network for biomedical image analysis.\n",
    "It has been extremely successful, with 9,000+ citations, and many new methods that have used the U-net architecture since.\n",
    "\n",
    "\n",
    "The architecture of U-net is based on the idea of using skip connections (i.e. concatenating) at different levels of the network to retain high, and low level features.\n",
    "\n",
    "Here is the architecture of a U-net:\n",
    "\n",
    "---\n",
    "\n",
    "![U-net](unet.png)\n",
    "Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-photon microscopy dataset of cortical axons\n",
    "\n",
    "In this tutorial we use a dataset of cortical neurons with their corresponding segmentation binary labels.\n",
    "\n",
    "These images were collected using in-vivo two-photon microscopy from the mouse somatosensory cortex. To generate the 2D images, a max projection was used over the 3D stack. The labels are binary segmentation maps of the axons.\n",
    "\n",
    "Here we will use 100 [64x64] crops during training and validation. \n",
    "\n",
    "These are some example images [256x256] from the original dataset:\n",
    "![axon_dataset](axon_dataset.png)\n",
    "\n",
    "Bass, Cher, et al. \"Image synthesis with a convolutional capsule generative adversarial network.\" Medical Imaging with Deep Learning (2019).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modules\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from load_memmap import *\n",
    "from AxonDataset import *\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "timestr = time.strftime(\"%d%m%Y-%H%M\")\n",
    "__location__ = os.path.realpath(\n",
    "    os.path.join(os.getcwd(), os.path.dirname('__file__')))\n",
    "\n",
    "path = os.path.join(__location__,'results')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "# Define your batch_size\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataloader\n",
    "\n",
    "In this example, a custom dataloader was created, and we import it from `AxonDataset.py`\n",
    "\n",
    "we create a dataset, and split into a train and validation set with 80%, 20% split\n",
    "\n",
    "### Task 1\n",
    "\n",
    "create a list of random indices for the train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we create a dataloader for our example dataset- two photon microscopy with axons\n",
    "axon_dataset = AxonDataset(data_name='org64', type='train')\n",
    "\n",
    "# -----------------------------------------------------task 1----------------------------------------------------------------\n",
    "# Task 1: create a random list of incides for training and testing with a 80%,20% split\n",
    "\n",
    "# We need to further split our training dataset into training and validation sets.\n",
    "# Define the indices\n",
    "indices = list(range(len(axon_dataset)))  # start with all the indices in training set\n",
    "split = int(len(indices)*0.2)  # define the split size\n",
    "\n",
    "# Get indices for train and validation datasets, and split the data\n",
    "validation_idx = np.random.choice(indices, size=split, replace=False)\n",
    "train_idx = list(set(indices) - set(validation_idx))\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# feed indices into the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "validation_sampler = SubsetRandomSampler(validation_idx)\n",
    "\n",
    "# Create a dataloader instance \n",
    "train_loader = torch.utils.data.DataLoader(axon_dataset, batch_size = batch_size,\n",
    "                                           sampler=train_sampler) \n",
    "val_loader = torch.utils.data.DataLoader(axon_dataset, batch_size = batch_size,\n",
    "                                        sampler=validation_sampler) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a U-net \n",
    "\n",
    "We next build our u-net network.\n",
    "\n",
    "First we define a layer `double_conv` that performs 2 sets of convolution followed by ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define U-net\n",
    "def double_conv(in_channels, out_channels, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=padding),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network\n",
    "We then define our U-net network.\n",
    "\n",
    "We initialise all the different layers in the network in `__init__`:\n",
    "1. `self.dconv_down1` is a double convolutional layer\n",
    "2. `self.maxpool` is a max pooling layer that is used to reduce the size of the input, and decrease the reptive field\n",
    "3. `self.upsample` is an upsampling layer that is used to increase the size of the input\n",
    "4. `dropout` is a dropout layer that is applied to regulise the training\n",
    "5. `dconv_up4` is also a double convolutional layer- note that it takes in additional channels from previous layers (i.e. the skip connections).\n",
    "\n",
    "skip connection are easily implemented by concatenating the result of a previous convolution with the current input, \n",
    "\n",
    "using e.g. `torch.cat([x, conv4], dim=1)`\n",
    "\n",
    "### Task 2 - implement skip connections\n",
    "Implement skip connections for conv3, conv2, and conv1.\n",
    "\n",
    "See conv4 example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dconv_down1 = double_conv(1, 32)\n",
    "        self.dconv_down2 = double_conv(32, 64)\n",
    "        self.dconv_down3 = double_conv(64, 128)\n",
    "        self.dconv_down4 = double_conv(128, 256)\n",
    "\n",
    "        self.dconv_down5 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.dconv_up4 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up3 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up2 = double_conv(128 + 64, 64)\n",
    "        self.dconv_up1 = double_conv(64 + 32, 32)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(32, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv1 = self.dropout(conv1)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        conv2 = self.dropout(conv2)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        conv3 = self.dconv_down3(x)\n",
    "        conv3 = self.dropout(conv3)\n",
    "        x = self.maxpool(conv3)\n",
    "\n",
    "        conv4 = self.dconv_down4(x)\n",
    "        conv4 = self.dropout(conv4)\n",
    "        x = self.maxpool(conv4)\n",
    "\n",
    "        conv5 = self.dconv_down5(x)\n",
    "        conv5 = self.dropout(conv5)\n",
    "\n",
    "        x = self.upsample(conv5)\n",
    "        \n",
    "        # example of skip connection with conv4\n",
    "        x = torch.cat([x, conv4], dim=1)\n",
    "        \n",
    "        x = self.dconv_up4(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # --------------------------------------------------- task 2 ----------------------------------------------------------\n",
    "        # Task 2: implement skip connection with conv3\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # --------------------------------------------------- task 2 ----------------------------------------------------------\n",
    "        # Task 2: implement skip connection with conv2\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # --------------------------------------------------- task 2 ----------------------------------------------------------\n",
    "        # Task 2: implement skip connection with conv1\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        out = F.sigmoid(self.conv_last(x))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we initialise the network with a previously trained network by loading the weights\n",
    "\n",
    "*for practical reasons training this network from scratch will take too long, and require large computational resources*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise network - and load weights\n",
    "net = UNet()\n",
    "net.load_state_dict(torch.load(path+'/'+'model.pt')) #this function loads a pretrained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an appropriate loss function\n",
    "We next define our loss function - in this case we use Dice loss, a commonly used loss for image segmentation.\n",
    "\n",
    "The Dice coefficient can be used as a loss function, and is essentially a measure of overlap between two samples.\n",
    "\n",
    "Dice is in the range of 0 to 1, where a Dice coefficient of 1 denotes perfect and complete overlap. The Dice coefficient was originally developed for binary data, and can be calculated as:\n",
    "\n",
    "$Dice = \\dfrac{2|A\\cap B|}{|A| + |B|}$\n",
    "\n",
    "where $|A\\cap B|$ represents the common elements between sets $A$ and $B$, and $|A|$ represents the number of elements in set $A$ (and likewise for set $B$).\n",
    "\n",
    "For the case of evaluating a Dice coefficient on predicted segmentation masks, we can approximate  $|A\\cap B|$ as the element-wise multiplication between the prediction and target mask, and then sum the resulting matrix.\n",
    "\n",
    "An **alternative loss** function would be pixel-wise cross entropy loss. It would examine each pixel individually, comparing the class predictions (depth-wise pixel vector) to our one-hot encoded target vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice loss\n",
    "def dice_coeff(pred, target):\n",
    "    \"\"\"This definition generalize to real valued pred and target vector.\n",
    "    This should be differentiable.\n",
    "    pred: tensor with first dimension as batch\n",
    "    target: tensor with first dimension as batch\n",
    "    \"\"\"\n",
    "\n",
    "    smooth = 1.\n",
    "    epsilon = 10e-8\n",
    "\n",
    "    # have to use contiguous since they may from a torch.view op\n",
    "    iflat = pred.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    A_sum = torch.sum(iflat * iflat)\n",
    "    B_sum = torch.sum(tflat * tflat)\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "    dice = dice.mean(dim=0)\n",
    "    dice = torch.clamp(dice, 0, 1.0-epsilon)\n",
    "\n",
    "    return  dice\n",
    "\n",
    "# cross entropy loss\n",
    "loss_BCE = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as before, we define the optimiser to train our network - here we use Adam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your optimiser\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=1e-05, betas=(0.5, 0.999))\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating our segmentation network\n",
    "We next train and evaluate our network \n",
    "\n",
    "note that the results are saved to a folder \\results - so please check that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2479: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][0/20] Elapsed_time: 0m2s Loss: 0.3897 Dice: 0.6103\n",
      "[0/10][1/20] Elapsed_time: 0m3s Loss: 0.3224 Dice: 0.6776\n",
      "[0/10][2/20] Elapsed_time: 0m5s Loss: 0.3065 Dice: 0.6935\n",
      "[0/10][3/20] Elapsed_time: 0m6s Loss: 0.3955 Dice: 0.6045\n",
      "[0/10][4/20] Elapsed_time: 0m8s Loss: 0.3504 Dice: 0.6496\n",
      "[0/10][5/20] Elapsed_time: 0m9s Loss: 0.3148 Dice: 0.6852\n",
      "[0/10][6/20] Elapsed_time: 0m10s Loss: 0.3657 Dice: 0.6343\n",
      "[0/10][7/20] Elapsed_time: 0m12s Loss: 0.3506 Dice: 0.6494\n",
      "[0/10][8/20] Elapsed_time: 0m13s Loss: 0.3435 Dice: 0.6565\n",
      "[0/10][9/20] Elapsed_time: 0m14s Loss: 0.3312 Dice: 0.6688\n",
      "[0/10][10/20] Elapsed_time: 0m16s Loss: 0.3087 Dice: 0.6913\n",
      "[0/10][11/20] Elapsed_time: 0m17s Loss: 0.3534 Dice: 0.6466\n",
      "[0/10][12/20] Elapsed_time: 0m19s Loss: 0.3108 Dice: 0.6892\n",
      "[0/10][13/20] Elapsed_time: 0m20s Loss: 0.3470 Dice: 0.6530\n",
      "[0/10][14/20] Elapsed_time: 0m22s Loss: 0.3565 Dice: 0.6435\n",
      "[0/10][15/20] Elapsed_time: 0m23s Loss: 0.3281 Dice: 0.6719\n",
      "[0/10][16/20] Elapsed_time: 0m25s Loss: 0.3561 Dice: 0.6439\n",
      "[0/10][17/20] Elapsed_time: 0m27s Loss: 0.3627 Dice: 0.6373\n",
      "[0/10][18/20] Elapsed_time: 0m28s Loss: 0.3460 Dice: 0.6540\n",
      "[0/10][19/20] Elapsed_time: 0m30s Loss: 0.3270 Dice: 0.6730\n",
      "Elapsed_time: 0m2s Val dice: 0.6841\n",
      "[1/10][0/20] Elapsed_time: 0m2s Loss: 0.3943 Dice: 0.6057\n",
      "[1/10][1/20] Elapsed_time: 0m3s Loss: 0.3306 Dice: 0.6694\n",
      "[1/10][2/20] Elapsed_time: 0m4s Loss: 0.3603 Dice: 0.6397\n",
      "[1/10][3/20] Elapsed_time: 0m6s Loss: 0.3753 Dice: 0.6247\n",
      "[1/10][4/20] Elapsed_time: 0m7s Loss: 0.3804 Dice: 0.6196\n",
      "[1/10][5/20] Elapsed_time: 0m9s Loss: 0.3249 Dice: 0.6751\n",
      "[1/10][6/20] Elapsed_time: 0m10s Loss: 0.3295 Dice: 0.6705\n",
      "[1/10][7/20] Elapsed_time: 0m11s Loss: 0.3222 Dice: 0.6778\n",
      "[1/10][8/20] Elapsed_time: 0m13s Loss: 0.3277 Dice: 0.6723\n",
      "[1/10][9/20] Elapsed_time: 0m15s Loss: 0.3688 Dice: 0.6312\n",
      "[1/10][10/20] Elapsed_time: 0m16s Loss: 0.3095 Dice: 0.6905\n",
      "[1/10][11/20] Elapsed_time: 0m18s Loss: 0.2919 Dice: 0.7081\n",
      "[1/10][12/20] Elapsed_time: 0m19s Loss: 0.3496 Dice: 0.6504\n",
      "[1/10][13/20] Elapsed_time: 0m20s Loss: 0.3109 Dice: 0.6891\n",
      "[1/10][14/20] Elapsed_time: 0m22s Loss: 0.3154 Dice: 0.6846\n",
      "[1/10][15/20] Elapsed_time: 0m24s Loss: 0.3724 Dice: 0.6276\n",
      "[1/10][16/20] Elapsed_time: 0m25s Loss: 0.3074 Dice: 0.6926\n",
      "[1/10][17/20] Elapsed_time: 0m27s Loss: 0.3786 Dice: 0.6214\n",
      "[1/10][18/20] Elapsed_time: 0m28s Loss: 0.3137 Dice: 0.6863\n",
      "[1/10][19/20] Elapsed_time: 0m30s Loss: 0.3256 Dice: 0.6744\n",
      "Elapsed_time: 0m2s Val dice: 0.6821\n",
      "[2/10][0/20] Elapsed_time: 0m1s Loss: 0.2946 Dice: 0.7054\n",
      "[2/10][1/20] Elapsed_time: 0m3s Loss: 0.3334 Dice: 0.6666\n",
      "[2/10][2/20] Elapsed_time: 0m5s Loss: 0.3441 Dice: 0.6559\n",
      "[2/10][3/20] Elapsed_time: 0m6s Loss: 0.3343 Dice: 0.6657\n",
      "[2/10][4/20] Elapsed_time: 0m7s Loss: 0.3475 Dice: 0.6525\n",
      "[2/10][5/20] Elapsed_time: 0m9s Loss: 0.3539 Dice: 0.6461\n",
      "[2/10][6/20] Elapsed_time: 0m10s Loss: 0.3220 Dice: 0.6780\n",
      "[2/10][7/20] Elapsed_time: 0m12s Loss: 0.3004 Dice: 0.6996\n",
      "[2/10][8/20] Elapsed_time: 0m14s Loss: 0.3328 Dice: 0.6672\n",
      "[2/10][9/20] Elapsed_time: 0m15s Loss: 0.3310 Dice: 0.6690\n",
      "[2/10][10/20] Elapsed_time: 0m16s Loss: 0.3893 Dice: 0.6107\n",
      "[2/10][11/20] Elapsed_time: 0m18s Loss: 0.3091 Dice: 0.6909\n",
      "[2/10][12/20] Elapsed_time: 0m19s Loss: 0.3338 Dice: 0.6662\n",
      "[2/10][13/20] Elapsed_time: 0m21s Loss: 0.2895 Dice: 0.7105\n",
      "[2/10][14/20] Elapsed_time: 0m22s Loss: 0.3218 Dice: 0.6782\n",
      "[2/10][15/20] Elapsed_time: 0m24s Loss: 0.4151 Dice: 0.5849\n",
      "[2/10][16/20] Elapsed_time: 0m25s Loss: 0.3844 Dice: 0.6156\n",
      "[2/10][17/20] Elapsed_time: 0m26s Loss: 0.3554 Dice: 0.6446\n",
      "[2/10][18/20] Elapsed_time: 0m28s Loss: 0.3063 Dice: 0.6937\n",
      "[2/10][19/20] Elapsed_time: 0m29s Loss: 0.3654 Dice: 0.6346\n",
      "Elapsed_time: 0m2s Val dice: 0.6846\n",
      "[3/10][0/20] Elapsed_time: 0m2s Loss: 0.3138 Dice: 0.6862\n",
      "[3/10][1/20] Elapsed_time: 0m4s Loss: 0.3543 Dice: 0.6457\n",
      "[3/10][2/20] Elapsed_time: 0m5s Loss: 0.3030 Dice: 0.6970\n",
      "[3/10][3/20] Elapsed_time: 0m6s Loss: 0.3078 Dice: 0.6922\n",
      "[3/10][4/20] Elapsed_time: 0m8s Loss: 0.3291 Dice: 0.6709\n",
      "[3/10][5/20] Elapsed_time: 0m9s Loss: 0.3472 Dice: 0.6528\n",
      "[3/10][6/20] Elapsed_time: 0m11s Loss: 0.3254 Dice: 0.6746\n",
      "[3/10][7/20] Elapsed_time: 0m12s Loss: 0.3643 Dice: 0.6357\n",
      "[3/10][8/20] Elapsed_time: 0m13s Loss: 0.3569 Dice: 0.6431\n",
      "[3/10][9/20] Elapsed_time: 0m15s Loss: 0.2909 Dice: 0.7091\n",
      "[3/10][10/20] Elapsed_time: 0m16s Loss: 0.3230 Dice: 0.6770\n",
      "[3/10][11/20] Elapsed_time: 0m18s Loss: 0.3298 Dice: 0.6702\n",
      "[3/10][12/20] Elapsed_time: 0m19s Loss: 0.3298 Dice: 0.6702\n",
      "[3/10][13/20] Elapsed_time: 0m21s Loss: 0.3744 Dice: 0.6256\n",
      "[3/10][14/20] Elapsed_time: 0m22s Loss: 0.3857 Dice: 0.6143\n",
      "[3/10][15/20] Elapsed_time: 0m24s Loss: 0.3073 Dice: 0.6927\n",
      "[3/10][16/20] Elapsed_time: 0m25s Loss: 0.3284 Dice: 0.6716\n",
      "[3/10][17/20] Elapsed_time: 0m27s Loss: 0.3297 Dice: 0.6703\n",
      "[3/10][18/20] Elapsed_time: 0m28s Loss: 0.3133 Dice: 0.6867\n",
      "[3/10][19/20] Elapsed_time: 0m30s Loss: 0.3619 Dice: 0.6381\n",
      "Elapsed_time: 0m2s Val dice: 0.6822\n",
      "[4/10][0/20] Elapsed_time: 0m2s Loss: 0.3612 Dice: 0.6388\n",
      "[4/10][1/20] Elapsed_time: 0m3s Loss: 0.4140 Dice: 0.5860\n",
      "[4/10][2/20] Elapsed_time: 0m5s Loss: 0.3285 Dice: 0.6715\n",
      "[4/10][3/20] Elapsed_time: 0m6s Loss: 0.3406 Dice: 0.6594\n",
      "[4/10][4/20] Elapsed_time: 0m7s Loss: 0.3834 Dice: 0.6166\n",
      "[4/10][5/20] Elapsed_time: 0m9s Loss: 0.3583 Dice: 0.6417\n",
      "[4/10][6/20] Elapsed_time: 0m10s Loss: 0.3222 Dice: 0.6778\n",
      "[4/10][7/20] Elapsed_time: 0m12s Loss: 0.3949 Dice: 0.6051\n",
      "[4/10][8/20] Elapsed_time: 0m13s Loss: 0.3525 Dice: 0.6475\n",
      "[4/10][9/20] Elapsed_time: 0m15s Loss: 0.3128 Dice: 0.6872\n",
      "[4/10][10/20] Elapsed_time: 0m16s Loss: 0.3152 Dice: 0.6848\n",
      "[4/10][11/20] Elapsed_time: 0m18s Loss: 0.3125 Dice: 0.6875\n",
      "[4/10][12/20] Elapsed_time: 0m19s Loss: 0.3146 Dice: 0.6854\n",
      "[4/10][13/20] Elapsed_time: 0m21s Loss: 0.3087 Dice: 0.6913\n",
      "[4/10][14/20] Elapsed_time: 0m22s Loss: 0.3126 Dice: 0.6874\n",
      "[4/10][15/20] Elapsed_time: 0m23s Loss: 0.2983 Dice: 0.7017\n",
      "[4/10][16/20] Elapsed_time: 0m25s Loss: 0.3311 Dice: 0.6689\n",
      "[4/10][17/20] Elapsed_time: 0m26s Loss: 0.3621 Dice: 0.6379\n",
      "[4/10][18/20] Elapsed_time: 0m27s Loss: 0.2791 Dice: 0.7209\n",
      "[4/10][19/20] Elapsed_time: 0m29s Loss: 0.3433 Dice: 0.6567\n",
      "Elapsed_time: 0m2s Val dice: 0.6841\n",
      "[5/10][0/20] Elapsed_time: 0m2s Loss: 0.3361 Dice: 0.6639\n",
      "[5/10][1/20] Elapsed_time: 0m3s Loss: 0.3014 Dice: 0.6986\n",
      "[5/10][2/20] Elapsed_time: 0m5s Loss: 0.3576 Dice: 0.6424\n",
      "[5/10][3/20] Elapsed_time: 0m6s Loss: 0.3408 Dice: 0.6592\n",
      "[5/10][4/20] Elapsed_time: 0m7s Loss: 0.3236 Dice: 0.6764\n",
      "[5/10][5/20] Elapsed_time: 0m9s Loss: 0.3079 Dice: 0.6921\n",
      "[5/10][6/20] Elapsed_time: 0m10s Loss: 0.3560 Dice: 0.6440\n",
      "[5/10][7/20] Elapsed_time: 0m12s Loss: 0.3279 Dice: 0.6721\n",
      "[5/10][8/20] Elapsed_time: 0m13s Loss: 0.3445 Dice: 0.6555\n",
      "[5/10][9/20] Elapsed_time: 0m15s Loss: 0.3292 Dice: 0.6708\n",
      "[5/10][10/20] Elapsed_time: 0m17s Loss: 0.3115 Dice: 0.6885\n",
      "[5/10][11/20] Elapsed_time: 0m18s Loss: 0.3219 Dice: 0.6781\n",
      "[5/10][12/20] Elapsed_time: 0m20s Loss: 0.3470 Dice: 0.6530\n",
      "[5/10][13/20] Elapsed_time: 0m22s Loss: 0.3141 Dice: 0.6859\n",
      "[5/10][14/20] Elapsed_time: 0m23s Loss: 0.4281 Dice: 0.5719\n",
      "[5/10][15/20] Elapsed_time: 0m24s Loss: 0.3346 Dice: 0.6654\n",
      "[5/10][16/20] Elapsed_time: 0m26s Loss: 0.2897 Dice: 0.7103\n",
      "[5/10][17/20] Elapsed_time: 0m27s Loss: 0.3615 Dice: 0.6385\n",
      "[5/10][18/20] Elapsed_time: 0m29s Loss: 0.3373 Dice: 0.6627\n",
      "[5/10][19/20] Elapsed_time: 0m31s Loss: 0.3205 Dice: 0.6795\n",
      "Elapsed_time: 0m2s Val dice: 0.6872\n",
      "[6/10][0/20] Elapsed_time: 0m2s Loss: 0.3632 Dice: 0.6368\n",
      "[6/10][1/20] Elapsed_time: 0m4s Loss: 0.3214 Dice: 0.6786\n",
      "[6/10][2/20] Elapsed_time: 0m6s Loss: 0.2950 Dice: 0.7050\n",
      "[6/10][3/20] Elapsed_time: 0m7s Loss: 0.3505 Dice: 0.6495\n",
      "[6/10][4/20] Elapsed_time: 0m9s Loss: 0.3096 Dice: 0.6904\n",
      "[6/10][5/20] Elapsed_time: 0m10s Loss: 0.3200 Dice: 0.6800\n",
      "[6/10][6/20] Elapsed_time: 0m12s Loss: 0.3096 Dice: 0.6904\n",
      "[6/10][7/20] Elapsed_time: 0m14s Loss: 0.2934 Dice: 0.7066\n",
      "[6/10][8/20] Elapsed_time: 0m15s Loss: 0.3276 Dice: 0.6724\n",
      "[6/10][9/20] Elapsed_time: 0m17s Loss: 0.3392 Dice: 0.6608\n",
      "[6/10][10/20] Elapsed_time: 0m18s Loss: 0.3453 Dice: 0.6547\n",
      "[6/10][11/20] Elapsed_time: 0m20s Loss: 0.2840 Dice: 0.7160\n",
      "[6/10][12/20] Elapsed_time: 0m21s Loss: 0.3248 Dice: 0.6752\n",
      "[6/10][13/20] Elapsed_time: 0m23s Loss: 0.2970 Dice: 0.7030\n",
      "[6/10][14/20] Elapsed_time: 0m25s Loss: 0.3347 Dice: 0.6653\n",
      "[6/10][15/20] Elapsed_time: 0m27s Loss: 0.3222 Dice: 0.6778\n",
      "[6/10][16/20] Elapsed_time: 0m28s Loss: 0.3470 Dice: 0.6530\n",
      "[6/10][17/20] Elapsed_time: 0m30s Loss: 0.3384 Dice: 0.6616\n",
      "[6/10][18/20] Elapsed_time: 0m31s Loss: 0.4116 Dice: 0.5884\n",
      "[6/10][19/20] Elapsed_time: 0m32s Loss: 0.3873 Dice: 0.6127\n",
      "Elapsed_time: 0m2s Val dice: 0.6866\n",
      "[7/10][0/20] Elapsed_time: 0m1s Loss: 0.3329 Dice: 0.6671\n",
      "[7/10][1/20] Elapsed_time: 0m3s Loss: 0.4440 Dice: 0.5560\n",
      "[7/10][2/20] Elapsed_time: 0m4s Loss: 0.3372 Dice: 0.6628\n",
      "[7/10][3/20] Elapsed_time: 0m6s Loss: 0.3365 Dice: 0.6635\n",
      "[7/10][4/20] Elapsed_time: 0m8s Loss: 0.3114 Dice: 0.6886\n",
      "[7/10][5/20] Elapsed_time: 0m9s Loss: 0.3318 Dice: 0.6682\n",
      "[7/10][6/20] Elapsed_time: 0m11s Loss: 0.3411 Dice: 0.6589\n",
      "[7/10][7/20] Elapsed_time: 0m12s Loss: 0.3102 Dice: 0.6898\n",
      "[7/10][8/20] Elapsed_time: 0m14s Loss: 0.3019 Dice: 0.6981\n",
      "[7/10][9/20] Elapsed_time: 0m15s Loss: 0.3535 Dice: 0.6465\n",
      "[7/10][10/20] Elapsed_time: 0m17s Loss: 0.3291 Dice: 0.6709\n",
      "[7/10][11/20] Elapsed_time: 0m19s Loss: 0.3137 Dice: 0.6863\n",
      "[7/10][12/20] Elapsed_time: 0m21s Loss: 0.3422 Dice: 0.6578\n",
      "[7/10][13/20] Elapsed_time: 0m22s Loss: 0.3210 Dice: 0.6790\n",
      "[7/10][14/20] Elapsed_time: 0m24s Loss: 0.2822 Dice: 0.7178\n",
      "[7/10][15/20] Elapsed_time: 0m25s Loss: 0.2890 Dice: 0.7110\n",
      "[7/10][16/20] Elapsed_time: 0m27s Loss: 0.3637 Dice: 0.6363\n",
      "[7/10][17/20] Elapsed_time: 0m28s Loss: 0.3597 Dice: 0.6403\n",
      "[7/10][18/20] Elapsed_time: 0m30s Loss: 0.3845 Dice: 0.6155\n",
      "[7/10][19/20] Elapsed_time: 0m31s Loss: 0.3323 Dice: 0.6677\n",
      "Elapsed_time: 0m2s Val dice: 0.6865\n",
      "[8/10][0/20] Elapsed_time: 0m1s Loss: 0.3249 Dice: 0.6751\n",
      "[8/10][1/20] Elapsed_time: 0m3s Loss: 0.3132 Dice: 0.6868\n",
      "[8/10][2/20] Elapsed_time: 0m5s Loss: 0.2988 Dice: 0.7012\n",
      "[8/10][3/20] Elapsed_time: 0m6s Loss: 0.3197 Dice: 0.6803\n",
      "[8/10][4/20] Elapsed_time: 0m8s Loss: 0.2839 Dice: 0.7161\n",
      "[8/10][5/20] Elapsed_time: 0m9s Loss: 0.3393 Dice: 0.6607\n",
      "[8/10][6/20] Elapsed_time: 0m10s Loss: 0.3021 Dice: 0.6979\n",
      "[8/10][7/20] Elapsed_time: 0m12s Loss: 0.4084 Dice: 0.5916\n",
      "[8/10][8/20] Elapsed_time: 0m13s Loss: 0.3015 Dice: 0.6985\n",
      "[8/10][9/20] Elapsed_time: 0m14s Loss: 0.3431 Dice: 0.6569\n",
      "[8/10][10/20] Elapsed_time: 0m16s Loss: 0.3664 Dice: 0.6336\n",
      "[8/10][11/20] Elapsed_time: 0m18s Loss: 0.3259 Dice: 0.6741\n",
      "[8/10][12/20] Elapsed_time: 0m19s Loss: 0.3510 Dice: 0.6490\n",
      "[8/10][13/20] Elapsed_time: 0m21s Loss: 0.2941 Dice: 0.7059\n",
      "[8/10][14/20] Elapsed_time: 0m22s Loss: 0.3020 Dice: 0.6980\n",
      "[8/10][15/20] Elapsed_time: 0m24s Loss: 0.4120 Dice: 0.5880\n",
      "[8/10][16/20] Elapsed_time: 0m25s Loss: 0.3386 Dice: 0.6614\n",
      "[8/10][17/20] Elapsed_time: 0m27s Loss: 0.3401 Dice: 0.6599\n",
      "[8/10][18/20] Elapsed_time: 0m28s Loss: 0.2984 Dice: 0.7016\n",
      "[8/10][19/20] Elapsed_time: 0m30s Loss: 0.3144 Dice: 0.6856\n",
      "Elapsed_time: 0m2s Val dice: 0.6908\n",
      "[9/10][0/20] Elapsed_time: 0m1s Loss: 0.3285 Dice: 0.6715\n",
      "[9/10][1/20] Elapsed_time: 0m3s Loss: 0.3223 Dice: 0.6777\n",
      "[9/10][2/20] Elapsed_time: 0m4s Loss: 0.3482 Dice: 0.6518\n",
      "[9/10][3/20] Elapsed_time: 0m6s Loss: 0.3151 Dice: 0.6849\n",
      "[9/10][4/20] Elapsed_time: 0m7s Loss: 0.3348 Dice: 0.6652\n",
      "[9/10][5/20] Elapsed_time: 0m9s Loss: 0.3091 Dice: 0.6909\n",
      "[9/10][6/20] Elapsed_time: 0m10s Loss: 0.3071 Dice: 0.6929\n",
      "[9/10][7/20] Elapsed_time: 0m12s Loss: 0.3740 Dice: 0.6260\n",
      "[9/10][8/20] Elapsed_time: 0m14s Loss: 0.2913 Dice: 0.7087\n",
      "[9/10][9/20] Elapsed_time: 0m15s Loss: 0.3431 Dice: 0.6569\n",
      "[9/10][10/20] Elapsed_time: 0m17s Loss: 0.3393 Dice: 0.6607\n",
      "[9/10][11/20] Elapsed_time: 0m18s Loss: 0.2979 Dice: 0.7021\n",
      "[9/10][12/20] Elapsed_time: 0m20s Loss: 0.2982 Dice: 0.7018\n",
      "[9/10][13/20] Elapsed_time: 0m21s Loss: 0.3298 Dice: 0.6702\n",
      "[9/10][14/20] Elapsed_time: 0m23s Loss: 0.3767 Dice: 0.6233\n",
      "[9/10][15/20] Elapsed_time: 0m24s Loss: 0.3385 Dice: 0.6615\n",
      "[9/10][16/20] Elapsed_time: 0m25s Loss: 0.3018 Dice: 0.6982\n",
      "[9/10][17/20] Elapsed_time: 0m27s Loss: 0.2879 Dice: 0.7121\n",
      "[9/10][18/20] Elapsed_time: 0m29s Loss: 0.3815 Dice: 0.6185\n",
      "[9/10][19/20] Elapsed_time: 0m30s Loss: 0.3029 Dice: 0.6971\n",
      "Elapsed_time: 0m2s Val dice: 0.6900\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "save_every=10\n",
    "all_error = np.zeros(0)\n",
    "all_error_L1 = np.zeros(0)\n",
    "all_error_dice = np.zeros(0)\n",
    "all_dice = np.zeros(0)\n",
    "all_val_dice = np.zeros(1)\n",
    "all_val_error = np.zeros(0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ##########\n",
    "    # Train\n",
    "    ##########\n",
    "    t0 = time.time()\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        \n",
    "        # setting your network to train will ensure that parameters will be updated during training, \n",
    "        # and that dropout will be used\n",
    "        net.train()\n",
    "        net.zero_grad()\n",
    "\n",
    "        target_real = torch.ones(data.size()[0])\n",
    "        batch_size = data.size()[0]\n",
    "        pred = net(data)\n",
    "        \n",
    "        # dice loss = 1-dice_coeff\n",
    "        # ----------------------------------------------- task 3 ------------------------------------------------------------\n",
    "        # Task 3: change loss function here\n",
    "        err = 1- dice_coeff(pred, label)\n",
    "        err = loss_BCE(pred, label)\n",
    "        # -------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        dice_value = dice_coeff(pred, label).item()\n",
    "\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        time_elapsed = time.time() - t0\n",
    "        print('[{:d}/{:d}][{:d}/{:d}] Elapsed_time: {:.0f}m{:.0f}s Loss: {:.4f} Dice: {:.4f}'\n",
    "              .format(epoch, epochs, i, len(train_loader), time_elapsed // 60, time_elapsed % 60,\n",
    "                      err.item(), dice_value))\n",
    "\n",
    "        if i % save_every == 0:\n",
    "            # setting your network to eval mode to remove dropout during testing\n",
    "            net.eval()\n",
    "\n",
    "            vutils.save_image(data.data, '%s/epoch_%03d_i_%03d_train_data.png' % (path, epoch, i),\n",
    "                                  normalize=True)\n",
    "            vutils.save_image(label.data, '%s/epoch_%03d_i_%03d_train_label.png' % (path, epoch, i),\n",
    "                                  normalize=True)\n",
    "            vutils.save_image(pred.data, '%s/epoch_%03d_i_%03d_train_pred.png' % (path, epoch, i),\n",
    "                                  normalize=True)\n",
    "\n",
    "            error = err.item()\n",
    "\n",
    "            all_error = np.append(all_error, error)\n",
    "            all_dice = np.append(all_dice, dice_value)\n",
    "\n",
    "    # #############\n",
    "    # # Validation\n",
    "    # #############\n",
    "    mean_error = np.zeros(0)\n",
    "    mean_dice = np.zeros(0)\n",
    "    t0 = time.time()\n",
    "    for i, (data, label) in enumerate(val_loader):\n",
    "\n",
    "        net.eval()\n",
    "        batch_size = data.size()[0]\n",
    "\n",
    "        data, label = Variable(data), Variable(label)\n",
    "        pred = net(data)\n",
    "        \n",
    "        # ----------------------------------------------- task 3 ------------------------------------------------------------\n",
    "        # Task 3: change loss function here\n",
    "        err = 1-dice_coeff(pred, label)\n",
    "        # err = loss_BCE(pred, label)\n",
    "        # -------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # compare generated image to data-  metric\n",
    "        dice_value = dice_coeff(pred, label).item()\n",
    "\n",
    "        if i == 0:\n",
    "            vutils.save_image(data.data, '%s/epoch_%03d_i_%03d_val_data.png' % (path, epoch, i),\n",
    "                              normalize=True)\n",
    "            vutils.save_image(label.data, '%s/epoch_%03d_i_%03d_val_label.png' % (path, epoch, i),\n",
    "                              normalize=True)\n",
    "            vutils.save_image(pred.data, '%s/epoch_%03d_i_%03d_val_pred.png' % (path, epoch, i),\n",
    "                              normalize=True)\n",
    "\n",
    "        error = err.item()\n",
    "        mean_error = np.append(mean_error, error)\n",
    "        mean_dice = np.append(mean_dice, dice_value)\n",
    "\n",
    "    all_val_error = np.append(all_val_error, np.mean(mean_error))\n",
    "    all_val_dice = np.append(all_val_dice, np.mean(mean_dice))\n",
    "\n",
    "    time_elapsed = time.time() - t0\n",
    "\n",
    "    print('Elapsed_time: {:.0f}m{:.0f}s Val dice: {:.4f}'\n",
    "          .format(time_elapsed // 60, time_elapsed % 60, mean_dice.mean()))\n",
    "    \n",
    "    \n",
    "    num_it_per_epoch_train = ((train_loader.dataset.x_data.shape[0] * (1 - 0.2)) // (\n",
    "            save_every * batch_size)) + 1\n",
    "    epochs_train = np.arange(1,all_error.size+1) / num_it_per_epoch_train\n",
    "    epochs_val = np.arange(0,all_val_dice.size)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_val, all_val_dice, label='dice_val')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "    plt.title('Dice score')\n",
    "    plt.savefig(path + '/dice_val.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "the results are saved to a folder \\results - so please check that:\n",
    "\n",
    "The results are saved per epoch for both training and validation, and are saved as the \n",
    "1. real data, \n",
    "2. binary labels, \n",
    "3. predicted labels. \n",
    "\n",
    "In this example since we trained on a small sample of the data (100 crops) the results are far from optimal, and are likely to overfit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "1. Change the dice loss to a cross entropy loss in the code - is dice loss or cross entropy loss better?\n",
    "2. run the training with dropout - what's the effect?\n",
    "\n",
    "**Note down your dice validation scores for each experiment, then change**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
