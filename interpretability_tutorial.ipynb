{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability tutorial\n",
    "\n",
    "In this tutorial we will go through several popular visualization techniques that help interpret deep learning networks.\n",
    "\n",
    "We will cover:\n",
    "1. Filter visualization\n",
    "2. Feature/ activation visualization with PyTorch hooks\n",
    "3. CNN Layer Visualization\n",
    "4. Gradient visualization with Guided backpropagation\n",
    "5. Gradient Class Activation Maps (grad-CAM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import visualizations\n",
    "from visualizations.src.misc_functions import *\n",
    "from visualizations.src.guided_backprop import GuidedBackprop\n",
    "from visualizations.src.cnn_layer_visualization import CNNLayerVisualization\n",
    "from visualizations.src.gradcam import GradCam\n",
    "from visualizations.src.deep_dream import DeepDream\n",
    "\n",
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Weights Visualization\n",
    "\n",
    "https://towardsdatascience.com/visualizing-convolution-neural-networks-using-pytorch-3dfa8443e74e\n",
    "\n",
    "https://colab.research.google.com/github/Niranjankumar-c/DeepLearning-PadhAI/blob/master/DeepLearning_Materials/6_VisualizationCNN_Pytorch/CNNVisualisation.ipynb#scrollTo=uQI9jHcP6xfP\n",
    "\n",
    "One of the first things you can visualize in your network - is your network weights.\n",
    "Your convolutional kernels have weights which are updated during training, and can be visualized by calling the weight data inside your network.\n",
    "\n",
    "Let's first load and print a pretrained network using pytorch.models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /home/cb19/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n",
      "100%|██████████| 244418560/244418560 [00:13<00:00, 18518656.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# first load pretrained alxenet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the network is made up of two sequential models - features, and classifier.\n",
    "\n",
    "To visualize the convolutional weights, we need to access a convolutional layer in the features model.\n",
    "\n",
    "This can be done in the following way:\n",
    "```python \n",
    "weight_tensor = model.features[layer_num].weight.data\n",
    "```\n",
    "**Note that layer_num should correspond to a convolutional layer - otherwise there are no weights to be visualized.**\n",
    "\n",
    "We will now define a few functions to help with plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_single_channel(t):\n",
    "    \n",
    "    kernels_to_plot = 30\n",
    "    channels_to_plot = 3\n",
    "    #total kernels depth * number of kernels\n",
    "    nplots = channels_to_plot*kernels_to_plot\n",
    "    ncols = 12\n",
    "    \n",
    "    nrows = 1 + nplots//ncols\n",
    "    #convert tensor to numpy image\n",
    "    npimg = np.array(t.numpy(), np.float32)\n",
    "    \n",
    "    count = 0\n",
    "    fig = plt.figure(figsize=(ncols, nrows))\n",
    "    \n",
    "    #looping through all the kernels in each channel\n",
    "    for i in range(kernels_to_plot):\n",
    "        for j in range(channels_to_plot):\n",
    "            count += 1\n",
    "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
    "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
    "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "            ax1.imshow(npimg)\n",
    "            ax1.set_title(str(i) + ',' + str(j))\n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "def plot_filters_multi_channel(t):\n",
    "    \n",
    "    kernels_to_plot = 60\n",
    "    #get the number of kernals\n",
    "    num_kernels = t.shape[0]    \n",
    "    \n",
    "    #define number of columns for subplots\n",
    "    num_cols = 12\n",
    "    #rows = num of kernels\n",
    "    num_rows = kernels_to_plot // num_cols\n",
    "    \n",
    "    #set the figure size\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    \n",
    "    #looping through all the kernels\n",
    "    for i in range(kernels_to_plot):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        \n",
    "        #for each kernel, we convert the tensor to numpy \n",
    "        npimg = np.array(t[i].numpy(), np.float32)\n",
    "        #standardize the numpy image\n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define our plot weights function, which first extracts the weights of a convolutional filter, and then passes into an appropriate image plotting function.\n",
    "\n",
    "### Task 1.1 - edit the `plot_weights` function to return the weights tensor corresponding to layer `layer_num`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(model, layer_num, single_channel = True):\n",
    "    #extracting the model features at the particular layer number\n",
    "    layer = model.features[layer_num]\n",
    "  \n",
    "    #checking whether the layer is convolution layer or not \n",
    "\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        #getting the weight tensor data\n",
    "        weight_tensor = model.features[layer_num].weight.data\n",
    "        print('weight_tensor.shape',weight_tensor.shape)\n",
    "        if single_channel:\n",
    "            plot_filters_single_channel(weight_tensor)\n",
    "        \n",
    "        else:\n",
    "            if weight_tensor.shape[1] == 3:\n",
    "                plot_filters_multi_channel(weight_tensor)\n",
    "            else:\n",
    "                print(\"Can only plot weights with three channels with single channel = False\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Can only visualize layers which are convolutional\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 Explain \n",
    "\n",
    "- what do the weights of your network represent? \n",
    "- what is the difference between a kernel and a filter (**hint** see lecture 4)\n",
    "- Layer 3 (the second convolution) has a weights matrix of size `[192, 64, 5, 5]`. What does each dimension represent? How many filters does it learn, how many kernels?\n",
    "\n",
    "#### Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3  Visualise weights for different layers.\n",
    "\n",
    "- plot the weights for different colvolutional layers\n",
    "- Note the purpose of parameter `single_channel=False` is to plot all filters as a single image. **However** this is only possible for 3 channel output - where it can be plotted in RGB; \n",
    "- try plotting the output of the first layer with `single_channel=True`, then `single_channel=False` to see the difference\n",
    "- What do the numbers above the plots mean? How many outputs are being returned and why (**hint** check the plotting functions)? How do you determine how many \n",
    "- try editing the plotting functions to include input arguments which vary the numbers of kernels plot per filter for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_tensor.shape torch.Size([384, 192, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 90 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize weights for alexnet - first conv layer\n",
    "plot_weights(alexnet, 6, single_channel = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. Activation visualization with PyTorch Hooks\n",
    "\n",
    "Another effective approach to examine what your network is learning, is the visualize your network's features or activations, i.e. intermediate outputs of your network for a specific inputs. \n",
    "\n",
    "Let's use MNIST for this example. Loading train and validation DataLoaders, and generating a similar basic convolutional network to which we used in Lecture 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/train/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:03, 2820988.55it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28881 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/train/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 125174.14it/s]           \n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/train/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:02, 563953.09it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 48995.96it/s]            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/test/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:09, 1016771.95it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/test/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28881 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/test/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 127714.75it/s]           \n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/test/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/test/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 925320.87it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/test/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 48120.52it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist_train_dataset = datasets.MNIST(root = 'mnist_data/train', download= True, train = True, transform = transforms.ToTensor())\n",
    "mnist_test_dataset = datasets.MNIST(root = 'mnist_data/test', download= True, train = False, transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "       mnist_train_dataset, batch_size= 8, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "       mnist_test_dataset, batch_size = 8, shuffle = True)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "          '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_Model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout2d(p=0.5)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout2d(p=0.5)\n",
      "  (lin_blocks): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MNIST_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Model, self).__init__()\n",
    "    \n",
    "        self.conv1=nn.Conv2d(1, 10, 3)\n",
    "        self.maxpool1=nn.MaxPool2d(2)\n",
    "        self.dropout1=nn.Dropout2d()\n",
    "        \n",
    "        self.conv2=nn.Conv2d(10, 20, 3)\n",
    "        self.maxpool2=nn.MaxPool2d(2)\n",
    "        self.dropout2=nn.Dropout2d()\n",
    "        \n",
    "        self.lin_blocks = nn.Sequential(\n",
    "            nn.Linear(500, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10),\n",
    "            #nn.Softmax(),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        #print(x.shape)\n",
    "        x = self.lin_blocks(x)\n",
    "\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "    \n",
    "net = MNIST_Model() \n",
    "print(net)\n",
    "net = net.to(device)\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "loss_fun = loss_fun.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.425\n",
      "[1,    11] loss: 2.287\n",
      "[1,    21] loss: 2.337\n",
      "[1,    31] loss: 2.295\n",
      "[1,    41] loss: 2.322\n",
      "[1,    51] loss: 2.301\n",
      "[1,    61] loss: 2.383\n",
      "[1,    71] loss: 2.327\n",
      "[1,    81] loss: 2.297\n",
      "[1,    91] loss: 2.372\n",
      "[1,   101] loss: 2.258\n",
      "[1,   111] loss: 2.321\n",
      "[1,   121] loss: 2.296\n",
      "[1,   131] loss: 2.312\n",
      "[1,   141] loss: 2.324\n",
      "[1,   151] loss: 2.275\n",
      "[1,   161] loss: 2.375\n",
      "[1,   171] loss: 2.297\n",
      "[1,   181] loss: 2.342\n",
      "[1,   191] loss: 2.302\n",
      "[1,   201] loss: 2.255\n",
      "[1,   211] loss: 2.283\n",
      "[1,   221] loss: 2.282\n",
      "[1,   231] loss: 2.318\n",
      "[1,   241] loss: 2.266\n",
      "[1,   251] loss: 2.241\n",
      "[1,   261] loss: 2.240\n",
      "[1,   271] loss: 2.251\n",
      "[1,   281] loss: 2.284\n",
      "[1,   291] loss: 2.278\n",
      "[1,   301] loss: 2.182\n",
      "[1,   311] loss: 2.208\n",
      "[1,   321] loss: 2.263\n",
      "[1,   331] loss: 2.257\n",
      "[1,   341] loss: 2.219\n",
      "[1,   351] loss: 2.125\n",
      "[1,   361] loss: 2.271\n",
      "[1,   371] loss: 2.150\n",
      "[1,   381] loss: 2.310\n",
      "[1,   391] loss: 2.342\n",
      "[1,   401] loss: 2.221\n",
      "[1,   411] loss: 2.272\n",
      "[1,   421] loss: 2.226\n",
      "[1,   431] loss: 2.267\n",
      "[1,   441] loss: 2.306\n",
      "[1,   451] loss: 2.222\n",
      "[1,   461] loss: 2.147\n",
      "[1,   471] loss: 2.092\n",
      "[1,   481] loss: 2.136\n",
      "[1,   491] loss: 2.304\n",
      "[1,   501] loss: 2.165\n",
      "[1,   511] loss: 2.229\n",
      "[1,   521] loss: 2.289\n",
      "[1,   531] loss: 2.199\n",
      "[1,   541] loss: 2.061\n",
      "[1,   551] loss: 2.140\n",
      "[1,   561] loss: 2.119\n",
      "[1,   571] loss: 2.056\n",
      "[1,   581] loss: 2.190\n",
      "[1,   591] loss: 1.949\n",
      "[1,   601] loss: 1.950\n",
      "[1,   611] loss: 2.104\n",
      "[1,   621] loss: 2.211\n",
      "[1,   631] loss: 1.991\n",
      "[1,   641] loss: 1.929\n",
      "[1,   651] loss: 1.652\n",
      "[1,   661] loss: 2.078\n",
      "[1,   671] loss: 2.222\n",
      "[1,   681] loss: 1.722\n",
      "[1,   691] loss: 1.640\n",
      "[1,   701] loss: 2.173\n",
      "[1,   711] loss: 1.692\n",
      "[1,   721] loss: 1.928\n",
      "[1,   731] loss: 1.919\n",
      "[1,   741] loss: 1.768\n",
      "[1,   751] loss: 1.922\n",
      "[1,   761] loss: 1.653\n",
      "[1,   771] loss: 1.357\n",
      "[1,   781] loss: 1.520\n",
      "[1,   791] loss: 1.838\n",
      "[1,   801] loss: 1.530\n",
      "[1,   811] loss: 1.607\n",
      "[1,   821] loss: 0.946\n",
      "[1,   831] loss: 1.256\n",
      "[1,   841] loss: 1.515\n",
      "[1,   851] loss: 1.491\n",
      "[1,   861] loss: 1.297\n",
      "[1,   871] loss: 1.325\n",
      "[1,   881] loss: 1.513\n",
      "[1,   891] loss: 2.018\n",
      "[1,   901] loss: 1.302\n",
      "[1,   911] loss: 1.517\n",
      "[1,   921] loss: 1.248\n",
      "[1,   931] loss: 1.331\n",
      "[1,   941] loss: 0.962\n",
      "[1,   951] loss: 1.712\n",
      "[1,   961] loss: 1.300\n",
      "[1,   971] loss: 1.262\n",
      "[1,   981] loss: 1.235\n",
      "[1,   991] loss: 1.319\n",
      "[1,  1001] loss: 0.981\n",
      "[1,  1011] loss: 1.082\n",
      "[1,  1021] loss: 1.447\n",
      "[1,  1031] loss: 0.965\n",
      "[1,  1041] loss: 1.086\n",
      "[1,  1051] loss: 0.949\n",
      "[1,  1061] loss: 1.596\n",
      "[1,  1071] loss: 0.685\n",
      "[1,  1081] loss: 1.284\n",
      "[1,  1091] loss: 1.067\n",
      "[1,  1101] loss: 2.022\n",
      "[1,  1111] loss: 1.084\n",
      "[1,  1121] loss: 0.867\n",
      "[1,  1131] loss: 0.554\n",
      "[1,  1141] loss: 0.786\n",
      "[1,  1151] loss: 1.026\n",
      "[1,  1161] loss: 0.933\n",
      "[1,  1171] loss: 0.875\n",
      "[1,  1181] loss: 1.637\n",
      "[1,  1191] loss: 1.211\n",
      "[1,  1201] loss: 0.825\n",
      "[1,  1211] loss: 0.847\n",
      "[1,  1221] loss: 1.876\n",
      "[1,  1231] loss: 1.014\n",
      "[1,  1241] loss: 0.980\n",
      "[1,  1251] loss: 1.307\n",
      "[1,  1261] loss: 0.702\n",
      "[1,  1271] loss: 0.866\n",
      "[1,  1281] loss: 0.851\n",
      "[1,  1291] loss: 0.899\n",
      "[1,  1301] loss: 0.229\n",
      "[1,  1311] loss: 0.749\n",
      "[1,  1321] loss: 0.751\n",
      "[1,  1331] loss: 1.402\n",
      "[1,  1341] loss: 0.372\n",
      "[1,  1351] loss: 0.614\n",
      "[1,  1361] loss: 0.365\n",
      "[1,  1371] loss: 0.672\n",
      "[1,  1381] loss: 0.781\n",
      "[1,  1391] loss: 0.531\n",
      "[1,  1401] loss: 0.499\n",
      "[1,  1411] loss: 0.881\n",
      "[1,  1421] loss: 0.978\n",
      "[1,  1431] loss: 0.619\n",
      "[1,  1441] loss: 0.767\n",
      "[1,  1451] loss: 1.679\n",
      "[1,  1461] loss: 1.420\n",
      "[1,  1471] loss: 1.802\n",
      "[1,  1481] loss: 0.789\n",
      "[1,  1491] loss: 0.242\n",
      "[1,  1501] loss: 0.505\n",
      "[1,  1511] loss: 1.040\n",
      "[1,  1521] loss: 1.153\n",
      "[1,  1531] loss: 0.789\n",
      "[1,  1541] loss: 1.057\n",
      "[1,  1551] loss: 0.401\n",
      "[1,  1561] loss: 0.742\n",
      "[1,  1571] loss: 0.376\n",
      "[1,  1581] loss: 0.469\n",
      "[1,  1591] loss: 0.567\n",
      "[1,  1601] loss: 0.422\n",
      "[1,  1611] loss: 0.359\n",
      "[1,  1621] loss: 1.506\n",
      "[1,  1631] loss: 0.775\n",
      "[1,  1641] loss: 0.451\n",
      "[1,  1651] loss: 0.801\n",
      "[1,  1661] loss: 0.459\n",
      "[1,  1671] loss: 0.766\n",
      "[1,  1681] loss: 1.180\n",
      "[1,  1691] loss: 0.801\n",
      "[1,  1701] loss: 0.310\n",
      "[1,  1711] loss: 0.145\n",
      "[1,  1721] loss: 0.787\n",
      "[1,  1731] loss: 0.535\n",
      "[1,  1741] loss: 1.189\n",
      "[1,  1751] loss: 0.831\n",
      "[1,  1761] loss: 0.311\n",
      "[1,  1771] loss: 0.353\n",
      "[1,  1781] loss: 0.480\n",
      "[1,  1791] loss: 0.393\n",
      "[1,  1801] loss: 0.209\n",
      "[1,  1811] loss: 0.615\n",
      "[1,  1821] loss: 0.315\n",
      "[1,  1831] loss: 0.263\n",
      "[1,  1841] loss: 1.242\n",
      "[1,  1851] loss: 0.268\n",
      "[1,  1861] loss: 0.286\n",
      "[1,  1871] loss: 0.358\n",
      "[1,  1881] loss: 0.390\n",
      "[1,  1891] loss: 0.375\n",
      "[1,  1901] loss: 0.852\n",
      "[1,  1911] loss: 2.255\n",
      "[1,  1921] loss: 0.673\n",
      "[1,  1931] loss: 0.639\n",
      "[1,  1941] loss: 0.507\n",
      "[1,  1951] loss: 0.192\n",
      "[1,  1961] loss: 0.506\n",
      "[1,  1971] loss: 1.043\n",
      "[1,  1981] loss: 0.713\n",
      "[1,  1991] loss: 0.478\n",
      "[1,  2001] loss: 0.608\n",
      "[1,  2011] loss: 0.874\n",
      "[1,  2021] loss: 0.396\n",
      "[1,  2031] loss: 0.100\n",
      "[1,  2041] loss: 0.620\n",
      "[1,  2051] loss: 0.357\n",
      "[1,  2061] loss: 0.776\n",
      "[1,  2071] loss: 0.825\n",
      "[1,  2081] loss: 0.534\n",
      "[1,  2091] loss: 0.539\n",
      "[1,  2101] loss: 0.529\n",
      "[1,  2111] loss: 0.287\n",
      "[1,  2121] loss: 0.961\n",
      "[1,  2131] loss: 0.368\n",
      "[1,  2141] loss: 0.593\n",
      "[1,  2151] loss: 2.308\n",
      "[1,  2161] loss: 0.322\n",
      "[1,  2171] loss: 0.281\n",
      "[1,  2181] loss: 0.721\n",
      "[1,  2191] loss: 0.578\n",
      "[1,  2201] loss: 1.044\n",
      "[1,  2211] loss: 0.370\n",
      "[1,  2221] loss: 0.622\n",
      "[1,  2231] loss: 0.569\n",
      "[1,  2241] loss: 0.433\n",
      "[1,  2251] loss: 0.167\n",
      "[1,  2261] loss: 0.244\n",
      "[1,  2271] loss: 0.521\n",
      "[1,  2281] loss: 0.686\n",
      "[1,  2291] loss: 0.316\n",
      "[1,  2301] loss: 0.119\n",
      "[1,  2311] loss: 0.542\n",
      "[1,  2321] loss: 0.112\n",
      "[1,  2331] loss: 0.643\n",
      "[1,  2341] loss: 0.144\n",
      "[1,  2351] loss: 0.496\n",
      "[1,  2361] loss: 1.102\n",
      "[1,  2371] loss: 0.444\n",
      "[1,  2381] loss: 0.252\n",
      "[1,  2391] loss: 0.248\n",
      "[1,  2401] loss: 0.212\n",
      "[1,  2411] loss: 0.121\n",
      "[1,  2421] loss: 1.517\n",
      "[1,  2431] loss: 0.540\n",
      "[1,  2441] loss: 1.274\n",
      "[1,  2451] loss: 0.280\n",
      "[1,  2461] loss: 1.477\n",
      "[1,  2471] loss: 0.564\n",
      "[1,  2481] loss: 0.293\n",
      "[1,  2491] loss: 0.617\n",
      "[1,  2501] loss: 0.546\n",
      "[1,  2511] loss: 0.746\n",
      "[1,  2521] loss: 0.227\n",
      "[1,  2531] loss: 0.435\n",
      "[1,  2541] loss: 0.158\n",
      "[1,  2551] loss: 0.786\n",
      "[1,  2561] loss: 0.485\n",
      "[1,  2571] loss: 0.346\n",
      "[1,  2581] loss: 1.002\n",
      "[1,  2591] loss: 0.335\n",
      "[1,  2601] loss: 0.155\n",
      "[1,  2611] loss: 0.528\n",
      "[1,  2621] loss: 0.427\n",
      "[1,  2631] loss: 0.500\n",
      "[1,  2641] loss: 0.122\n",
      "[1,  2651] loss: 1.227\n",
      "[1,  2661] loss: 0.258\n",
      "[1,  2671] loss: 0.450\n",
      "[1,  2681] loss: 0.870\n",
      "[1,  2691] loss: 1.774\n",
      "[1,  2701] loss: 1.119\n",
      "[1,  2711] loss: 0.530\n",
      "[1,  2721] loss: 0.285\n",
      "[1,  2731] loss: 0.714\n",
      "[1,  2741] loss: 1.555\n",
      "[1,  2751] loss: 0.393\n",
      "[1,  2761] loss: 0.945\n",
      "[1,  2771] loss: 0.721\n",
      "[1,  2781] loss: 0.096\n",
      "[1,  2791] loss: 0.505\n",
      "[1,  2801] loss: 1.266\n",
      "[1,  2811] loss: 0.412\n",
      "[1,  2821] loss: 0.525\n",
      "[1,  2831] loss: 0.311\n",
      "[1,  2841] loss: 0.244\n",
      "[1,  2851] loss: 1.185\n",
      "[1,  2861] loss: 0.276\n",
      "[1,  2871] loss: 0.108\n",
      "[1,  2881] loss: 0.076\n",
      "[1,  2891] loss: 0.379\n",
      "[1,  2901] loss: 1.202\n",
      "[1,  2911] loss: 0.394\n",
      "[1,  2921] loss: 0.577\n",
      "[1,  2931] loss: 1.133\n",
      "[1,  2941] loss: 0.248\n",
      "[1,  2951] loss: 0.361\n",
      "[1,  2961] loss: 0.496\n",
      "[1,  2971] loss: 1.096\n",
      "[1,  2981] loss: 0.752\n",
      "[1,  2991] loss: 0.459\n",
      "[1,  3001] loss: 0.413\n",
      "[1,  3011] loss: 0.358\n",
      "[1,  3021] loss: 0.244\n",
      "[1,  3031] loss: 0.236\n",
      "[1,  3041] loss: 0.450\n",
      "[1,  3051] loss: 1.263\n",
      "[1,  3061] loss: 0.557\n",
      "[1,  3071] loss: 0.548\n",
      "[1,  3081] loss: 0.135\n",
      "[1,  3091] loss: 0.414\n",
      "[1,  3101] loss: 0.582\n",
      "[1,  3111] loss: 0.482\n",
      "[1,  3121] loss: 0.239\n",
      "[1,  3131] loss: 0.261\n",
      "[1,  3141] loss: 0.574\n",
      "[1,  3151] loss: 0.348\n",
      "[1,  3161] loss: 0.760\n",
      "[1,  3171] loss: 0.448\n",
      "[1,  3181] loss: 0.391\n",
      "[1,  3191] loss: 1.292\n",
      "[1,  3201] loss: 0.565\n",
      "[1,  3211] loss: 1.099\n",
      "[1,  3221] loss: 0.317\n",
      "[1,  3231] loss: 1.010\n",
      "[1,  3241] loss: 1.041\n",
      "[1,  3251] loss: 0.998\n",
      "[1,  3261] loss: 0.828\n",
      "[1,  3271] loss: 0.147\n",
      "[1,  3281] loss: 0.280\n",
      "[1,  3291] loss: 2.076\n",
      "[1,  3301] loss: 0.888\n",
      "[1,  3311] loss: 0.266\n",
      "[1,  3321] loss: 0.650\n",
      "[1,  3331] loss: 0.104\n",
      "[1,  3341] loss: 0.652\n",
      "[1,  3351] loss: 1.040\n",
      "[1,  3361] loss: 0.056\n",
      "[1,  3371] loss: 0.206\n",
      "[1,  3381] loss: 0.735\n",
      "[1,  3391] loss: 0.468\n",
      "[1,  3401] loss: 0.585\n",
      "[1,  3411] loss: 0.143\n",
      "[1,  3421] loss: 0.336\n",
      "[1,  3431] loss: 0.306\n",
      "[1,  3441] loss: 0.092\n",
      "[1,  3451] loss: 0.065\n",
      "[1,  3461] loss: 0.504\n",
      "[1,  3471] loss: 0.643\n",
      "[1,  3481] loss: 0.204\n",
      "[1,  3491] loss: 0.165\n",
      "[1,  3501] loss: 0.411\n",
      "[1,  3511] loss: 0.372\n",
      "[1,  3521] loss: 0.261\n",
      "[1,  3531] loss: 0.265\n",
      "[1,  3541] loss: 0.453\n",
      "[1,  3551] loss: 0.243\n",
      "[1,  3561] loss: 0.234\n",
      "[1,  3571] loss: 0.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  3581] loss: 0.276\n",
      "[1,  3591] loss: 1.085\n",
      "[1,  3601] loss: 0.174\n",
      "[1,  3611] loss: 0.272\n",
      "[1,  3621] loss: 0.210\n",
      "[1,  3631] loss: 1.074\n",
      "[1,  3641] loss: 0.177\n",
      "[1,  3651] loss: 0.404\n",
      "[1,  3661] loss: 0.048\n",
      "[1,  3671] loss: 0.665\n",
      "[1,  3681] loss: 0.840\n",
      "[1,  3691] loss: 0.641\n",
      "[1,  3701] loss: 0.686\n",
      "[1,  3711] loss: 0.055\n",
      "[1,  3721] loss: 0.932\n",
      "[1,  3731] loss: 0.170\n",
      "[1,  3741] loss: 0.190\n",
      "[1,  3751] loss: 0.092\n",
      "[1,  3761] loss: 0.809\n",
      "[1,  3771] loss: 0.255\n",
      "[1,  3781] loss: 1.071\n",
      "[1,  3791] loss: 0.041\n",
      "[1,  3801] loss: 0.502\n",
      "[1,  3811] loss: 0.122\n",
      "[1,  3821] loss: 1.041\n",
      "[1,  3831] loss: 0.486\n",
      "[1,  3841] loss: 0.093\n",
      "[1,  3851] loss: 0.106\n",
      "[1,  3861] loss: 0.572\n",
      "[1,  3871] loss: 1.887\n",
      "[1,  3881] loss: 0.108\n",
      "[1,  3891] loss: 0.219\n",
      "[1,  3901] loss: 0.827\n",
      "[1,  3911] loss: 0.474\n",
      "[1,  3921] loss: 0.166\n",
      "[1,  3931] loss: 0.099\n",
      "[1,  3941] loss: 0.837\n",
      "[1,  3951] loss: 0.398\n",
      "[1,  3961] loss: 1.180\n",
      "[1,  3971] loss: 0.351\n",
      "[1,  3981] loss: 0.081\n",
      "[1,  3991] loss: 0.416\n",
      "[1,  4001] loss: 0.274\n",
      "[1,  4011] loss: 0.433\n",
      "[1,  4021] loss: 0.262\n",
      "[1,  4031] loss: 0.130\n",
      "[1,  4041] loss: 0.446\n",
      "[1,  4051] loss: 0.386\n",
      "[1,  4061] loss: 0.965\n",
      "[1,  4071] loss: 0.378\n",
      "[1,  4081] loss: 0.320\n",
      "[1,  4091] loss: 0.221\n",
      "[1,  4101] loss: 0.654\n",
      "[1,  4111] loss: 0.170\n",
      "[1,  4121] loss: 0.250\n",
      "[1,  4131] loss: 0.504\n",
      "[1,  4141] loss: 0.372\n",
      "[1,  4151] loss: 0.451\n",
      "[1,  4161] loss: 0.616\n",
      "[1,  4171] loss: 0.553\n",
      "[1,  4181] loss: 0.344\n",
      "[1,  4191] loss: 0.262\n",
      "[1,  4201] loss: 0.409\n",
      "[1,  4211] loss: 0.533\n",
      "[1,  4221] loss: 0.231\n",
      "[1,  4231] loss: 0.127\n",
      "[1,  4241] loss: 0.241\n",
      "[1,  4251] loss: 0.398\n",
      "[1,  4261] loss: 0.110\n",
      "[1,  4271] loss: 0.554\n",
      "[1,  4281] loss: 0.068\n",
      "[1,  4291] loss: 0.012\n",
      "[1,  4301] loss: 0.761\n",
      "[1,  4311] loss: 0.447\n",
      "[1,  4321] loss: 0.117\n",
      "[1,  4331] loss: 1.026\n",
      "[1,  4341] loss: 0.096\n",
      "[1,  4351] loss: 0.513\n",
      "[1,  4361] loss: 0.469\n",
      "[1,  4371] loss: 0.249\n",
      "[1,  4381] loss: 0.467\n",
      "[1,  4391] loss: 0.054\n",
      "[1,  4401] loss: 0.051\n",
      "[1,  4411] loss: 0.290\n",
      "[1,  4421] loss: 0.399\n",
      "[1,  4431] loss: 0.450\n",
      "[1,  4441] loss: 0.365\n",
      "[1,  4451] loss: 0.294\n",
      "[1,  4461] loss: 0.382\n",
      "[1,  4471] loss: 0.582\n",
      "[1,  4481] loss: 0.346\n",
      "[1,  4491] loss: 0.165\n",
      "[1,  4501] loss: 4.345\n",
      "[1,  4511] loss: 0.433\n",
      "[1,  4521] loss: 0.202\n",
      "[1,  4531] loss: 0.232\n",
      "[1,  4541] loss: 0.127\n",
      "[1,  4551] loss: 0.094\n",
      "[1,  4561] loss: 0.315\n",
      "[1,  4571] loss: 0.517\n",
      "[1,  4581] loss: 0.918\n",
      "[1,  4591] loss: 0.750\n",
      "[1,  4601] loss: 0.289\n",
      "[1,  4611] loss: 0.058\n",
      "[1,  4621] loss: 0.099\n",
      "[1,  4631] loss: 0.124\n",
      "[1,  4641] loss: 0.222\n",
      "[1,  4651] loss: 0.642\n",
      "[1,  4661] loss: 0.547\n",
      "[1,  4671] loss: 0.398\n",
      "[1,  4681] loss: 0.180\n",
      "[1,  4691] loss: 0.652\n",
      "[1,  4701] loss: 0.095\n",
      "[1,  4711] loss: 0.898\n",
      "[1,  4721] loss: 0.730\n",
      "[1,  4731] loss: 0.184\n",
      "[1,  4741] loss: 1.465\n",
      "[1,  4751] loss: 0.141\n",
      "[1,  4761] loss: 0.343\n",
      "[1,  4771] loss: 0.254\n",
      "[1,  4781] loss: 0.084\n",
      "[1,  4791] loss: 0.063\n",
      "[1,  4801] loss: 0.138\n",
      "[1,  4811] loss: 0.086\n",
      "[1,  4821] loss: 0.131\n",
      "[1,  4831] loss: 0.751\n",
      "[1,  4841] loss: 0.434\n",
      "[1,  4851] loss: 0.284\n",
      "[1,  4861] loss: 0.983\n",
      "[1,  4871] loss: 0.648\n",
      "[1,  4881] loss: 0.200\n",
      "[1,  4891] loss: 0.014\n",
      "[1,  4901] loss: 0.322\n",
      "[1,  4911] loss: 0.583\n",
      "[1,  4921] loss: 0.309\n",
      "[1,  4931] loss: 0.456\n",
      "[1,  4941] loss: 0.373\n",
      "[1,  4951] loss: 0.374\n",
      "[1,  4961] loss: 0.123\n",
      "[1,  4971] loss: 0.185\n",
      "[1,  4981] loss: 0.277\n",
      "[1,  4991] loss: 0.065\n",
      "[1,  5001] loss: 0.385\n",
      "[1,  5011] loss: 0.096\n",
      "[1,  5021] loss: 0.375\n",
      "[1,  5031] loss: 0.358\n",
      "[1,  5041] loss: 0.157\n",
      "[1,  5051] loss: 0.238\n",
      "[1,  5061] loss: 0.303\n",
      "[1,  5071] loss: 0.151\n",
      "[1,  5081] loss: 0.597\n",
      "[1,  5091] loss: 0.242\n",
      "[1,  5101] loss: 0.536\n",
      "[1,  5111] loss: 0.197\n",
      "[1,  5121] loss: 0.178\n",
      "[1,  5131] loss: 0.012\n",
      "[1,  5141] loss: 0.338\n",
      "[1,  5151] loss: 0.284\n",
      "[1,  5161] loss: 0.122\n",
      "[1,  5171] loss: 0.096\n",
      "[1,  5181] loss: 0.189\n",
      "[1,  5191] loss: 0.457\n",
      "[1,  5201] loss: 0.185\n",
      "[1,  5211] loss: 0.070\n",
      "[1,  5221] loss: 0.328\n",
      "[1,  5231] loss: 0.819\n",
      "[1,  5241] loss: 0.481\n",
      "[1,  5251] loss: 0.197\n",
      "[1,  5261] loss: 0.307\n",
      "[1,  5271] loss: 0.210\n",
      "[1,  5281] loss: 0.144\n",
      "[1,  5291] loss: 0.194\n",
      "[1,  5301] loss: 0.327\n",
      "[1,  5311] loss: 0.154\n",
      "[1,  5321] loss: 0.183\n",
      "[1,  5331] loss: 0.756\n",
      "[1,  5341] loss: 0.652\n",
      "[1,  5351] loss: 0.135\n",
      "[1,  5361] loss: 0.228\n",
      "[1,  5371] loss: 0.774\n",
      "[1,  5381] loss: 0.121\n",
      "[1,  5391] loss: 0.108\n",
      "[1,  5401] loss: 0.158\n",
      "[1,  5411] loss: 0.566\n",
      "[1,  5421] loss: 0.124\n",
      "[1,  5431] loss: 0.071\n",
      "[1,  5441] loss: 1.260\n",
      "[1,  5451] loss: 0.029\n",
      "[1,  5461] loss: 0.165\n",
      "[1,  5471] loss: 0.009\n",
      "[1,  5481] loss: 0.182\n",
      "[1,  5491] loss: 1.024\n",
      "[1,  5501] loss: 0.472\n",
      "[1,  5511] loss: 0.040\n",
      "[1,  5521] loss: 0.532\n",
      "[1,  5531] loss: 0.760\n",
      "[1,  5541] loss: 0.234\n",
      "[1,  5551] loss: 0.116\n",
      "[1,  5561] loss: 0.499\n",
      "[1,  5571] loss: 0.172\n",
      "[1,  5581] loss: 0.043\n",
      "[1,  5591] loss: 0.146\n",
      "[1,  5601] loss: 0.591\n",
      "[1,  5611] loss: 0.110\n",
      "[1,  5621] loss: 0.056\n",
      "[1,  5631] loss: 0.217\n",
      "[1,  5641] loss: 0.343\n",
      "[1,  5651] loss: 0.019\n",
      "[1,  5661] loss: 1.171\n",
      "[1,  5671] loss: 0.023\n",
      "[1,  5681] loss: 0.377\n",
      "[1,  5691] loss: 0.144\n",
      "[1,  5701] loss: 0.037\n",
      "[1,  5711] loss: 0.874\n",
      "[1,  5721] loss: 0.428\n",
      "[1,  5731] loss: 0.262\n",
      "[1,  5741] loss: 0.756\n",
      "[1,  5751] loss: 0.074\n",
      "[1,  5761] loss: 0.047\n",
      "[1,  5771] loss: 0.126\n",
      "[1,  5781] loss: 0.021\n",
      "[1,  5791] loss: 0.128\n",
      "[1,  5801] loss: 0.145\n",
      "[1,  5811] loss: 0.781\n",
      "[1,  5821] loss: 0.134\n",
      "[1,  5831] loss: 0.300\n",
      "[1,  5841] loss: 0.053\n",
      "[1,  5851] loss: 0.222\n",
      "[1,  5861] loss: 0.077\n",
      "[1,  5871] loss: 0.110\n",
      "[1,  5881] loss: 0.021\n",
      "[1,  5891] loss: 0.092\n",
      "[1,  5901] loss: 0.203\n",
      "[1,  5911] loss: 0.512\n",
      "[1,  5921] loss: 0.049\n",
      "[1,  5931] loss: 0.234\n",
      "[1,  5941] loss: 0.504\n",
      "[1,  5951] loss: 0.194\n",
      "[1,  5961] loss: 1.074\n",
      "[1,  5971] loss: 0.147\n",
      "[1,  5981] loss: 0.014\n",
      "[1,  5991] loss: 0.468\n",
      "[1,  6001] loss: 0.211\n",
      "[1,  6011] loss: 0.111\n",
      "[1,  6021] loss: 0.166\n",
      "[1,  6031] loss: 0.532\n",
      "[1,  6041] loss: 0.710\n",
      "[1,  6051] loss: 0.592\n",
      "[1,  6061] loss: 0.033\n",
      "[1,  6071] loss: 2.124\n",
      "[1,  6081] loss: 0.382\n",
      "[1,  6091] loss: 0.212\n",
      "[1,  6101] loss: 0.098\n",
      "[1,  6111] loss: 0.209\n",
      "[1,  6121] loss: 0.139\n",
      "[1,  6131] loss: 0.346\n",
      "[1,  6141] loss: 0.009\n",
      "[1,  6151] loss: 0.185\n",
      "[1,  6161] loss: 0.100\n",
      "[1,  6171] loss: 0.087\n",
      "[1,  6181] loss: 0.209\n",
      "[1,  6191] loss: 0.373\n",
      "[1,  6201] loss: 0.163\n",
      "[1,  6211] loss: 0.083\n",
      "[1,  6221] loss: 0.134\n",
      "[1,  6231] loss: 0.029\n",
      "[1,  6241] loss: 0.260\n",
      "[1,  6251] loss: 0.369\n",
      "[1,  6261] loss: 0.137\n",
      "[1,  6271] loss: 0.016\n",
      "[1,  6281] loss: 2.298\n",
      "[1,  6291] loss: 0.212\n",
      "[1,  6301] loss: 0.180\n",
      "[1,  6311] loss: 0.312\n",
      "[1,  6321] loss: 0.339\n",
      "[1,  6331] loss: 0.730\n",
      "[1,  6341] loss: 0.050\n",
      "[1,  6351] loss: 0.628\n",
      "[1,  6361] loss: 0.332\n",
      "[1,  6371] loss: 0.219\n",
      "[1,  6381] loss: 0.365\n",
      "[1,  6391] loss: 0.229\n",
      "[1,  6401] loss: 0.288\n",
      "[1,  6411] loss: 0.047\n",
      "[1,  6421] loss: 0.229\n",
      "[1,  6431] loss: 0.165\n",
      "[1,  6441] loss: 0.446\n",
      "[1,  6451] loss: 0.392\n",
      "[1,  6461] loss: 0.273\n",
      "[1,  6471] loss: 1.248\n",
      "[1,  6481] loss: 0.290\n",
      "[1,  6491] loss: 0.380\n",
      "[1,  6501] loss: 0.310\n",
      "[1,  6511] loss: 0.269\n",
      "[1,  6521] loss: 0.342\n",
      "[1,  6531] loss: 0.264\n",
      "[1,  6541] loss: 0.178\n",
      "[1,  6551] loss: 0.107\n",
      "[1,  6561] loss: 0.517\n",
      "[1,  6571] loss: 0.322\n",
      "[1,  6581] loss: 0.346\n",
      "[1,  6591] loss: 0.612\n",
      "[1,  6601] loss: 0.070\n",
      "[1,  6611] loss: 0.065\n",
      "[1,  6621] loss: 0.045\n",
      "[1,  6631] loss: 0.125\n",
      "[1,  6641] loss: 0.317\n",
      "[1,  6651] loss: 0.542\n",
      "[1,  6661] loss: 0.422\n",
      "[1,  6671] loss: 0.157\n",
      "[1,  6681] loss: 0.023\n",
      "[1,  6691] loss: 0.156\n",
      "[1,  6701] loss: 0.766\n",
      "[1,  6711] loss: 0.272\n",
      "[1,  6721] loss: 0.088\n",
      "[1,  6731] loss: 0.117\n",
      "[1,  6741] loss: 0.353\n",
      "[1,  6751] loss: 0.187\n",
      "[1,  6761] loss: 0.659\n",
      "[1,  6771] loss: 0.315\n",
      "[1,  6781] loss: 0.039\n",
      "[1,  6791] loss: 0.671\n",
      "[1,  6801] loss: 0.243\n",
      "[1,  6811] loss: 1.237\n",
      "[1,  6821] loss: 0.247\n",
      "[1,  6831] loss: 0.063\n",
      "[1,  6841] loss: 0.641\n",
      "[1,  6851] loss: 0.079\n",
      "[1,  6861] loss: 0.880\n",
      "[1,  6871] loss: 0.217\n",
      "[1,  6881] loss: 0.017\n",
      "[1,  6891] loss: 0.222\n",
      "[1,  6901] loss: 0.228\n",
      "[1,  6911] loss: 0.127\n",
      "[1,  6921] loss: 0.007\n",
      "[1,  6931] loss: 0.080\n",
      "[1,  6941] loss: 0.268\n",
      "[1,  6951] loss: 0.106\n",
      "[1,  6961] loss: 0.262\n",
      "[1,  6971] loss: 0.051\n",
      "[1,  6981] loss: 0.598\n",
      "[1,  6991] loss: 0.263\n",
      "[1,  7001] loss: 0.250\n",
      "[1,  7011] loss: 0.101\n",
      "[1,  7021] loss: 0.130\n",
      "[1,  7031] loss: 0.172\n",
      "[1,  7041] loss: 0.256\n",
      "[1,  7051] loss: 0.796\n",
      "[1,  7061] loss: 0.753\n",
      "[1,  7071] loss: 0.286\n",
      "[1,  7081] loss: 0.274\n",
      "[1,  7091] loss: 0.221\n",
      "[1,  7101] loss: 1.196\n",
      "[1,  7111] loss: 0.547\n",
      "[1,  7121] loss: 0.223\n",
      "[1,  7131] loss: 0.216\n",
      "[1,  7141] loss: 0.009\n",
      "[1,  7151] loss: 0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  7161] loss: 0.878\n",
      "[1,  7171] loss: 0.678\n",
      "[1,  7181] loss: 0.114\n",
      "[1,  7191] loss: 0.073\n",
      "[1,  7201] loss: 0.266\n",
      "[1,  7211] loss: 0.085\n",
      "[1,  7221] loss: 0.365\n",
      "[1,  7231] loss: 0.539\n",
      "[1,  7241] loss: 0.743\n",
      "[1,  7251] loss: 0.146\n",
      "[1,  7261] loss: 0.171\n",
      "[1,  7271] loss: 0.015\n",
      "[1,  7281] loss: 0.026\n",
      "[1,  7291] loss: 0.087\n",
      "[1,  7301] loss: 0.096\n",
      "[1,  7311] loss: 0.110\n",
      "[1,  7321] loss: 0.005\n",
      "[1,  7331] loss: 0.862\n",
      "[1,  7341] loss: 0.423\n",
      "[1,  7351] loss: 0.255\n",
      "[1,  7361] loss: 0.762\n",
      "[1,  7371] loss: 0.117\n",
      "[1,  7381] loss: 0.214\n",
      "[1,  7391] loss: 0.152\n",
      "[1,  7401] loss: 0.278\n",
      "[1,  7411] loss: 1.064\n",
      "[1,  7421] loss: 0.307\n",
      "[1,  7431] loss: 0.244\n",
      "[1,  7441] loss: 0.060\n",
      "[1,  7451] loss: 0.615\n",
      "[1,  7461] loss: 0.213\n",
      "[1,  7471] loss: 0.201\n",
      "[1,  7481] loss: 0.635\n",
      "[1,  7491] loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs): \n",
    "\n",
    "    # enumerate can be used to output iteration index i, as well as the data \n",
    "    for i, (data, labels) in enumerate(train_loader, 0):\n",
    "        \n",
    "        # Task 3.1 load data and labels to device\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # --------------------------------------------------task 2 ------------------------------------------------------------\n",
    "        # 3.2: implement training iteration here\n",
    "        # clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #3.3 feed the input and acquire the output from network\n",
    "        outputs = net(data)\n",
    "\n",
    "        #3.4 calculating the predicted and the expected loss\n",
    "        loss = loss_fun(outputs, labels)\n",
    "\n",
    "        #3.5 compute the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        #3.6 update the parameters\n",
    "        optimizer.step()\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # print statistics\n",
    "        ce_loss = loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, ce_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding PyTorch Hooks\n",
    "\n",
    "Hooks are functions with which you can modify or return different sub-components of your network. Returning the outputs of different layers (i.e. the activations - the goal of this section) is thus an excellent example. In general the point is that they are simply functions that are run whenever the `forward` or `backward` function of a `torch.Autograd.Function` object is called i.e. the `grad_fn` of a tensor (discussed in Lecture 2). \n",
    "\n",
    "You can register a function on a `Module` or a `Tensor` and are defined apriori as forward hooks or a backward hooks. Depending on which they are they will either be executed when a forward call is executed (forward hook) or a backward pass in run (backward hook). \n",
    "\n",
    "Let's look at using a forward and backward hook just for debugging (and thus printing) the output of a function (example taken from [the official PyTorch tutorials](https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html))\n",
    "\n",
    "A forward hook has the general form:\n",
    "\n",
    "```python\n",
    "model.conv_name.register_forward_hook(hook_function(module, input,output))\n",
    "```\n",
    "\n",
    "And a backward hook has a general form\n",
    "\n",
    "```python\n",
    "model.conv_name.register_backward_hook(hook_function(module,grad_input,grad_output))\n",
    "```\n",
    "\n",
    "Say we are interested in layer $l$. A forward hook function can look at inputs and outputs the layer during the forward pass i.e. the input activation from layer $l-1$ and the output activation for layer $l$. The backward pass can look at the inputs and outputs to the backward pass i.e. the incoming (input) gradient with respect to the parameters from the layer above $l+1$ and the outgoing (output) gradient with respect to the parameters of the current layer $l$.\n",
    "\n",
    "Thus if we wish to print information about the input and output activations we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([8, 1, 28, 28])\n",
      "output size: torch.Size([8, 10, 26, 26])\n",
      "output norm: tensor(145.6300, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def printnorm(self, input, output):\n",
    "    # input is a tuple of packed inputs\n",
    "    # output is a Tensor. output.data is the Tensor we are interested\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('')\n",
    "    print('input: ', type(input))\n",
    "    print('input[0]: ', type(input[0]))\n",
    "    print('output: ', type(output))\n",
    "    print('')\n",
    "    print('input size:', input[0].size())\n",
    "    print('output size:', output.data.size())\n",
    "    print('output norm:', output.data.norm())\n",
    "\n",
    "\n",
    "print_forward_handle=net.conv1.register_forward_hook(printnorm)\n",
    "\n",
    "#--------------------- ---- ----------------------------#\n",
    "# performing forward pass\n",
    "out = net(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to return backward pass outputs and inputs use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([8, 1, 28, 28])\n",
      "output size: torch.Size([8, 10, 26, 26])\n",
      "output norm: tensor(145.6300, device='cuda:0')\n",
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([8, 10, 13, 13])\n",
      "grad_output size: torch.Size([8, 20, 11, 11])\n",
      "grad_input norm: tensor(0.1650, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "    print('Inside class:' + self.__class__.__name__)\n",
    "    print('')\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output[0]))\n",
    "    print('')\n",
    "    print('grad_input size:', grad_input[0].size())\n",
    "    print('grad_output size:', grad_output[0].size())\n",
    "    print('grad_input norm:', grad_input[0].norm())\n",
    "\n",
    "\n",
    "print_backward_handle=net.conv2.register_backward_hook(printgradnorm)\n",
    "\n",
    "out = net(data)\n",
    "err = loss_fun(out,labels)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By naming your hooks e.g.\n",
    "\n",
    "```\n",
    "print_forward_handle=model.conv1.register_forward_hook(printnorm)\n",
    "\n",
    "```\n",
    "it is possible to remove them as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_forward_handle.remove()\n",
    "print_backward_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on hooks can be found in https://www.kaggle.com/sironghuang/understanding-pytorch-hooks and https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/ should you be interested.\n",
    "\n",
    "### Task 2.1. Register hook to get network activations for a given input\n",
    "\n",
    "Thus hooks are functions that can be applied to the inputs and outputs of our forwards and backwards layers and as such we can use them to return the activations of each layer.\n",
    "\n",
    "**To do ** Modify the below code to use the hook function `get_activation` to save the activation tensor for the first convolutional layer of your network:\n",
    "\n",
    "We define the function for you. All you need to do is:\n",
    "\n",
    "1. Create a (forward or backward) hook \n",
    "2. Pass it the hook function `get_activation`. Here, the argument `name` is expecting the name of the layer. Yhe name is what you call the variable in your `__init__` function i.e. `conv1,pool1... ` etc in this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set up the hook for activations\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "#--------------------- Task 2.1 ----------------------------#\n",
    "# Create a hook on the first convolutional layer\n",
    "#\n",
    "net.conv1.register_forward_hook(get_activation('conv1'))\n",
    "\n",
    "#--------------------- ---- ----------------------------#\n",
    "data, _ = mnist_train_dataset[0]\n",
    "data = data.to(device)\n",
    "data.unsqueeze_(0)\n",
    "\n",
    "# Run through model again, to save the relavent activation\n",
    "output = net(data)\n",
    "\n",
    "# Visualize the activation\n",
    "act = activation['conv1'].squeeze()\n",
    "\n",
    "print(act.size(0),min(act.size(0),10))\n",
    "fig, axarr = plt.subplots(1,min(act.size(0),10),figsize=(20,20))\n",
    "n_plots=min(act.size(0),10)\n",
    "for idx in np.arange(n_plots):\n",
    "    axarr[idx].imshow(act.cpu()[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Visualise an activation of another convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------- Task 2 --------------------------------------------------------\n",
    "# write code here\n",
    "\n",
    "# Register the hook with the convolutional layer of interest\n",
    "net.conv2.register_forward_hook(get_activation('conv2'))\n",
    "\n",
    "# Run through model again, to save the relavent activation\n",
    "output = net(data)\n",
    "\n",
    "# Visualize the activation\n",
    "act = activation['conv2'].squeeze()\n",
    "fig, axarr = plt.subplots(1,min(act.size(0),10),figsize=(20,20))\n",
    "n_plots=min(act.size(0),10)\n",
    "for idx in np.arange(n_plots):\n",
    "    axarr[idx].imshow(act.cpu()[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3 Explain \n",
    "\n",
    "1. How can you interpret the activations of different layers? What does that mean with respect to the relative importance of different parts of your image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualisation and Attribution\n",
    "\n",
    "When it comes to techniques for visualising and interpretting what an individual network is learning there are two main sub-fields: feature visualisation and feature attribution:\n",
    "\n",
    "### Feature visualisation\n",
    "\n",
    "This represents the category of methods which attempt to understand through backwards designing inputs, which maximize the activation of individual units (neurons/channels/layers) of networks, whereas\n",
    "\n",
    "### Feature attribution (saliency mapping) \n",
    "Reflect methods which seek to backpropagate maps which highlight which parts of an image are important for activation of a specific unit\n",
    "\n",
    "We start by discussing saliency mapping though occlusion as this can be meaningfully tested with MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution (saliency mapping)\n",
    "\n",
    "### Exercise 3: Saliency by occlusion\n",
    "\n",
    "In a related sense we will now try to interpret what our network is doing by occluding different parts/proportions of our image to see what impact this has on classification. Let's return a batch of images from our validation DataLoader and visualise them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_MNIST(images,labels):\n",
    "    rows = 2\n",
    "    columns = 4\n",
    "    classes = ('0', '1', '2', '3',\n",
    "          '4', '5', '6', '7', '8', '9')\n",
    "    # plot y_score - true label (t) vs predicted label (p)\n",
    "    fig2 = plt.figure()\n",
    "    for i in range(8):\n",
    "        fig2.add_subplot(rows, columns, i+1)\n",
    "        plt.title('t: ' + classes[labels[i].cpu()])\n",
    "        img = images[i] / 2 + 0.5     # this is to unnormalize the image\n",
    "        img = torchvision.transforms.ToPILImage()(img.cpu())\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "im_batch, lab_batch=next(iter(test_loader)) # view one batch\n",
    "im_batch = im_batch.to(device)\n",
    "plot_MNIST(im_batch,lab_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is run inference on the images without occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions =  tensor([8, 0, 0, 3, 2, 6, 1, 7], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#running inference on the images without occlusion\n",
    "\n",
    "# pretrained model\n",
    "outputs = net(im_batch)\n",
    "\n",
    "# #passing the outputs through softmax to interpret them as probability\n",
    "# outputs = nn.functional.softmax(outputs, dim = 1)\n",
    "# print(outputs)\n",
    "\n",
    "#assigning the predicted label from the maximum softmax output\n",
    "prob_no_occ, pred = torch.max(outputs.data, 1)\n",
    "\n",
    "#get the first item\n",
    "prob_no_occ = prob_no_occ[0].item()\n",
    "\n",
    "print('Predictions = ', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to be able to do is zero (or grey out) block of pixels in our image. \n",
    "\n",
    "Similar to the patch based selection that we saw in lecture 4, we are constrained to select only patches which fit in our image (which means that number of points on which we can start each patch is constrained by the width and height of our patch). This means that the output size will be smaller than the original image size by a factor of: (h-p)/s; where, h is the height (or width), p is the patch size and s is the chosen stride.\n",
    "\n",
    "Let's create an image with an occluded patch in the centre. We start by first creating a copy of our image using `image.detach().clone()`.  Here, \" `tensor.detach()` creates a tensor that shares storage with the original tensor, but for which `requires_grad=False`; `tensor.clone()` creates a copy of tensor that imitates the original tensor's `requires_grad` field. Thus `detach()` should be used to remove a tensor from a computation graph, and `clone()` copies the tensor while still keeping the copy as a part of the computation graph it came from. \" quoted from https://discuss.pytorch.org/t/clone-and-detach-in-v0-4-0/16861.\n",
    "\n",
    "#### To do 3.1 Create a function which occuldes a patch from an image\n",
    "\n",
    "1. set all pixels of patch (starting at height: `heigh_start` and width: `width_start`, and of size: `patch_size` to 0.5\n",
    "2. Pass the oculded image through the network (`model`) to make a prediction\n",
    "3. Select the softmax output corresponding to the correct label for that image and print it out; \n",
    "  - note you will need to use `nn.functional.softmax()` on the output from your network in order to turn the log(softmax) output of the network back to a probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlude_image(image, model, height_start,width_start,patch_size):\n",
    "    ''' \n",
    "    Creates a copy of the image and occludes a patch \n",
    "    input:\n",
    "    image (Pytorch tensor): image to be occluded\n",
    "    model: Pytorch network model \n",
    "    height_start=starting index on height dimension\n",
    "    width_start=starting index on width dimension\n",
    "    patch_size: size of patch\n",
    "    \n",
    "    output: \n",
    "    probability\n",
    "    '''\n",
    "    occluded_image = im_batch[0].detach().clone()\n",
    "    height_end=height_start+patch_size\n",
    "    width_end=width_start+patch_size\n",
    "    occluded_image[:,height_start:height_end,width_start:width_end]=0.5\n",
    "    \n",
    "    output_occluded=net(occluded_image.unsqueeze(0))\n",
    "    occluded_prob=nn.functional.softmax(output_occluded, dim=1)[0,true_label]\n",
    "\n",
    "    \n",
    "    return occluded_prob, occluded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do 3.2 Compare  against prediction probability when the full image is used\n",
    "\n",
    "1. Get prediction probability when the full image is used and compare\n",
    "2. Compare against probability for different patch locations and sizes; plot the occluded and original image to help you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "True label=2; prediction probability for full image0.07124502956867218; prediction probability for occluded 0.0883224830031395\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_label=lab_batch[0].numpy()\n",
    "\n",
    "print(true_label)\n",
    "patch_size=20\n",
    "height_start=8\n",
    "width_start=8\n",
    "\n",
    "#--------------- Task 3.2.1 Estimate output of network for first image of the batch -----------------#\n",
    "# use nn.functional.softmax to return a probabiliyt\n",
    "output_full=net(im_batch[0].unsqueeze(0))\n",
    "full_prob=nn.functional.softmax(output_full,dim=1)[0,true_label]\n",
    "\n",
    "#--------------- Task 3.2.2 Estimate output of network for an occluded version of the same image -----------------#\n",
    "# use function defined above\n",
    "occluded_prob, occluded_image=occlude_image(im_batch, net, height_start,width_start,patch_size)\n",
    "\n",
    "print('True label={}; prediction probability for full image{}; prediction probability for occluded {}'\n",
    "      .format(true_label,full_prob, occluded_prob))\n",
    "\n",
    "# plot\n",
    "fig2 = plt.figure(figsize=(15,5))\n",
    "fig2.add_subplot(1, 2, 1)\n",
    "#displaying the image using seaborn heatmap and also setting the maximum value of gradient to probability\n",
    "img = torchvision.transforms.ToPILImage()(occluded_image[0].cpu())\n",
    "plt.imshow(img)\n",
    "fig2.add_subplot(1, 2, 2)\n",
    "img = torchvision.transforms.ToPILImage()(im_batch[0].cpu())\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate, creating patches across our entire image in order to create a heatmap which shows how big an impact a patch, centred on each pixel centre has.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to conduct occlusion experiments\n",
    "\n",
    "def occlusion(model, image, label, occ_size = 50, occ_stride = 50, occ_pixel = 0.5):\n",
    "    print(image.shape,label)\n",
    "    #get the width and height of the image\n",
    "    width, height = image.shape[-2], image.shape[-1]\n",
    "  \n",
    "    #setting the output image width and height\n",
    "    output_height = int(np.ceil((height-occ_size)/occ_stride))\n",
    "    output_width = int(np.ceil((width-occ_size)/occ_stride))\n",
    "    #create a white image of sizes we defined\n",
    "    heatmap = torch.zeros((output_height, output_width))\n",
    "    \n",
    "    #iterate all the pixels in each column\n",
    "    for h in range(0, height):\n",
    "        for w in range(0, width):\n",
    "            \n",
    "            h_start = h*occ_stride\n",
    "            w_start = w*occ_stride \n",
    "            h_end = min(height, h_start + occ_size)\n",
    "            w_end = min(width, w_start + occ_size)\n",
    "            \n",
    "            if (w_end) >= width or (h_end) >= height:\n",
    "                continue\n",
    "            \n",
    "            occluded_image = image.detach().clone()\n",
    "#             print(type(image),image.shape)\n",
    "            \n",
    "            #replacing all the pixel information in the image with occ_pixel(grey) in the specified location\n",
    "            occluded_image[:, :, w_start:w_end, h_start:h_end] = occ_pixel\n",
    "            \n",
    "            #run inference on modified image\n",
    "            output = model(occluded_image)\n",
    "            \n",
    "            # get the softmax output corresponding to the true label\n",
    "            prob = output.tolist()[0][label]\n",
    "            \n",
    "            #setting the heatmap location to probability value\n",
    "            heatmap[h, w] = prob \n",
    "\n",
    "    return heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8, device='cuda:0') <built-in method type of Tensor object at 0x7f4ac4791558>\n",
      "torch.Size([1, 1, 28, 28]) 2\n"
     ]
    }
   ],
   "source": [
    "print(pred[0],pred[0].type)\n",
    "image=im_batch[0].unsqueeze(0)\n",
    "heatmap = occlusion(net, image, lab_batch[0].item(),13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig2 = plt.figure(figsize=(15,5))\n",
    "fig2.add_subplot(1, 2, 1)\n",
    "#displaying the image using seaborn heatmap and also setting the maximum value of gradient to probability\n",
    "imgplot = sns.heatmap(heatmap, xticklabels=False, yticklabels=False, vmax=prob_no_occ)\n",
    "figure = imgplot.get_figure()    \n",
    "fig2.add_subplot(1, 2, 2)\n",
    "img = torchvision.transforms.ToPILImage()(image[0].cpu())\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "The web journal [Distill.pub](https://distill.pub/) is a particularly strong source of information for those interested in network visualisation. In partiocular [this article](https://distill.pub/2017/feature-visualization/) by Chris Olah has been a strong source of information for this section.\n",
    "\n",
    "### 3. CNN Layer Visualization\n",
    "\n",
    "We will go through the next examples using code from the following repository https://github.com/utkuozbulak/pytorch-cnn-visualizations, which implements several well known visualization techniques for deep learning networks.\n",
    "\n",
    "**CNN layer visualization** technique produces an image that minimizes the loss of a convolutional operation for a specific layer and filter - i.e. it learns the image that optimally activates a particular convolutional filter.\n",
    "\n",
    "D. Erhan, Y. Bengio, A. Courville, P. Vincent. Visualizing Higher-Layer Features of a Deep Network https://www.researchgate.net/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network\n",
    "\n",
    "**All the visualizations will be saved to** `/generated` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/cb19/.cache/torch/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 553433881/553433881 [01:40<00:00, 5513680.82it/s] \n"
     ]
    }
   ],
   "source": [
    "# load vgg model, and extract layers from the features modules only\n",
    "pretrained_model = models.vgg16(pretrained=True).features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss: 0.96\n",
      "Iteration: 2 Loss: 0.44\n",
      "Iteration: 3 Loss: -3.77\n",
      "Iteration: 4 Loss: -7.36\n",
      "Iteration: 5 Loss: -10.98\n",
      "Iteration: 6 Loss: -14.29\n",
      "Iteration: 7 Loss: -17.33\n",
      "Iteration: 8 Loss: -20.20\n",
      "Iteration: 9 Loss: -22.94\n",
      "Iteration: 10 Loss: -25.58\n",
      "Iteration: 11 Loss: -28.12\n",
      "Iteration: 12 Loss: -30.63\n",
      "Iteration: 13 Loss: -33.11\n",
      "Iteration: 14 Loss: -35.57\n",
      "Iteration: 15 Loss: -38.01\n",
      "Iteration: 16 Loss: -40.44\n",
      "Iteration: 17 Loss: -42.85\n",
      "Iteration: 18 Loss: -45.24\n",
      "Iteration: 19 Loss: -47.64\n",
      "Iteration: 20 Loss: -50.03\n",
      "Iteration: 21 Loss: -52.40\n",
      "Iteration: 22 Loss: -54.77\n",
      "Iteration: 23 Loss: -57.14\n",
      "Iteration: 24 Loss: -59.52\n",
      "Iteration: 25 Loss: -61.91\n",
      "Iteration: 26 Loss: -64.28\n",
      "Iteration: 27 Loss: -66.65\n",
      "Iteration: 28 Loss: -69.07\n",
      "Iteration: 29 Loss: -71.48\n",
      "Iteration: 30 Loss: -73.90\n"
     ]
    }
   ],
   "source": [
    "cnn_layer = 21\n",
    "filter_pos = 5\n",
    "# Fully connected layer is not needed\n",
    "layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)\n",
    "\n",
    "# Layer visualization with pytorch hooks\n",
    "layer_vis.visualise_layer_with_hooks()\n",
    "\n",
    "# Layer visualization without pytorch hooks\n",
    "#layer_vis.visualise_layer_without_hooks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Visualize different CNN layers and filters\n",
    "Change the CNN layer and filter to visualize the network at different depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------- Task 3 --------------------------------------------------------\n",
    "# write code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deep Dream\n",
    "Deep dream is a technique similar to layer visualization, that optimises an input image based on a selected convolutional filter. The main difference is that you start with a real picture, instead of a random noise image, and optmise that.\n",
    "\n",
    "**All the visualizations will be saved to** `/generated` folder\n",
    "\n",
    "See paper - https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss: 5.40\n",
      "Iteration: 2 Loss: 0.81\n",
      "Iteration: 3 Loss: -4.40\n",
      "Iteration: 4 Loss: -8.86\n",
      "Iteration: 5 Loss: -12.73\n",
      "Iteration: 6 Loss: -16.38\n",
      "Iteration: 7 Loss: -19.44\n",
      "Iteration: 8 Loss: -23.10\n",
      "Iteration: 9 Loss: -26.64\n",
      "Iteration: 10 Loss: -29.93\n",
      "(117, 224, 3)\n",
      "Iteration: 11 Loss: -32.64\n",
      "Iteration: 12 Loss: -35.87\n",
      "Iteration: 13 Loss: -39.08\n",
      "Iteration: 14 Loss: -42.76\n",
      "Iteration: 15 Loss: -45.75\n",
      "Iteration: 16 Loss: -49.54\n",
      "Iteration: 17 Loss: -53.64\n",
      "Iteration: 18 Loss: -58.05\n",
      "Iteration: 19 Loss: -60.94\n",
      "Iteration: 20 Loss: -63.48\n",
      "(117, 224, 3)\n",
      "Iteration: 21 Loss: -67.32\n",
      "Iteration: 22 Loss: -71.84\n",
      "Iteration: 23 Loss: -75.33\n",
      "Iteration: 24 Loss: -78.92\n",
      "Iteration: 25 Loss: -82.60\n",
      "Iteration: 26 Loss: -86.20\n",
      "Iteration: 27 Loss: -89.10\n",
      "Iteration: 28 Loss: -92.65\n",
      "Iteration: 29 Loss: -95.70\n",
      "Iteration: 30 Loss: -99.51\n",
      "(117, 224, 3)\n",
      "Iteration: 31 Loss: -102.96\n",
      "Iteration: 32 Loss: -106.56\n",
      "Iteration: 33 Loss: -109.42\n",
      "Iteration: 34 Loss: -113.02\n",
      "Iteration: 35 Loss: -116.61\n",
      "Iteration: 36 Loss: -119.72\n",
      "Iteration: 37 Loss: -123.04\n",
      "Iteration: 38 Loss: -125.94\n",
      "Iteration: 39 Loss: -129.10\n",
      "Iteration: 40 Loss: -132.41\n",
      "(117, 224, 3)\n",
      "Iteration: 41 Loss: -135.53\n",
      "Iteration: 42 Loss: -138.80\n",
      "Iteration: 43 Loss: -141.61\n",
      "Iteration: 44 Loss: -144.43\n",
      "Iteration: 45 Loss: -147.59\n",
      "Iteration: 46 Loss: -150.76\n",
      "Iteration: 47 Loss: -153.25\n",
      "Iteration: 48 Loss: -156.32\n",
      "Iteration: 49 Loss: -159.23\n",
      "Iteration: 50 Loss: -162.15\n",
      "(117, 224, 3)\n",
      "Iteration: 51 Loss: -165.33\n",
      "Iteration: 52 Loss: -168.21\n",
      "Iteration: 53 Loss: -170.93\n",
      "Iteration: 54 Loss: -173.94\n",
      "Iteration: 55 Loss: -176.86\n",
      "Iteration: 56 Loss: -179.94\n",
      "Iteration: 57 Loss: -182.76\n",
      "Iteration: 58 Loss: -185.52\n",
      "Iteration: 59 Loss: -188.29\n",
      "Iteration: 60 Loss: -191.10\n",
      "(117, 224, 3)\n",
      "Iteration: 61 Loss: -193.90\n",
      "Iteration: 62 Loss: -196.67\n",
      "Iteration: 63 Loss: -199.41\n",
      "Iteration: 64 Loss: -202.57\n",
      "Iteration: 65 Loss: -205.23\n",
      "Iteration: 66 Loss: -208.10\n",
      "Iteration: 67 Loss: -210.92\n",
      "Iteration: 68 Loss: -213.83\n",
      "Iteration: 69 Loss: -216.63\n",
      "Iteration: 70 Loss: -219.60\n",
      "(117, 224, 3)\n",
      "Iteration: 71 Loss: -222.38\n",
      "Iteration: 72 Loss: -225.23\n",
      "Iteration: 73 Loss: -227.84\n",
      "Iteration: 74 Loss: -230.75\n",
      "Iteration: 75 Loss: -233.62\n",
      "Iteration: 76 Loss: -236.41\n",
      "Iteration: 77 Loss: -239.10\n",
      "Iteration: 78 Loss: -241.93\n",
      "Iteration: 79 Loss: -244.82\n",
      "Iteration: 80 Loss: -247.60\n",
      "(117, 224, 3)\n",
      "Iteration: 81 Loss: -250.21\n",
      "Iteration: 82 Loss: -253.15\n",
      "Iteration: 83 Loss: -256.11\n",
      "Iteration: 84 Loss: -258.84\n",
      "Iteration: 85 Loss: -261.69\n",
      "Iteration: 86 Loss: -264.47\n",
      "Iteration: 87 Loss: -267.33\n",
      "Iteration: 88 Loss: -270.16\n",
      "Iteration: 89 Loss: -272.81\n",
      "Iteration: 90 Loss: -275.83\n",
      "(117, 224, 3)\n",
      "Iteration: 91 Loss: -278.51\n",
      "Iteration: 92 Loss: -281.33\n",
      "Iteration: 93 Loss: -284.01\n",
      "Iteration: 94 Loss: -286.93\n",
      "Iteration: 95 Loss: -289.68\n",
      "Iteration: 96 Loss: -292.51\n",
      "Iteration: 97 Loss: -295.41\n",
      "Iteration: 98 Loss: -298.13\n",
      "Iteration: 99 Loss: -300.92\n",
      "Iteration: 100 Loss: -303.77\n",
      "(117, 224, 3)\n",
      "Iteration: 101 Loss: -306.54\n",
      "Iteration: 102 Loss: -309.32\n",
      "Iteration: 103 Loss: -312.17\n",
      "Iteration: 104 Loss: -314.89\n",
      "Iteration: 105 Loss: -317.64\n",
      "Iteration: 106 Loss: -320.48\n",
      "Iteration: 107 Loss: -323.29\n",
      "Iteration: 108 Loss: -326.16\n",
      "Iteration: 109 Loss: -328.89\n",
      "Iteration: 110 Loss: -331.55\n",
      "(117, 224, 3)\n",
      "Iteration: 111 Loss: -334.48\n",
      "Iteration: 112 Loss: -337.20\n",
      "Iteration: 113 Loss: -339.94\n",
      "Iteration: 114 Loss: -342.76\n",
      "Iteration: 115 Loss: -345.48\n",
      "Iteration: 116 Loss: -348.40\n",
      "Iteration: 117 Loss: -351.19\n",
      "Iteration: 118 Loss: -354.03\n",
      "Iteration: 119 Loss: -356.85\n",
      "Iteration: 120 Loss: -359.61\n",
      "(117, 224, 3)\n",
      "Iteration: 121 Loss: -362.30\n",
      "Iteration: 122 Loss: -365.11\n",
      "Iteration: 123 Loss: -367.88\n",
      "Iteration: 124 Loss: -370.64\n",
      "Iteration: 125 Loss: -373.46\n",
      "Iteration: 126 Loss: -376.24\n",
      "Iteration: 127 Loss: -379.01\n",
      "Iteration: 128 Loss: -381.86\n",
      "Iteration: 129 Loss: -384.61\n",
      "Iteration: 130 Loss: -387.51\n",
      "(117, 224, 3)\n",
      "Iteration: 131 Loss: -390.23\n",
      "Iteration: 132 Loss: -393.08\n",
      "Iteration: 133 Loss: -395.64\n",
      "Iteration: 134 Loss: -398.54\n",
      "Iteration: 135 Loss: -401.21\n",
      "Iteration: 136 Loss: -404.06\n",
      "Iteration: 137 Loss: -406.69\n",
      "Iteration: 138 Loss: -409.49\n",
      "Iteration: 139 Loss: -412.28\n",
      "Iteration: 140 Loss: -415.07\n",
      "(117, 224, 3)\n",
      "Iteration: 141 Loss: -417.90\n",
      "Iteration: 142 Loss: -420.56\n",
      "Iteration: 143 Loss: -423.32\n",
      "Iteration: 144 Loss: -426.18\n",
      "Iteration: 145 Loss: -428.91\n",
      "Iteration: 146 Loss: -431.68\n",
      "Iteration: 147 Loss: -434.32\n",
      "Iteration: 148 Loss: -436.99\n",
      "Iteration: 149 Loss: -439.86\n",
      "Iteration: 150 Loss: -442.62\n",
      "(117, 224, 3)\n",
      "Iteration: 151 Loss: -445.44\n",
      "Iteration: 152 Loss: -448.13\n",
      "Iteration: 153 Loss: -450.91\n",
      "Iteration: 154 Loss: -453.71\n",
      "Iteration: 155 Loss: -456.43\n",
      "Iteration: 156 Loss: -459.17\n",
      "Iteration: 157 Loss: -461.87\n",
      "Iteration: 158 Loss: -464.48\n",
      "Iteration: 159 Loss: -467.34\n",
      "Iteration: 160 Loss: -470.17\n",
      "(117, 224, 3)\n",
      "Iteration: 161 Loss: -472.90\n",
      "Iteration: 162 Loss: -475.49\n",
      "Iteration: 163 Loss: -478.31\n",
      "Iteration: 164 Loss: -481.05\n",
      "Iteration: 165 Loss: -483.84\n",
      "Iteration: 166 Loss: -486.54\n",
      "Iteration: 167 Loss: -489.37\n",
      "Iteration: 168 Loss: -491.97\n",
      "Iteration: 169 Loss: -494.66\n",
      "Iteration: 170 Loss: -497.46\n",
      "(117, 224, 3)\n",
      "Iteration: 171 Loss: -500.23\n",
      "Iteration: 172 Loss: -503.00\n",
      "Iteration: 173 Loss: -505.74\n",
      "Iteration: 174 Loss: -508.44\n",
      "Iteration: 175 Loss: -511.08\n",
      "Iteration: 176 Loss: -513.78\n",
      "Iteration: 177 Loss: -516.61\n",
      "Iteration: 178 Loss: -519.33\n",
      "Iteration: 179 Loss: -522.22\n",
      "Iteration: 180 Loss: -524.82\n",
      "(117, 224, 3)\n",
      "Iteration: 181 Loss: -527.51\n",
      "Iteration: 182 Loss: -530.22\n",
      "Iteration: 183 Loss: -533.03\n",
      "Iteration: 184 Loss: -535.67\n",
      "Iteration: 185 Loss: -538.41\n",
      "Iteration: 186 Loss: -541.08\n",
      "Iteration: 187 Loss: -543.83\n",
      "Iteration: 188 Loss: -546.54\n",
      "Iteration: 189 Loss: -549.14\n",
      "Iteration: 190 Loss: -551.96\n",
      "(117, 224, 3)\n",
      "Iteration: 191 Loss: -554.66\n",
      "Iteration: 192 Loss: -557.32\n",
      "Iteration: 193 Loss: -559.89\n",
      "Iteration: 194 Loss: -562.74\n",
      "Iteration: 195 Loss: -565.45\n",
      "Iteration: 196 Loss: -568.09\n",
      "Iteration: 197 Loss: -570.78\n",
      "Iteration: 198 Loss: -573.47\n",
      "Iteration: 199 Loss: -576.19\n",
      "Iteration: 200 Loss: -578.91\n",
      "(117, 224, 3)\n",
      "Iteration: 201 Loss: -581.68\n",
      "Iteration: 202 Loss: -584.36\n",
      "Iteration: 203 Loss: -587.11\n",
      "Iteration: 204 Loss: -589.77\n",
      "Iteration: 205 Loss: -592.37\n",
      "Iteration: 206 Loss: -595.03\n",
      "Iteration: 207 Loss: -597.65\n",
      "Iteration: 208 Loss: -600.41\n",
      "Iteration: 209 Loss: -603.00\n",
      "Iteration: 210 Loss: -605.71\n",
      "(117, 224, 3)\n",
      "Iteration: 211 Loss: -608.38\n",
      "Iteration: 212 Loss: -611.14\n",
      "Iteration: 213 Loss: -613.80\n",
      "Iteration: 214 Loss: -616.57\n",
      "Iteration: 215 Loss: -619.28\n",
      "Iteration: 216 Loss: -621.87\n",
      "Iteration: 217 Loss: -624.57\n",
      "Iteration: 218 Loss: -627.22\n",
      "Iteration: 219 Loss: -629.82\n",
      "Iteration: 220 Loss: -632.57\n",
      "(117, 224, 3)\n",
      "Iteration: 221 Loss: -635.16\n",
      "Iteration: 222 Loss: -637.85\n",
      "Iteration: 223 Loss: -640.46\n",
      "Iteration: 224 Loss: -643.22\n",
      "Iteration: 225 Loss: -645.73\n",
      "Iteration: 226 Loss: -648.49\n",
      "Iteration: 227 Loss: -651.08\n",
      "Iteration: 228 Loss: -653.74\n",
      "Iteration: 229 Loss: -656.32\n",
      "Iteration: 230 Loss: -658.99\n",
      "(117, 224, 3)\n",
      "Iteration: 231 Loss: -661.62\n",
      "Iteration: 232 Loss: -664.32\n",
      "Iteration: 233 Loss: -666.90\n",
      "Iteration: 234 Loss: -669.56\n",
      "Iteration: 235 Loss: -672.19\n",
      "Iteration: 236 Loss: -674.90\n",
      "Iteration: 237 Loss: -677.54\n",
      "Iteration: 238 Loss: -680.05\n",
      "Iteration: 239 Loss: -682.65\n",
      "Iteration: 240 Loss: -685.35\n",
      "(117, 224, 3)\n",
      "Iteration: 241 Loss: -687.98\n",
      "Iteration: 242 Loss: -690.66\n",
      "Iteration: 243 Loss: -693.17\n",
      "Iteration: 244 Loss: -695.83\n",
      "Iteration: 245 Loss: -698.41\n",
      "Iteration: 246 Loss: -701.08\n",
      "Iteration: 247 Loss: -703.63\n",
      "Iteration: 248 Loss: -706.29\n",
      "Iteration: 249 Loss: -708.89\n",
      "Iteration: 250 Loss: -711.62\n",
      "(117, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "cnn_layer = 21\n",
    "filter_pos = 5\n",
    "\n",
    "im_path = './visualizations/input_images/dd_tree.jpg'\n",
    "# Fully connected layer is not needed\n",
    "\n",
    "dd = DeepDream(pretrained_model, cnn_layer, filter_pos, im_path)\n",
    "# This operation can also be done without Pytorch hooks\n",
    "# See layer visualisation for the implementation without hooks\n",
    "dd.dream()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient visualization with Guided backpropagation\n",
    "\n",
    "In order to visualise what is learnt by neurons in higher layers, a deconvolutional approach was developed, which inverts the data flow of a CNN, going from a neuron of interest to an image. The resulting image is the one which most strongly activates this neuron.\n",
    "\n",
    "![guided_backprop](guided_backprop.png)\n",
    "\n",
    "Details of the backprop method is in the following reference:\n",
    "\n",
    "Springenberg, Jost Tobias, et al. \"Striving for simplicity: The all convolutional net.\" arXiv preprint arXiv:1412.6806 (2014)-\n",
    "https://arxiv.org/pdf/1412.6806.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the implementation of guided backpropagation in `/visualizations/src/guided_backprop.py`.\n",
    "\n",
    "First get input image, class label, and pretrained model (pretrained alexnet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_example = 0  \n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you create an instance of the guidedbackprop class using `GuidedBackprop(pretrained_model)`. \n",
    "This operation creates hooks on the model, which updates relu activation functions so that:\n",
    "1. it stores the output of the forward pass\n",
    "2. it imputes zero for gradient values that are less than zero, i.e. all gradients are clamped to zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------- Guided backprop---------------------------------------------------\n",
    "# Guided backprop\n",
    "GBP = GuidedBackprop(pretrained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then you can generate gradients that are specific to a particular input image, and class using the method `GP.generate_gradients()` with the following steps:\n",
    " 1. go through a forward pass with the image input, and generate an output\n",
    " 2. backprop through the output\n",
    " 3. get the gradients from the backprop\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gradients\n",
    "guided_grads = GBP.generate_gradients(prep_img, target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can save the gradients using the following plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided backprop completed\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------- Save images-------------------------------------------------------\n",
    "# Save colored gradients\n",
    "save_gradient_images(guided_grads, file_name_to_export + '_Guided_BP_color')\n",
    "# Convert to grayscale\n",
    "grayscale_guided_grads = convert_to_grayscale(guided_grads)\n",
    "# Save grayscale gradients\n",
    "save_gradient_images(grayscale_guided_grads, file_name_to_export + '_Guided_BP_gray')\n",
    "# Positive and negative saliency maps\n",
    "pos_sal, neg_sal = get_positive_negative_saliency(guided_grads)\n",
    "save_gradient_images(pos_sal, file_name_to_export + '_pos_sal')\n",
    "save_gradient_images(neg_sal, file_name_to_export + '_neg_sal')\n",
    "print('Guided backprop completed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Run guided backprop for different inputs, and classes\n",
    "You can do this by changing `target_example=` (there's 3 inputs available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------- Task 4 --------------------------------------------------------\n",
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradient Class Activation Mapping (grad-CAM)\n",
    "\n",
    "\n",
    "R. R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, and D. Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, https://arxiv.org/abs/1610.02391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad cam completed\n"
     ]
    }
   ],
   "source": [
    "# Get params\n",
    "target_example = 1\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n",
    "\n",
    "# Grad cam\n",
    "grad_cam = GradCam(pretrained_model, target_layer=11)\n",
    "# Generate cam mask\n",
    "cam = grad_cam.generate_cam(prep_img, target_class)\n",
    "# Save mask\n",
    "save_class_activation_images(original_image, cam, file_name_to_export)\n",
    "print('Grad cam completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
