{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability tutorial\n",
    "\n",
    "In this tutorial we will go through several popular visualization techniques that help interpret deep learning networks.\n",
    "\n",
    "We will cover:\n",
    "1. Filter visualization\n",
    "2. Feature/ activation visualization with PyTorch hooks\n",
    "3. CNN Layer Visualization\n",
    "4. Gradient visualization with Guided backpropagation\n",
    "5. Gradient Class Activation Maps (grad-CAM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import visualizations\n",
    "from visualizations.src.misc_functions import *\n",
    "from visualizations.src.guided_backprop import GuidedBackprop\n",
    "from visualizations.src.cnn_layer_visualization import CNNLayerVisualization\n",
    "from visualizations.src.gradcam import GradCam\n",
    "from visualizations.src.deep_dream import DeepDream\n",
    "\n",
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Weights Visualization\n",
    "\n",
    "https://towardsdatascience.com/visualizing-convolution-neural-networks-using-pytorch-3dfa8443e74e\n",
    "\n",
    "https://colab.research.google.com/github/Niranjankumar-c/DeepLearning-PadhAI/blob/master/DeepLearning_Materials/6_VisualizationCNN_Pytorch/CNNVisualisation.ipynb#scrollTo=uQI9jHcP6xfP\n",
    "\n",
    "One of the first things you can visualize in your network - is your network weights.\n",
    "Your convolutional kernels have weights which are updated during training, and can be visualized by calling the weight data inside your network.\n",
    "\n",
    "Let's first load and print a pretrained network using pytorch.models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# first load pretrained alxenet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the network is made up of two sequential models - features, and classifier.\n",
    "\n",
    "To visualize the convolutional weights, we need to access a convolutional layer in the features model.\n",
    "\n",
    "This can be done in the following way:\n",
    "```python \n",
    "weight_tensor = model.features[layer_num].weight.data\n",
    "```\n",
    "**Note that layer_num should correspond to a convolutional layer - otherwise there are no weights to be visualized.**\n",
    "\n",
    "We will now define a few functions to help with plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_single_channel(t):\n",
    "    \n",
    "    kernels_to_plot = 30\n",
    "    channels_to_plot = 3\n",
    "    #total kernels depth * number of kernels\n",
    "    nplots = channels_to_plot*kernels_to_plot\n",
    "    ncols = 12\n",
    "    \n",
    "    nrows = 1 + nplots//ncols\n",
    "    #convert tensor to numpy image\n",
    "    npimg = np.array(t.numpy(), np.float32)\n",
    "    \n",
    "    count = 0\n",
    "    fig = plt.figure(figsize=(ncols, nrows))\n",
    "    \n",
    "    #looping through all the kernels in each channel\n",
    "    for i in range(kernels_to_plot):\n",
    "        for j in range(channels_to_plot):\n",
    "            count += 1\n",
    "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
    "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
    "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "            ax1.imshow(npimg)\n",
    "            ax1.set_title(str(i) + ',' + str(j))\n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "def plot_filters_multi_channel(t):\n",
    "    \n",
    "    kernels_to_plot = 60\n",
    "    #get the number of kernals\n",
    "    num_kernels = t.shape[0]    \n",
    "    \n",
    "    #define number of columns for subplots\n",
    "    num_cols = 12\n",
    "    #rows = num of kernels\n",
    "    num_rows = kernels_to_plot // num_cols\n",
    "    \n",
    "    #set the figure size\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    \n",
    "    #looping through all the kernels\n",
    "    for i in range(kernels_to_plot):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        \n",
    "        #for each kernel, we convert the tensor to numpy \n",
    "        npimg = np.array(t[i].numpy(), np.float32)\n",
    "        #standardize the numpy image\n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define our plot weights function, which first extracts the weights of a convolutional filter, and then passes into an appropriate image plotting function.\n",
    "\n",
    "### Task 1.1 - edit the `plot_weights` function to return the weights tensor corresponding to layer `layer_num`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(model, layer_num, single_channel = True):\n",
    "    #extracting the model features at the particular layer number\n",
    "    layer = model.features[layer_num]\n",
    "  \n",
    "    #checking whether the layer is convolution layer or not \n",
    "\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        #getting the weight tensor data\n",
    "        weight_tensor = model.features[layer_num].weight.data\n",
    "        print('weight_tensor.shape',weight_tensor.shape)\n",
    "        if single_channel:\n",
    "            plot_filters_single_channel(weight_tensor)\n",
    "        \n",
    "        else:\n",
    "            if weight_tensor.shape[1] == 3:\n",
    "                plot_filters_multi_channel(weight_tensor)\n",
    "            else:\n",
    "                print(\"Can only plot weights with three channels with single channel = False\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Can only visualize layers which are convolutional\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 Explain \n",
    "\n",
    "- what do the weights of your network represent? \n",
    "- what is the difference between a kernel and a filter (**hint** see lecture 4)\n",
    "- Layer 3 (the second convolution) has a weights matrix of size `[192, 64, 5, 5]`. What does each dimension represent? How many filters does it learn, how many kernels?\n",
    "\n",
    "#### Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3  Visualise weights for different layers.\n",
    "\n",
    "- plot the weights for different colvolutional layers\n",
    "- Note the purpose of parameter `single_channel=False` is to plot all filters as a single image. **However** this is only possible for 3 channel output - where it can be plotted in RGB; \n",
    "- try plotting the output of the first layer with `single_channel=True`, then `single_channel=False` to see the difference\n",
    "- What do the numbers above the plots mean? How many outputs are being returned and why (**hint** check the plotting functions)? How do you determine how many \n",
    "- try editing the plotting functions to include input arguments which vary the numbers of kernels plot per filter for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_tensor.shape torch.Size([384, 192, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAI4CAYAAABQssmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XncXGV99/HvN7kDkYQgoIABSwwEhVBIxIpLWSxgAKtoI5aCAmofoBTbgmKrggTBDddaIYgFw66AuBUwRAUFEVlKgEaQNSzGsBlCEjBAcj1/nCs+0/uZmXvOdZ9zZjmf9+s1r2Rmruuc63wzv5n5zRaHEAQAAAAAkMZ0ewEAAAAA0CtokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAqJQGyfYmtr9ne5Xth2wf3GKcbX/e9lPxdJptl7GmXpIjn7fYvsb2ctuLK15mV+TI5njb/2N7he0HbR9f9VqrZPsY27fYXm173ghjj7W9NN5uzrG9fkXL7IpOs7G9o+35tp+0XYv/AC5HNofZvtX2M7YfjffFQxUutXK217d9dryfWWH7Ntv7tRlfm7rKk03d6ipnNnWsqwts/z4e8z22/77N2NrUlNR5NnWrqXVy5FNJXZX1DtLpkp6XtLmkQyTNtT29ybgjJL1T0s6SdpL015KOLGlNvaTTfFZJOkfSQD/5H6bTbCzpUEkbS9pX0jG2D6psldVbIulUZbeHlmzPkvRvkvaSNEXSVEknl724LusoG0kvSLpE0gdLX1Hv6DSbDST9i6SXSdpV2e3nI+UureuGJD0iaQ9JG0k6UdIltqcMH1jDuuo4G9WvrvJkU8e6+qykKSGESZLeIelU27sMH1TDmpI6zEb1q6l1Os2nmroKIRR6kjRB2RPc7RouO1/S55qMvUHSEQ3nPyjpxqLX1EunPPk0XL+3pMXdXnsvZtMw7muS/qPbx1BBRqdKmtfm+oskfabh/F6SlnZ73b2QTcO4bbO7vu6vudeyaRh/nKQfdXvdXcjpDkmzm1xe27oaKZuG62tXV51m0zCuVnUl6dWSfi/pPU2uq3VNtcumYUyda2rEfBrGllJXZbyDtJ2kNSGEexouu11Ss3cBpsfrRho3SPLkUzdJ2di2pN0kLSpxbf2iWU1tbnvTLq0H/Wl31ayebG+u7D6o2XHXuq5GyKbWcmZTi7qyfYbtZyXdrexJ7pVNhtWypjrMprYS8ymlrspokCZKWj7ssuWSNuxg7HJJE+MT3kGVJ5+6Sc1mjrLb8rdKWFO/aVZTErcvdMj2+yW9TtIXu72WqtgeJ+lCSeeGEO5uMqS2ddVBNrWVJ5s61VUI4WhltbGbpMslrW4yrJY11WE2tZU3nzLrqowGaaWkScMumyRpRQdjJ0laGeJ7ZgMqTz51kzsb28co+y7S20II3NE0rymJ2xc6YPudkj4nab8QwpPdXk8VbI9R9lHe5yUd02JYLeuqw2xqKU82dayrEMKaEML1kraS9A9NhtSypqSOsqm1TvMpu67KaJDukTRke1rDZTur+dtfi+J1I40bJHnyqZtc2dj+gOKXPEMIj1awvn7QrKYeCyE81aX1oE/Y3lfSNyW9PYRwZ7fXU4X4aYWzlf0ozOwQwgsthtaurnJkUzt5sqljXQ0zJGmbJpfXrqaaaJUNMi3zqaKuCm+QQgirlL0t9inbE2y/WdIBks63PcV2aPi1l/MkHWd7S9uTJX1Y0ryi19RL8uRje4zt8ZLGZWc93vZ63Vp72XJmc4ikz0jaJ4TwQLfWXBXbQ/G2MFbS2HhbGIrXBdt7xqHnSfqg7R1sbyzpBA14TXWajTPjJa0Xz4+vwc/KdprNXyn7qNDsEMJNXVtw9eZK2l7Zg+xzjVfUva7UYTZ1rCt1nk2t6sr2ZrYPsj3R9tj4S3V/J+ln8fra1lSebOpYUznzqaauSvr1iU0kfV/Zz1Q/LOngePlukhZLGhfPW9Jpkv4QT6dJcrd/PaPsU4589pQUhp2u7fb6eySbB5X9FObKhtOZ3V5/ibnMaXJbmKPsLegVkjZtGHucpMckPaPse1nrd3v9vZCNsp+SHT5ucbfX3yPZXCPpxWH1dFW3119yNlvHPP447LgPqXtd5cmmbnWVM5ta1ZWkl0v6uaSnY53cKen/xOvqXlMdZ1O3mkrIp5K6ctxZJWyfIOmJEMI3KttpHyGf1simOdvvlTQ9hPCxbq+l15BNa2TTHvm0RjatkU1rZNMa2bTXrXwqbZAAAAAAoJeV8SMNAAAAANCXaJAAAAAAIKJBAgAAAIBoqN2VF937+uQvKJ321YOS5v33iXNTd6kxW9zr5Mk5Xbt4WnI2n546o8ildGTB2ksry2bZkq2Ss3nPVm9Mmjd/ycLUXVZ6u5Gk79+/c3I+p0/bLmlev+Sz70s/mJzNlXf/osildKTKbNYuTb/PSbXNT9+fPPfBQz5eWTb7jDkwOZuxG2+cNG/NsmWpu6z0/ng0t5tZkxMfq5x+eAvWXFJZNifdeUByNouf2zRp3rf+7LrUXfbN/c22F6b936f3HdIfz/9Gc3+T+li882lHp+5Sd3752L7I5qFL/jxp3tbvSf9vkNrdF/MOEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAEA21u/KgDZclb/igE+cmzZs1eUbyPhesTZ6a2+7j0+d+OnHevIevT99phTYa85LkuWOnvzpx5sLkfVbtHROeTZ772/9ZUeBKes8j526VPHc09x2pqrzP6YZt33db+uRDilvHSMZuPy157pU/vbTAlfSe0dTF/CX9c7+a4qSX/6byffbLc5zR2Ob4XyXNm/nQ0cn7vP1ryVNzu/9Lb0ieO2ty2rwtdEPyPvXlY9Pn5jS6+4y0ubNUzmM/7yABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQDTU7spZk2ckbzi8aeekedbtyfscdK8YmtjtJXRk5s0HJc/dbNHdSfNGc1tdsDZ5apLRrDXVT9Qf+dy560XJc2eN4hj7wdTLj0yeO+2YXxe4kt6z5q57K9/n1O+l/3ss/ocCF1KiV83/YNK8qRek7/OaBelz8+rGffF9X31D5fus2tJj35Q0b4uv3JC+068dmz43p/v+7szkuW+9/PCkeVdfOi95n0jDO0gAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEDkEEK31wAAAAAAPYF3kAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhKbZBsT7P9R9sXtLjetj9v+6l4Os22y1xTr+ggm7fYvsb2ctuLK15eV3WQzfG2/8f2CtsP2j6+6jV2g+1rYy4r4+m3LcbVrq5yZFO7usqRTV3r6iDbd9leZft+27u1GHes7aXxtnOO7fWrXmvVOsnG9o6259t+0nboxjq7ocNsDrN9q+1nbD8a74uHurHeqjTcz6w7rbH9H23G16au8mRTt7rKmU0ldVX2O0inS7q5zfVHSHqnpJ0l7STpryUdWfKaesVI2aySdI6kWjxJGWakbCzpUEkbS9pX0jG2D6piYT3gmBDCxHh6dYsxda2rTrKpa111kk3t6sr2PpI+L+n9kjaUtLukB5qMmyXp3yTtJWmKpKmSTq5soV3QaTaSXpB0iaQPVre67sqRzQaS/kXSyyTtquz285GKltkVDfczEyVtLuk5SZc2G1u3usqTjWpWVzmzqaSuSmuQ4gPr05J+2mbYYZK+FEJ4NITwO0lfknR4WWvqFZ1kE0K4KYRwvprf6Q6sDrM5LYTw3yGEF0MIv5X0A0lvrmqNfaCWddWJutZVJ2paVydL+lQI4cYQwtoQwu9izQx3mKSzQwiLQgjLJJ2iwa+pjrIJIfw2hHC2pEXVL7FrOs1mbgjhuhDC8/H6CzX4NdXo3ZIel3Rdi+vrWFfrtM2mpnW1zkjZVFJXpTRItidJ+pSkD48wdLqk2xvO3x4vG1g5sqmdlGziR8d2U33uRD4b33L/pe09W4ypXV1FnWRTV7myqUNd2R4r6XWSXm77vvhRja/bfkmT4c1qanPbm1ax1qrlzKZWRpnN7hrgmmriMEnnhRBafUSsVnU1zEjZ1FnebEqpq7LeQTpF2asCj4wwbqKk5Q3nl0uaOODfl+g0mzpKyWaOstvxt0pZUW/5V2UfQdhS0lmSfmR7mybj6lhXnWZTRynZzNHg19XmksYpe7VyN0kzJM2UdEKTsc1qSso+XjWI8mRTN0nZ2H6/ssbqi2UvsBfY/jNJe0g6t82wutWVpI6zqaW82ZRZV4U3SLZnSNpb0lc6GL5S0qSG85MkrRzUjjpnNrWSko3tY5R9Z+JtIYTVZa2tV4QQfh1CWBFCWB1COFfSLyXt32RorepKypVN7eTNpkZ19Vz88z9CCL8PITwp6cvqvKYkaUWJ6+umPNnUTe5sbL9T0uck7RfH18Ghkq4PITzYZkzd6mqdTrKpq46zKbuuyvg1lT2Vfdnu4fiC9URJY23vEEJ47bCxi5R9kfymeH5nDfbbz3uq82zqZk/lyMb2B5R9uXP3EMKjFa6zlwRlX6wfrm511UyrbNAmmzrVVQhhme1HleUxknU1dUk8v7Okx0IIT5W1vm7KmU2t5M3G9r6SvqnsBYc7S11cbzlU2ZPXdmpVVw06yaauOsqmkroKIRR6UvbrEls0nL4o6TJJL1f2BDhImhLHHiXpLmUf/ZisrFiOKnpNvXLKmc0YSeMl7Sfpofj39bp9DD2SzSGSlkravtvrrjCfl0qaFW8HQzGDVZJeTV3lyqZudZUnmzrW1aeU/WLmZsp+ve86SafE64KkPePf943Z7BDH/UzS57q9/h7JxvH2tUO8fLyk9bu9/h7J5q8kPaXsBYeur7vCfN4U72c2bHJd3euq02zqWFedZlNJXVVxwHMkXRD/vpukxZLGNdwATpP0h3g6TZK7/Y9U4Y2hXTZ7xhtE4+nabq+5R7J5UNlPYK5sOJ3Z7TWXnMfL4wPyCmW/8nejpH1a5FOrusqZTa3qKmc2dayrcZLOiNkslfS1+ERkq5jZpg1jj5P0mKRnlH03a9CfrHSUjf5fo914Wtzt9fdINtdIenFYTV3V7fVXkM83JJ3f5HLqqsNsalpXnWZTSV057qwStk+Q9EQI4RuV7bRPkE1rZNMe+bRGNq2RTWu23ytpegjhY91eS68hm9bIpj3yaY1sWutWNpU2SAAAAADQy0r7j2IBAAAAoN/QIAEAAABARIMEAAAAAFHb/wdp5hWfSP6C0q27XDLyoCb2n/nW1F3qx78/vbL/92Tt0mmVf3lr1uQZyXMXrL20smz23Pfzydk8tcN6SfNu/+gZqbvUmC3urfT/y3nVV7+UnM/9B51Z5FI6UmU+o6mrWX9zaNrEG+9I3WWldTWabHY+7eikef1SV/uMOTA5m5f8fPOkec/t8VjqLvvmdpNqx39Pu71J0m8+e2xl2Uz99qeTs/nAjr9KmvdCGJu6S5385z+oLJt9NzsqOZu7vjAlad527781dZeV1tRo7m/mL1lY5FI60i/3xak8lP5ful79/MUts+EdJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIBpqd+XzL7a9uhRrHnu88n2m+PhjOyXPnTL+yQJX0nvGXX1L8twtrk6c+NHkXVZu2+NuTJ67/SvflzTvrjefn7zPKs2aPCN57uLvpM377W4Lk/dZpZ1v+rvkuVt89YakebO+mv7vsWBt8tRKfX/a/LSJS4pdR1l+/Oz6yXP33WB1gSvpPfftOa/yfY7mPk4V1tSVd/y0up1FixY/V/k+U8xfkv6Y8bY3vj1p3osPPZK8zyrvi0eTTWpt3POl1yXvsx3eQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAaKjdlZPf9ZvkDc/SjKR595z5+uR9VunWmem95WeWLEmad/nMtyTvs1945vSkea//+BuT93nLOclTKzf1I08nzdvviTcl73P+yuSplZryt3ckzdv+k0cn7/O3c5Kn5vbWP7s7ee4XlixMmjdrctr9eNUeuWzH5Ln77bd90ryrrro4eZ9V+sq2accnST+8eXzSvC0/f0PyPvXZY9Pn5vQfy7ZOnvvl69+aNG873Zy8zypNvfSo5LkbPpD2/GiLf0+/3SxYmzy1Uhdc/52keQe9Mv0xvF/MT3yc+osT0p//tcM7SAAAAAAQ0SABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQOQQQrfXAAAAAAA9gXeQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiEppkGxPsX2l7WW2l9r+uu2hFmMPtv2Q7VW2v297kzLW1Es6zcf2K2z/0PYS28H2lOpXW60c2bzN9vW2n47jvml7w26suSq2t7f9M9vLbd9n+11txh4bc1lu+xzb61e51qp1mo3tHW3Pt/2k7VD1OrshRzaH2b7V9jO2H7V9Wqv77X5l+xjbt9hebXvesOv2sn237WdtX2N76zbbmRLHPBvn7F364ktWYDan2L7T9ou255S97ioUkY3tzWxfHB/Pl9v+pe1dKzmAErXKxvZ6ti+zvTg+f9lzhO1sYvt78bngQ7YPLnvtZSswm5a3v35VRDa217d9dry9rLB9m+39ilpjWe8gnSHpcUmvkDRD0h6Sjh4+yPZ0Sd+Q9D5Jm0t6Ns4ddB3lI2mtpB9Lml3d0rqu02w2knSqpMmStpe0laQvVLTGysUnqj+Q9F+SNpF0hKQLbG/XZOwsSf8maS9JUyRNlXRyZYutWJ5sJL0g6RJJH6xuhd2TM5sNJP2LpJdJ2lXZ7ecjFS21KkuU3W+c03ih7ZdJulzSicpyukXSd9ps52JJt0naVNInJF1m++VlLLhCRWVzn6SPSrqinGV2RRHZTJR0s6Rd4thzJV1he2JJa65K02yi6yW9V9LSDrZzuqTnlT0XPETS3PgcsZ8VlU277fSrIrIZkvSIsueJGymrw0tc1JsJIYTCT5LukrR/w/kvSPpGk3GfkXRRw/ltlBXIhmWsq1dOnebTcP2QpCBpSrfX3mvZNIz7G0l3dnv9Jeayo6SVktxw2dWSTmky9iJJn2k4v5ekpd0+hl7IpuH6bbO7v+6vv9eyaRh3nKQfdfsYSsrlVEnzGs4fIemGhvMTJD0n6TVN5m4naXXj45Sk6yQd1e3j6nY2w7ZzgaQ53T6eXsymYfwzknbp9nGVkc2w6x6VtGebuRPic7/tGi47X9Lnun1c3c6m0+3066mobBrm3CFpdhFrK+sdpH+XdJDtDWxvKWk/Ze+EDDdd0u3rzoQQ7lcskpLW1Ss6zaeOUrPZXdKiUlfWXW5x2Y5NLv9fdRX/vrntTctYWA/Ik03djCabQa+pRsMfi1ZJuj9e3mzsAyGEFQ2X3d5i7CDIk03dJGdje4ak9ZS941Z320laE0K4p+GyQa4plMD25spuS4U8bpXVIP1c2Q37GWUd4C2Svt9k3ERJy4ddtlzSQH+XRJ3nU0e5s7G9j6TDJH2y9NV1z93KPnp4vO1xtt+q7G3lDZqMHV5X6/4+qHWVJ5u6ScrG9vslvU7SF8tfYk/I81hUt8etuh1vHknZ2J6k7B2Sk0MIw+fXEbcxjIrtcZIulHRuCOHuIrZZeINke4yk+co+lztB2efZN5b0+SbDV0qaNOyySZJWNBk7EHLmUysp2dh+g7KPlL172KtPAyWE8IKkd0p6m7LP5X5Y2XdpHm0yfHhdrfv7QNZVzmxqJSUb2++U9DlJ+4UQnqxinT0gz2NR3R636na8eeTOxvZLJP1I0o0hhM+WuLZ+wm0MyeJzx/OVfQLtmKK2W8Y7SJtIeqWkr4cQVocQnpL0LUn7Nxm7SNLO687YnippfUkD+0RX+fKpm1zZ2J4p6YeSPhBC+Gl1y+yOEMIdIYQ9QgibhhBmKfvxhZuaDP1fdRX//ljMcyDlyKZ28mRje19J35T09hDCnVWus8uGPxZNUPad2GYf1Vgkaar/969m7txi7CDIk03d5MrG2a+Jfl/S7yQdWcUC+8Q9koZsT2u4bJBrCgWxbUlnK/txj9nxRcFCFN4gxVccH5T0D7aHbL9U2cefbpek+NN9h8fhF0p6u+3d4h3LpyRdPuyz3QMlZz6yPV5Z0yhJ68fzAylPNrZ3VPbdpA+FEH7UpSVXyvZOtsfH72d9RNkv/c2L1zX+HOZ5kj5oewfbG0s6Yd24QdVpNs6MV/bZf8U5g/4T6J1m81fK7pNnhxAGsrmM9yvjJY2VNDbmMiTpe5J2tD07Xv9JSXes+6iG7Tm2r5Wk+E71QkknxfnvkrSTpO924ZAKU0Q28fy4OG6Msie9422PrfyAClRENvEjQJcp+xGHQ0MIa7txLEVrk826n2Fe95xlvXid43WH214s/em7W5dL+pTtCbbfLOkAZe8K9K0ishlpO/2qqGwkzVX2S8ZvDyE8V+giS/pVihmSrpW0TNKTki6VtJmyJyUr1PALL5IOlvSwpFXKfo52kzLW1EunnPmE4adur78XslH2ztJaZW/Nrzst6vb6S87mCzGXlZKukrRtvHyrmM2mDWOPk/SYsu9yfUvS+t1efy9ko+xnz4fX1OJur79HsrlG0ovDauqqbq+/4CzmNPn3nxOv21vZd7aei/dBUxrmnS3p0w3np8Qxz0n6raS9u31sPZTNvCbbObzbx9ftbJR99y8o++9MGmtst24fX4nZLG5y3ZR43YmSLmzYzibK3l1bpew54cHdPrYeyqbldvr1VEQ2kraO1/1xWE0dUsQaHXdSCdt/KekfQwh/V9lO+wj5tEY2rdl+r6TpIYSPdXstvYZsWiObztleKGmvMMAfU01FNq2RTWu2r5b0zyGEu7q9ll5DNq1VmU2lDRIAAAAA9LKyfuYbAAAAAPoODRIAAAAARDRIAAAAABC1/ZnAfcYc2FdfUFqw9lJXta/RZPPqW8YlzRvnNam71FdmfqeybNYunZaczbxnNkuad/FrJqfustLbjSTt/4t/Ss5n7d+m3QauvO3q1F1qzBb39kVd+WdbJs17fOXE1F1q4V+fWlk2l98/Mzmb4375t0nzph1+a+ou++b+eMyMHZLmrV34m9RdVprN1md9ITmb7Y6q/tfeq8xmNI9VqY589I3Jc7/5uvMGOpvRqPJxajTZzJo8I2ne/CULU3fZN4/h3dDu/oZ3kAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgGio3ZXzlyysah1/MmvyjMr3meLxo9+UPvl1NxS3kE6trX6XKQ6f9HjSvIs1ueCVlOfFfZ5Knvvjh25Kmrdw9erkfb42eWZ+29w8PnnuGVtekTRvVPc5FdbVOyesTJ/71rPTJi5J3mXfuOrKi5Lm/eUdf1PwSsoxdtLzyXMfPintce7PTu7CY1zF/urwv0+aN+7qW9J32ieP4914HregT7JJNfXSo5LnLv5QgQsZwSD1DbyDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAADRULsr37bLvskbvv8fXpU0b2v9KnmfVbrthDPSJ59Q3Dp60cEPviV57tPv3yRx5v3J+6xaeOH55LmzJs8ocCWdWbC2un2dseWN1e2sz0z9yQeS50479L8LXElnqrzddMP1O10+itmfL2wdI7lvz3npk/dMm7b/6Xul77NCb/zwUclzfzXvzKR53bgPTzGadY7ZcMOkeWtXrEjeZ5VGk83Q1ClJ8x44MO32lvnwKObms+1F6TW11TVrkuZdu+Sbyftsh3eQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAyCGEbq8BAAAAAHoC7yABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAESFNEi2j7F9i+3Vtuc1XP4G2wts/8H2E7Yvtf2KNtvZxPb3bK+y/ZDtg4tYXzcVmE3T7fSzIrKxvb7ts+PtZYXt22zvV9lBlKhNPjvEy5fF009s79BmO3Wqq7zZ1KmuOs5mUOuqk39v2yfZDrb3brOdKbavsf2s7bvbje0XBWZziu07bb9oe05Z661SEdnY3sz2xbaX2F5u+5e2dy114RVoc39nSwDdAAAgAElEQVQzJeaxsuF0Ypvt1KamErKpTU3lyabsmirqHaQlkk6VdM6wyzeWdJakKZK2lrRC0rfabOd0Sc9L2lzSIZLm2p5e0Bq7pahsWm2nnxWRzZCkRyTtIWkjSSdKusT2lMJXW71W+SyR9G5Jm0h6maQfSvp2m+3Uqa7yZlOnusqTzaDWVdt/b9vbKMvo9yNs52JJt0naVNInJF1m++UFrrMbisrmPkkflXRFoavrriKymSjpZkm7KKvBcyVdYXtisUut3Ej3oS8NIUyMp1PabKd2NaXOs6ldTamzbEqtqUIapBDC5SGE70t6atjlV4UQLg0hPBNCeFbS1yW9udk2bE+QNFvSiSGElSGE65U9gL+viDV2SxHZtNtOPysimxDCqhDCnBDC4hDC2hDCf0l6UFnB9LU2+TwdjzdIsqQ1krZtto0a1lXH2bTbTj8rIptBrasO/r2/Lulflb2g0JTt7SS9VtJJIYTnQgjflXSnsjrrW0VkE7dzbgjhKmUvbA2EIrIJITwQQvhyCOH3IYQ1IYSzJK0n6dXFr7g6RdyH1rimOt1OHWuqk22UWlNDRWwkh90lLWpx3XaS1oQQ7mm47HZlr2DWQbts6q7jbGxvruy2NPBZ2n5a2SsoYyR9ssWwWtZVh9nUUko2dagr2wdKej6EcKXtdkOnS3oghND4ZOX2ePlAypFN7aRmY3uGsidz95W1th7xkO0gaYGk40MITzYZU7uaijrJpq5yZ1N0TVX2Iw22d1L2YHx8iyETJS0fdtlySRuWua5e0EE2tZUnG9vjJF0o6dwQwt1lr63bQggvVfbxp2OUfTShmVrWVYfZ1FLebOpQV/EjGZ+R9C8dDK9VTeXMplZSs7E9SdL5kk4OIQy/LQ2KJyX9hbKPye+irD4ubDG2VjWlfNnUTVI2ZdRUJe8g2d5W0lWS/jmEcF2LYSslTRp22SQN0FuKzXSYTS3lycb2GGXF8byyJ361EEJYZftMSU/Y3j6E8PiwIbWsK6mjbGqr02xqVFcnSzo/hPBgB2PrVlN5sqmb3NnYfomkH0m6MYTw2dJW1mUhhJWSbolnH7N9jKTf254UQnhm2PBa1VTObGolJZuyaqr0d5Bsby3pJ5JOCSGc32boPZKGbE9ruGxnDfZHOjrNpnbyZOPscw1nK/sRgtkhhBcqWGIvGSNpA0lbNrmudnU1TLts6q5tNjWrq70k/ZPtpbaXSnqlsh+l+NcmYxdJmmq78dXtQa6pPNnUTa5sbK8v6fuSfifpyOqW2RNC/LPZ5xDrVlPDtcum7tpmU2ZNFfUz30O2x0saK2ms7fHxsi0l/UzS6SGEM5vMO9z2Yil7RVPS5ZI+ZXuC7TdLOkDZq5d9q4hs2m2nosMoRVHZSJoraXtJbw8hPFfF2qvQJp99bM+0PTa+rfxlScsk3RXn1bmuOs6m3XaqP6LiFJWNBrCu2vx77yVpR0kz4mmJsgfb0+O8ObavlaT4fb6Fkk6K898laSdJ3636eIpURDbx/Li4nTHKXpwZb3tstUdTrCKycfZR1cskPSfp0BDC2soPpARt7m92tf1q22Nsbyrpa5KuXffxpzrXVJ5s4vna1FSebEqvqRDCqE+S5ijr8hpPcySdFP++svHUMO9ESRc2nN9EWSe4StLDkg4uYn3dPBWYTdPtdPv4up2Nss+pBkl/HDb+kG4fX4n5HCjp7nicT0i6UtJObW47daqrvNnUqa46zmZQ66rTf29JiyXt3XD+bEmfbjg/RdK1yh6Yf9s4tl9PBWYzr8l2Du/28XU7G2U/jBMkPTuspnbr9vGVkY2kv1P2y5erlP38+XmStmhzu6lNTSVkU5uaypNN2TXluJOusH21su+X3NW1RfQosmmNbNojn9bIpjWyac32Qkl7hRAG5ufgi0I2rZFNa2TTGtm0VmU2XW2QAAAAAKCXVPYz3wAAAADQ62iQAAAAACCiQQIAAACAqO3P2U798peSv6B038H/368zd2SPI49I3aWu+8Hxlf2G/Nql05KzmTV5RtK8+UsWpu5SY7a4t7Jstv/EV5KzWfShM5LmpWYqSQvWXlrp/z3wjuuOSc7nzltflTTv/oPS6lGq9rYz5fQvJmcz7UO/LnIpHanytjOa+5xUJz+xQ/rcP/9BZdnsM+bAyrPpl/vj0WQzmmNMVWU2o6mpd9y7b9K81XssTd1l39zfjObxOFWV2YympsZuuknSvCvv/FnqLvumpuY9s1nSvMMnpf8f8O2y4R0kAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgGmp35TYfuTF5w7M+MiNp3ur39kfPtts/Hpk8dwP9usCV9J6tPntD8tztdj40ad49S85L3mfVntvjseS52ypt7rz9N0ve5we2SJ6a2wOzv5E+eXbatP13f1f6PvvErL9JqyvdeEf6TtemT83LM6cnz/3xFRcWuJLeM3/JwuS5syanPY6PxoIKbzejOb7V+78yad7QWyYn73PQjZ3+6m4voSPdqKnR3FarrKnRuPg1abVxsdJrql02/dGNAAAAAEAFaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIhsra8PwlCxNnps6TpA+PYm4+G3zv18lz07PpE3by1FcddEfaxCXJu6zcPWe/LnnumPXWJM07fFJ/3OYefnFl8tyPPHxA0ry1D/0ueZ9V+vMvH508d+F3v540b/8tX5u8zyr94dTnK9/n/tPfkjz3x08VuJAR3PjHtPuM0fj2IzdUvs8U98x9ffLcBw84K2ne1O8embzPfpH6HGfW5IIX0oOWXTEtad5NMy8teCW9J7xp56R5vuH2gleS4R0kAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACCiQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgcgih22sAAAAAgJ7AO0gAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABEhTRIto+xfYvt1bbnDbtuA9tn2H7S9nLbv2iznU1sf8/2KtsP2T64iPV1U4HZtNxOvyoiG9vr2z473l5W2L7N9n6VHEDJWuVj+xDbKxtOz9oOtndpsZ3a1FVCNrWpqzzZDGpdjXCf8x7bd8Xj/Y3td7bZzvq2z7H9jO2lto8rffElKzCb99i+Id6+ri173VUoMJsv2r43jr3b9qGlL75kI2Tz97bvi/c3P7Y9uc12avM4Fa/Lk01tHqfidR1lU/bjVFHvIC2RdKqkc5pcd5akTSRtH/88ts12Tpf0vKTNJR0iaa7t6QWtsVuKyqbddvpVEdkMSXpE0h6SNpJ0oqRLbE8peK3d0DSfEMKFIYSJ606Sjpb0gKT/brGd2tRVQja1qauc2QxqXTXNxvaWki6QdJykSZKOl3SR7c1abGeOpGmStpb0Fkkftb1vSWuuSlHZ/EHSVyV9rrylVq6obFZJeruymjpM0r/bflNZi65Iq2z2kPQZSQcoewx/UNLFbbZTm8ephGxq8ziVM5tSH6eGithICOFySbL9Oklbrbvc9qslvUPSViGEZ+LFtzbbhu0JkmZL2jGEsFLS9bZ/KOl9kv6tiHV2QxHZtNtOPysimxDCKmVPVtb5L9sPStpF0uLiV12dHP/mh0k6L4QQhl9Rt7pqomU2ObfTN4rIZlDrqk02W0l6OoRwVTx/he1VkraR9HiTTR0q6f0hhGWSltn+pqTDJf24rLWXrahsQgg/idv5+3JXXJ0Cszmp4eyvbV8n6Y2Sbihl4RVok83bJV0aQlgUrz9F0u9sbxNCuL9xGzV8nOo4mxG207eKyKbsx6myv4O0q6SHJJ3s7KNSd9qe3WLsdpLWhBDuabjsdkn9/gpCK3myqZvkbGxvruy2tKjMBfYK21tL2l3SeS2G1K2u/qSDbGorbzY1qKtbJN1l+x22x8aPSa2WdMfwgbY3ljRZWR2tM8g11XE2NZScje2XSPoLDW5NOZ4az0vSjk3G1u1xKk82dZOcTdGPU2U3SFspO6jlyh5QjpF0ru3tm4ydGMc1Wi5pw1JX2D15sqmbpGxsj5N0oaRzQwh3l77K3nCopOtCCA+2uL5uddVopGzqrONs6lBXIYQ1yprFi5Q9wb1I0pHxFcrhJsY/G+tqYGsqZza1MspszlTWBMwvb4VddaWk99jeKTaDn5QUJG3QZGzdHqfyZFM3SdmU8ThVdoP0nKQXJJ0aQng+hPBzSddIemuTsSuVfYa30SRJK8pdYtfkyaZucmdje4yk85V9hvmYSlbZGw6VdG6b6+tWV41GyqbOOsqmLnVle29Jp0naU9J6yj7T/p+2ZzQZvjL+2VhXA1tTObOpldRsbH9B2YuA72n18d9+F0L4qaSTJH1X2SdCFiurkUebDK/V41TObGolJZuyHqfKbpDyvAV/j6Qh29MaLttZg/v2Mx9PaC1XNrYt6WxlX+6cHUJ4oZRV9Rjbb1b2DttlbYbVra4kdZxNLXWaTc3qaoakX4QQbgkhrA0h3Czp15L2Hj4wfu/o98rqaJ1BrqmOs6mh3NnYPlnSfpLe2vAd24EUQjg9hDAthLCZsie8Q5L+p8nQ2j1O5cimdvJkU+bjVFE/8z1ke7yksZLG2h5ve0jSLyQ9LOljccyblb3SMj/OO9z2YulPX7a6XNKnbE+IYw9Q1hX2rSKyGWE7fauobCTNVfZrd28PITxX5TGUqYN/88MkfTeEsGLYvDrX1TojZtPhdvpOUdloAOuqTTY3S9pt3Sv/tmdK2k3xxRrbe9pufKX/PEkn2N7Y9msk/R9J8yo8lMIVlU38Ls54ZU9qxsTtjKv6eIpUYDYfk3SwpH1CCE9VfRxlaJVN/HNHZ/5M2S/T/nt8gaHWj1N5smm3nS4cUmGKykZlPk6FEEZ9UvYrEmHYaU68brqkXyn7ecvfSHpXw7wTJV3YcH4TSd+PYx+WdHAR6+vmqcBsWm6nX09FZKPsZ3aDpD8qe5t+3emQbh9fyfmMl/S0pL2azKt7XeXJpm511VE2g1pXI2RzjKT7lH2c4wFJH26Y9z5JNzScX1/Zz9M+I+kxScd1+9h6KJvDm2xnXrePr0eyCcq+q9RYUx/v9vGVkY2klyprFFdJWirps5LGNsyr7eNUQjYtb3/9eioiG5X8OOW4k66wfbWkfw4h3NW1RfQosmmNbNojn9bIpjWyac32fyr76dlB/UJ9MrJpjWxa4/6mNbJprcpsutogAQAAAEAvKftHGgAAAACgb9AgAQAAAEBEgwQAAAAAUdufCdxnzIF99QWlBWsvdVX7Wrt0WnI2syZX///r9Us2O8w9OmneK0+5IXWXlWYjSW/Z+3PJ+YTElzRWf2RZ6i71q7d+vi9uO284/qikeRtdeGPqLvumrh58YeXIg5p41biJqbvUmC3urSybbjxWzV+yMHku2bRWZTYPP/qK5Gx2/9GHk+a95hN3p+5SP/7Df/bF7WbxqW9MmjflhF+l7rLS++LRZDP7rseT5h2x0ZLUXVZaU7sd8IXkbB5+W9q8B99xVuou22bDO0gAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEA01O7K+UsWJm941uQZSfPuPe+1yfus0kEP/tUoZv8hadbQq7YexT6rsyasTZ479o8FLqRH/fSCs7u9hJw+X9meUu83JOnGJWcmzdv/6n2S91mlk5/YIXnuRXe/LmnelL+9I3mfC9LvBnIbzWPVoOvG4/g23zkqeZ8P/nPy1Ny2GpqYPHejRWOT5q15ennyPqu02x3pD8bzXzY3beIHknfZN8764gFJ8444JTHTiv38G2clz91h7tFJ80bzvKHd4xTvIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABANFTWhucvWZg4M3WeJH1sFHPz+farfpY8d+Y/Hp00b4tfPp28zyqNdXrffeexZyTN2/err0/eZ9VmTZ7R7SXksmBtt1fQmW0v/IekeffdPrfglZTjpJf/JnnuRf+1R4Er6T1Tv3tk8txpH/p10rxlV0xL3uct+yVP7Qv3/+2Zo5j94cLWUabbTkh7rJrptMf/ql230/jkuR+/baekeb/85BuS93ndD5Kn5pb+/FZ6zwObJs0bzfOGfnkMf+UpN3R7Cf8L7yABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAACRQwjdXgMAAAAA9ATeQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiAppkGyvb/ts2w/ZXmH7Ntv7NVy/l+27bT9r+xrbW7fZ1pQ45tk4Z+8i1tgtBWdziu07bb9oe04lB1CiorKxvZnti20vsb3c9i9t71rdkRSvXTa217N9me3FtoPtPUfY1ia2v2d7VdzewZUcREkKzuYY27fYXm17XhXrL1NR2YxUm/1ohGzeYHuB7T/YfsL2pbZf0WZbdaqpvNnUqaY6zmYQa0oaMZ8d4m1hWTz9xPYObbZVp7rKm02d6qrjbMqsq6LeQRqS9IikPSRtJOlESZc4a3ZeJunyeNkmkm6R9J0227pY0m2SNpX0CUmX2X55QevshiKzuU/SRyVdUeqKq1NUNhMl3Sxplzj2XElX2J5Y7vJL1TKbeP31kt4raWkH2zpd0vOSNpd0iKS5tqcXvN4qFZnNEkmnSjqn8FV2R1HZjLSdftTumDaWdJakKZK2lrRC0rfabKtONZU3mzrVVJ5sBrGmpPbHtUTSu5U9Lr9M0g8lfbvNtupUV3mzqVNd5cmmvLoKIZRyknSHpNmSjpB0Q8PlEyQ9J+k1TeZsJ2m1pA0bLrtO0lFlrbMbp5Rshs2/QNKcbh9HL2bTMP4ZSbt0+3jKyGbYZY9K2rPNnAnKHnC2a7jsfEmf6/bxdDubYWNPlTSv28fRi9m0206/n1odk6TXSlrRYk5ta2qkbIaNq1VN5clmpO30+6nFfc6QpH+U9GyLObWtq5GyGTa2VnWVJ5t220k5lfIdJNubK2t2FkmaLun2ddeFEFZJuj9ePtx0SQ+EEFY0XHZ7i7F9aRTZDLyisrE9Q9J6yt5xGwjDssljO0lrQgj3NFw2yDWFBkVlM4gZj3BMu7e4XKKm2mUz8IrKZhBrSmp+XLaflvRHSf8h6TMtptayrjrMZuAVlU2RdTU02g0MZ3ucpAslnRtCuDt+zOmJYcOWS9qwyfSJ8brhY7csep3dMMpsBlpR2diepOxVp5NDCMNvS31peDY5p7eqqYG4jY0ym4FWVDaDmHG7Y7K9k6RPSjqgxfTa1lQH2Qy0orIZxJqSWh9XCOGltidIOkzSQy2m17KuOsxmoBWVTdF1VWiDZHuMsienz0s6Jl68UtKkYUMnKfus7nB5xvaVArIZWEVlY/slkn4k6cYQwmdLWGrlWmSTx8DexgrIZmAVlc0gZtzumGxvK+kqSf8cQriuxSZqWVMdZjOwispmEGtKGvm4QgirbJ8p6Qnb24cQHh82pJZ1JXWUzcAqKpsy6qqwj9jZtqSzlX25bnYI4YV41SJJOzeMmyBpGzV/+2uRpKm2G18x2LnF2L5RUDYDqahsbK8v6fuSfifpyDLXXJU22eRxj6Qh29MaLhvkmqq9orIZxIzbHZOzX8n8iaRTQgjnt9lM7WoqRzYDqahsBrGmpFzHNUbSBmr+qaDa1dUw7bIZSEVlU1ZdFfkdpLmStpf09hDCcw2Xf0/SjrZn2x6v7C3oO9a9/WV7ju1rJSl+9nShpJNsj7f9Lkk7SfpugevshlFnE8+Pi+PGKLsjGW97bGVHUY5RZxPfVr1M2Y84HBpCWFvlAZSoVTbrftpyfDy7XrwtOF53uO3F0p++u3W5pE/ZnmD7zco+AtLvT3JGnU08PxTHjpU0No4t/KPHFSskm3bb6WNNj8n2lpJ+Jun0EMKZwyfVuabyZBPP16am8mbTajsDoFU++9ieaXuss4+/f1nSMkl3xevrXFcdZxPP16mucmXTajujVtAvT2wtKSj7MtXKhtMh8fq9Jd2t7AnstZKmNMw9W9KnG85PiWOek/RbSXsXscZunQrOZl7cVuPp8G4fY7ezUfbzjkHSs8O2s1u3j7HEbBY3uS1MidedKOnChm1touzdtVWSHpZ0cLePr4eymdNk7JxuH2O3sxlpO/14andMkk6K1zVevrJhbm1rKiGb2tRUnmwGsaY6yOdAZY/hK5V9p/hKSTu1ue3Uqa7yZlOnuuo4mzLrynEHXWN7oaS9QghPdXUhPYhsWiOb1mxfreyz8Hd1ey29hmxaI5vWyKY1smmNbNojn9bIprWqsul6gwQAAAAAvaKU/wcJAAAAAPoRDRIAAAAARDRIAAAAABDRIAEAAABA1PY31Kf/4KTkX3BY+cSEpHk37PuV1F1qy61+7+TJOf3lu76QnM0v5p6VNG/HGw9J3aV+8845lWWz7/SPJ2ez5q57k+Y9eeQbU3ep2+YeV1k20uhuOy/5wU1J8x77pzel7lJ3fPXYyvLZZ8yBffWrMQvWXlpZNsuWbJWczXu2Sq+PVFVmM5rbzfwlC4tcSkfGbHEv2bTQL9mEN+088qAmrr7s3NRdVprN2qXTkrP5+GM7Jc27dWb6a/ZV3t+MJptUsybPSJ7bL/fFf71oWdK8D238UOou29YU7yABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQDTU7srJ7/pNVev4k1csmVj5PlP8Yu5ZyXP3OOKIpHlb/tdNyfvU2vSpea25697qdhbdetLcUcw+rrB1dGKrj6bnc9HchUnzZk1O3qX01WNHMTmfZVdMS55708xLk+Zte+3hyfus0kZjXlL5PucvSbu99ZNZk2ckzSOb1u458/XJ+3wo7eExyWj+DVPvU1MzlaQFFT6O77/H3yTPvfLnlyfN2/Pqdybvc9A9cNobu72EjniobVvR1uRxywpcyejxDhIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAAARDRIAAAAAREPtrlz146nJG75+p8uT5/aD/We+NXnu+MduSpr38CfflLzPKs1fsrDbS+hpF73qmsr32S//Jp99Tfr9xvK1zyXN22CD1cn7rNLBD74lee53H70qceb45H32i/u/+IbEmf1RU6Op/bcsOiBp3oPTz0rep3T8KObmM2vyjOS5qbnuNzX19laxZcuTp6bm+uwV45L3WaXR3G4m/OLlSfOmfvRXyfvUR9Kn5hVefDF57uyJzyTN2/FrRyfv8zefaX0d7yABAAAAQESDBAAAAAARDRIAAAAARDRIAAAAABDRIAEAAABARIMEAAAAABENEgAAAABENEgAAAAAENEgAQAAAEBEgwQAAAAAEQ0SAAAAAEQ0SAAAAAAQ0SABAAAAQESDBAAAAACRQwjdXgMAAAAA9ATeQQIAAACAiAYJAAAAACIaJAAAAACIaJAAAAAAIKJBAgAAAICIBgkAAAAAIhokAAAAAIhokAAAAAAgokECAAAAgIgGCQAAAAAiGiQAAAAAiGiQAAAAACAqpEGyvb7ts20/ZHuF7dts79dk3Em2g+2922xriu1rbD9r++52Y/tBwdmcYvtO2y/anlPqwitQVDa2N7N9se0ltpfb/qXtXcs/gvK0yybWSLC9suF0Yptt1aamErKpTU3lyaZuNRWv38D2GbafjMf8izbb2sT292yvits7uJqjKEfB2Rxj+xbbq23Pq+QASlRUNp0+3vWbEe5zDhl2f/NsvA/apcW2alNXCdnUpq7yZFNmXQ0VsZG4nUck7SHpYUn7S7rE9p+HEBZLku1tJL1b0u9H2NbFkn4Vt7G/pMtsTwshPFHQWqtWZDb3SfqopKNKW221ispmoqSbJR0n6XFJH5R0he0pIYSV5S2/VC2zaRjz0hDCix1sqzY11TCm02xqU1MNYzrJplY1Fe9vzopjtpf0B0kz2mzrdEnPS9o8jrvC9u0hhEXlLb9URWazRNKpkmZJekmJa65KUdmM+HjXp9od14WSLlw30Pbhkk6U9N8ttlWnusqbTZ3qKk825dVVCKGUk6Q7JM1uOH9VXPhiSXu3mLOdpNWSNmy47DpJR5W1zm6cUrIZNv8CSXO6fRy9mE3DvGck7dLt4ykjG0lTJAVJQx3MqVVN5clm2PyBr6nUbBq2M8g19ep4fJM6mDNB2ZO47RouO1/S57p9PN3OZtj8UyXN6/Zx9GI2w2VMDFUAAA+FSURBVLfT7eMpK58ml18j6aQWc2pVV3myGTZu4OsqNZuRtpP3VMp3kGxvruyJ2aJ4/kBJz4cQrhxh6nRJD4QQVjRcdnu8fCCMIpuBV1Q2tmdIWk/ZuwMDYXg20UO2H7X9LdsvazG1djUVdZLNwCsqmxrU1K6SHpJ0cvyo1J22Z7eYup2kNSH83/buPUiyqr4D+PfsDrIIkohGcRXBxEUtSFzjk1C+HwtJabQsjEJCSKKJGowWxBitkICixqhVWhVLjGJ4BI0a1JLEctkyokZBXeNKBVHwAVE2SyIisivycE/+6LNWOzUzO3P3dvdMz+dTdWtrbvfv3HO/02d2fn27e+o1Q/umeU0tJZup11c286zNFW++8yqlHJ7kCUkumKd0ta2r4f17y2bq9ZVNn+uq9waplLJfBpfGzq+1fr2UclCSNyR5xSLKD0pyy6x9tyS5R7+znIx9zGaq9ZVNKeXgDJ51OqvWOvuxtCLNzibJ95M8OsnhSR6Zwfq4aJ7yVbWmsrRsplpf2aySNfWAJEdnsDbWJzk1yfmllIfNUb7a1tRSsplqfWUzxzhTYS/ndXKSz9ZavzNP+WpbV8P2ls1U6yubvtdVrw1SKWVNBv+R3pHBD4okOSvJhYv8xu9McvCsfQcnuXWO+64oPWQztfrKppRyQJJLklxRa31j7xOdgLmyqbXurLVurbXeVWu9se1/RvtFdrZVtaaWmM3U6iub1bKmktyW5M4kZ9da76i1fjqDl3U8Y44hVtWaytKymVp9ZTPPOCveIs7r5CTnLzDEaltXw/aWzdTqK5tRrKveGqRSSklybgZvrnturfXOdtNTk/xZKWVHKWVHksMyeAPVq+YY5qokv1xKGX7G4OFZ4Zege8pmKvWVTSll/yQfTXJDkj8Z/cxHb4FsZqt7Sua4bbWtqdkWymYq9ZXNKltTVy5hmGuSzJRSNgztm+Y1tZRsplJf2Sxhba4oezuvUsqxGVxh+5cFhllt62rP7YvJZir1lc3I1lWPb646J8kVSQ6atf9eSQ4d2r6b5IQ990tyZpLLhu5/RZK3JFmX5DlJfpjkl/qa5yS2HrPZr+XyvgzeqLcuydpJn9+ks2m5XJLBL3Od3oC+HLcFsnlsBm8OXtNy+kCSTw3dvprX1FKzWU1ratHZrMI1tV8G7686I4NPRTo2g2euH9puPyXJdUP3/+cMPh3ywHbfW5IcNenzWybZzLR19MYMntFdt9IfQz1mM+c4K33b23ll8El/F8yxf9Wuqw7ZrJp11SGbkayrvk7y8AyejfxJBpdJ92wnzXHf6zL0aWQZdH2vH/r6iCSXZXDp+htZwieXLcet52zOa2MNb6dM+hwnnU0GH+9Yk/x41jiPn/Q5jiKbJC9I8p0kuzL4+PMLkhy6wONm1aypDtmsmjW1lGxW25pqtx+Vwcfh70rytSTPGao9I8lFQ18fkkHzuCuDj5Y9cdLnt4yyOXOONXXmpM9x0tnsbZyVui0in3UZPCn31DlqV/u6Wko2q21dLSqbUa6r0g4wMaWUbRkEcNNEJ7IMyWZ+spmfbOYnm/nJZn6llEuTvLzWevWk57LcyGZ+slmYfOYnm/mNK5uJN0gAAADLxUj+DhIAAMBKpEECAABoNEgAAADNzEI37t6xofMblK65c1enuhe8/s+7HjJfOee0sf2tk6evOaFzNpu3b+tzKouy5tBrx5bNvjxuujr+uOd3rt287XVj/Rs5k3jsHHP6i7seMl+46PSpfuxsWr+xc+2W3R8aWzbH3/9l3bNZ0+25sLtu2N75kOPM5vB/fFPnbI78o619TmVRxpnNvqypF3332E517z7sc10PuWL+r9qXnxtdjfNx8+z/eGnnbD784C2d6lbKz+J9edy87eYjOtW94p7XdT3killTXY3qceMKEgAAQKNBAgAAaDRIAAAAjQYJAACg0SABAAA0GiQAAIBGgwQAANBokAAAABoNEgAAQKNBAgAAaDRIAAAAjQYJAACg0SABAAA0GiQAAIBmZqEbN63fOK55/My9c3n34nP6m8fe3PTCYzrXPvKsbrX3flf3bLbs7lw6Vr/2xRd0qrvflVf3PJPpcvlb92VxnN7bPPbm1Bse27n27+//hU51157/652POU7/9uVPjP2YD/roH4/9mF3c4167Otdu3r6tU93TTvrDzsdcKd592Oc61e3L7w4r5f+qh2zdr1PdJV98RM8zGY0PP3hL59r//Wn39TjtNj/usE51//qop3Q+5r9/snPpquYKEgAAQKNBAgAAaDRIAAAAjQYJAACg0SABAAA0GiQAAIBGgwQAANBokAAAABoNEgAAQKNBAgAAaDRIAAAAjQYJAACg0SABAAA0MwvduHn7ts4Dv+rGjZ3qPvbNX+18zHHa+tp3dq7ddvvtnepe9a7Hdj7mSnHrTQd2qrtfz/MYpes/2P0xftwDF1yy86p33dX5mFt2dy5dsmsf3W1tJEm2dytbM1O7H3OF2LS+28/ju529tueZjMaVj3l/59o33bShU93Np+3sfMxx6vq9T5Kzvv3lHmcyXX545wGd6o586Re7H/TF3UuX6s0/+JXOta885Fud6mbud2jnY47TQ859SefaI269vFPd2k/9Z+djjtNvPuE5nWs//pmPdKq79Xce1/mYC3EFCQAAoNEgAQAANBokAACARoMEAADQaJAAAAAaDRIAAECjQQIAAGg0SAAAAI0GCQAAoNEgAQAANBokAACARoMEAADQaJAAAAAaDRIAAEBTaq2TngMAAMCy4AoSAABAo0ECAABoNEgAAACNBgkAAKDRIAEAADQaJAAAgEaDBAAA0GiQAAAAGg0SAABAo0ECAABoNEgAAACNBgkAAKDppUEqpexfSjm3lHJ9KeXWUspXSinHD93+vFLK1e22r5VSnr2Xsd5bSvlRKWVHKeW0PuY4KT1n87xSyudLKT8upVw2lhMYoZ6zeUsp5dp236+XUk4ez1mMxiKyeWEp5ZullJ2llE+UUtYvMNYhpZSPlFJ2tfFOHM9ZjEbP2ZxaStlaSrm9lHLeWE5ghPrKZm/jAMA06+sK0kyS7yZ5YpJfSHJGkg+WUo4opdw/yT8lOS3JwUlemeR9pZT7zDPWmUk2JDk8yZOT/EUp5bie5jkJfWbzgyRvS/K3I5/1ePSZza4kz2zj/H6St5dSfmPE8x+lhbJ5YpI3JPntJIck+U6S9y8w1juS3JHkvklOSvLOUspRI5z7qPWZzfYkZyd570hnPD59ZTPvOKOcPAAsB6XWOpqBS7kyyVlJvpfkklrrfYZu+78kz6q1Xj5H3Q1J/qDWemn7+nVJNtRanz+SiU5A12yG7vPCJL9ba33SqOc6bvuazdB9P5bk07XWt45ssmM2lM0xSQ6otf5p278+yQ1JHlxr/dasmgOT3Jzk6FrrNW3fhUluqLX+5TjnP0pdsplVf3aSB9RaTxnDdMdqX7OZPU6t9eJRzhcAJm0k70Eqpdw3yZFJrkqyNcnVpZRnlVLWtpdJ3Z7kyjnq7plkfZKvDu3+apKV/Gz3z+mazWrQVzallAOSPLqNMxVmZVPa9rOb279Hz1F6ZJKf7mmOmmleU0vJZur1lc2scQBgqs30PWApZb8kFyU5v9b69bbvgiTvS7Iug5f6nFBr3TVH+UHt31uG9t2S5B59z3MS9jGbqdZzNudk0ARsHtF0x2p2NqWUjyf5QCnlnCTXJvnrJDXJ3ecoPyg/v56SKV5TS8xmqvWVzVxrEwCmWa9XkEopa5JcmMEvs6e2fU9L8ndJnpTkbhm8pv09pZSNcwyxs/178NC+g5Pc2uc8J6GHbKZWn9mUUt6cwTPiz6ujev3oGM2VTa31k0n+JsnFSa5Pcl0Ga+R7cwyxMz+/npIpXlNLzGZq9ZXNXOMAwLTrrUEqpZQk52bwRvDn1lrvbDdtTPKZWuvWWuvuWuuXknwhydNmj1FrvTnJ/yR5+NDuh2eFv6yjj2ymVZ/ZlFLOSnJ8kmfUWn804qmP3ALZpNb6jlrrhvYerYszuBr8X3MMc02SmVLKhqF907ymlpLNVOorm4XGAYBp1ucVpHcmeViSZ9Zabxva/6Ukj9/zzH8p5RFJHp/2XpJSypNKKcPP9F+Q5K9KKfcspTw0yYuSnNfjPCehl2zae3HWZfBLzZpSyrr28peVrK9sXp3kxCRPr7XeNK7Jj9ic2bTv+9Fl4IFJ/iHJ29sTDCmlnFJKuS5J2ksSP5zktaWUA0spx2bwKWYXjvlc+rbP2bSvZ9qaWptkbavv/aXHY9ZLNvONAwBTr9a6z1sGH8ldk/wkg5f07NlOarefmuSbGbyc49tJTh+q/b0knx/6ev8MPnL3R0luTHJaH3Oc1NZzNqe0sYa38yZ9jsskm5rBhzgMj/OaSZ/jKLJJ8osZNIq7kuxI8sYka4dqz0hy0dDXhyT5aLv/fyc5cdLnt4yyOXOONXXmpM9x0tnsbW3abDabzTbN28g+5nuxSinvSfKhWutUvKG+T7KZn2zmV0q5NMnLa61XT3ouy41s5icbABiYeIMEAACwXIzk7yABAACsRBokAACARoMEAADQLPhxtk9fc0LnNyht3r6ta2lnaw69tozrWLt3bBj7m7cuu617P/uUB31jRWSzaf34/0bult0fGls2SfKl6w/vnM9rHvSYPqeyKOPMZ19+5nzv4qM61V11zEVdD7lifuY85LMnd6q7c8fdux4y173s9LGuKwDoiytIAAAAjQYJAACg0SABAAA0GiQAAIBGgwQAANBokAAAABoNEgAAQKNBAgAAaDRIAAAAjQYJAACg0SABAAA0GiQAAIBGgwQAANBokAAAAJqZSU+AxXvU/j+e9BRGbvP2bZ3qNq3f2PNMRueq29dPegrLVtfvf5Js6hjrpnR/7GzZ3bl0rO7YebdOdUe+/IruB31Z91IAmCRXkAAAABoNEgAAQKNBAgAAaDRIAAAAjQYJAACg0SABAAA0GiQAAIBGgwQAANBokAAAABoNEgAAQKNBAgAAaDRIAAAAjQYJAACgmRnVwJvWb+xUV2a6T+nSOzqXLlnX85uULbsnPYPFOe63TupYeVWv8xilkw/+fvfa7d1rp90Bn75vp7rbnnhjzzMZjce8+iWda488//IeZwIA080VJAAAgEaDBAAA0GiQAAAAGg0SAABAo0ECAABoNEgAAACNBgkAAKDRIAEAADQaJAAAgEaDBAAA0GiQAAAAGg0SAABAo0ECAABoNEgAAABNqbVOeg4AAADLgitIAAAAjQYJAACg0SABAAA0GiQAAIBGgwQAANBokAAAAJr/B/7rtXWLSJCzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 90 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize weights for alexnet - first conv layer\n",
    "plot_weights(alexnet, 6, single_channel = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. Activation visualization with PyTorch Hooks\n",
    "\n",
    "Another effective approach to examine what your network is learning, is the visualize your network's features or activations, i.e. intermediate outputs of your network for a specific inputs. \n",
    "\n",
    "Let's use MNIST for this example. Loading train and validation DataLoaders, and generating a similar basic convolutional network to which we used in Lecture 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset = datasets.MNIST(root = 'mnist_data/train', download= True, train = True, transform = transforms.ToTensor())\n",
    "mnist_test_dataset = datasets.MNIST(root = 'mnist_data/test', download= True, train = False, transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "       mnist_train_dataset, batch_size= 8, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "       mnist_test_dataset, batch_size = 8, shuffle = True)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "          '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_Model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (lin_blocks): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MNIST_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Model, self).__init__()\n",
    "    \n",
    "        self.conv1=nn.Conv2d(1, 10, 3)\n",
    "        self.maxpool1=nn.MaxPool2d(2)\n",
    "        self.dropout1=nn.Dropout2d()\n",
    "        \n",
    "        self.conv2=nn.Conv2d(10, 20, 3)\n",
    "        self.maxpool2=nn.MaxPool2d(2)\n",
    "        self.dropout2=nn.Dropout2d()\n",
    "        \n",
    "        self.lin_blocks = nn.Sequential(\n",
    "            nn.Linear(500, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10),\n",
    "            #nn.Softmax(),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        #print(x.shape)\n",
    "        x = self.lin_blocks(x)\n",
    "\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "    \n",
    "net = MNIST_Model() \n",
    "print(net)\n",
    "net = net.to(device)\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "loss_fun = loss_fun.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.315\n",
      "[1,    11] loss: 2.318\n",
      "[1,    21] loss: 2.290\n",
      "[1,    31] loss: 2.310\n",
      "[1,    41] loss: 2.287\n",
      "[1,    51] loss: 2.289\n",
      "[1,    61] loss: 2.332\n",
      "[1,    71] loss: 2.313\n",
      "[1,    81] loss: 2.329\n",
      "[1,    91] loss: 2.304\n",
      "[1,   101] loss: 2.317\n",
      "[1,   111] loss: 2.310\n",
      "[1,   121] loss: 2.338\n",
      "[1,   131] loss: 2.331\n",
      "[1,   141] loss: 2.296\n",
      "[1,   151] loss: 2.306\n",
      "[1,   161] loss: 2.311\n",
      "[1,   171] loss: 2.273\n",
      "[1,   181] loss: 2.239\n",
      "[1,   191] loss: 2.269\n",
      "[1,   201] loss: 2.221\n",
      "[1,   211] loss: 2.280\n",
      "[1,   221] loss: 2.314\n",
      "[1,   231] loss: 2.273\n",
      "[1,   241] loss: 2.235\n",
      "[1,   251] loss: 2.296\n",
      "[1,   261] loss: 2.343\n",
      "[1,   271] loss: 2.223\n",
      "[1,   281] loss: 2.300\n",
      "[1,   291] loss: 2.362\n",
      "[1,   301] loss: 2.329\n",
      "[1,   311] loss: 2.278\n",
      "[1,   321] loss: 2.301\n",
      "[1,   331] loss: 2.176\n",
      "[1,   341] loss: 2.224\n",
      "[1,   351] loss: 2.243\n",
      "[1,   361] loss: 2.265\n",
      "[1,   371] loss: 2.252\n",
      "[1,   381] loss: 2.255\n",
      "[1,   391] loss: 2.243\n",
      "[1,   401] loss: 2.301\n",
      "[1,   411] loss: 2.271\n",
      "[1,   421] loss: 2.261\n",
      "[1,   431] loss: 2.195\n",
      "[1,   441] loss: 2.199\n",
      "[1,   451] loss: 2.188\n",
      "[1,   461] loss: 2.243\n",
      "[1,   471] loss: 2.272\n",
      "[1,   481] loss: 2.211\n",
      "[1,   491] loss: 2.292\n",
      "[1,   501] loss: 2.132\n",
      "[1,   511] loss: 2.236\n",
      "[1,   521] loss: 2.196\n",
      "[1,   531] loss: 2.161\n",
      "[1,   541] loss: 2.184\n",
      "[1,   551] loss: 2.286\n",
      "[1,   561] loss: 2.205\n",
      "[1,   571] loss: 2.139\n",
      "[1,   581] loss: 2.034\n",
      "[1,   591] loss: 2.159\n",
      "[1,   601] loss: 1.811\n",
      "[1,   611] loss: 1.878\n",
      "[1,   621] loss: 1.926\n",
      "[1,   631] loss: 2.126\n",
      "[1,   641] loss: 2.202\n",
      "[1,   651] loss: 1.984\n",
      "[1,   661] loss: 1.928\n",
      "[1,   671] loss: 1.981\n",
      "[1,   681] loss: 2.246\n",
      "[1,   691] loss: 2.142\n",
      "[1,   701] loss: 2.011\n",
      "[1,   711] loss: 1.914\n",
      "[1,   721] loss: 1.308\n",
      "[1,   731] loss: 1.528\n",
      "[1,   741] loss: 1.737\n",
      "[1,   751] loss: 1.702\n",
      "[1,   761] loss: 2.210\n",
      "[1,   771] loss: 1.423\n",
      "[1,   781] loss: 1.444\n",
      "[1,   791] loss: 1.675\n",
      "[1,   801] loss: 1.359\n",
      "[1,   811] loss: 2.088\n",
      "[1,   821] loss: 1.883\n",
      "[1,   831] loss: 1.606\n",
      "[1,   841] loss: 1.056\n",
      "[1,   851] loss: 3.025\n",
      "[1,   861] loss: 1.224\n",
      "[1,   871] loss: 1.397\n",
      "[1,   881] loss: 0.769\n",
      "[1,   891] loss: 0.974\n",
      "[1,   901] loss: 1.101\n",
      "[1,   911] loss: 1.944\n",
      "[1,   921] loss: 1.600\n",
      "[1,   931] loss: 0.764\n",
      "[1,   941] loss: 1.742\n",
      "[1,   951] loss: 1.976\n",
      "[1,   961] loss: 1.055\n",
      "[1,   971] loss: 1.499\n",
      "[1,   981] loss: 0.709\n",
      "[1,   991] loss: 1.374\n",
      "[1,  1001] loss: 0.882\n",
      "[1,  1011] loss: 0.860\n",
      "[1,  1021] loss: 1.131\n",
      "[1,  1031] loss: 1.540\n",
      "[1,  1041] loss: 1.513\n",
      "[1,  1051] loss: 1.328\n",
      "[1,  1061] loss: 1.031\n",
      "[1,  1071] loss: 1.319\n",
      "[1,  1081] loss: 0.820\n",
      "[1,  1091] loss: 0.953\n",
      "[1,  1101] loss: 0.785\n",
      "[1,  1111] loss: 0.814\n",
      "[1,  1121] loss: 0.800\n",
      "[1,  1131] loss: 1.232\n",
      "[1,  1141] loss: 1.052\n",
      "[1,  1151] loss: 1.625\n",
      "[1,  1161] loss: 1.594\n",
      "[1,  1171] loss: 1.079\n",
      "[1,  1181] loss: 1.237\n",
      "[1,  1191] loss: 1.298\n",
      "[1,  1201] loss: 1.624\n",
      "[1,  1211] loss: 2.021\n",
      "[1,  1221] loss: 1.276\n",
      "[1,  1231] loss: 0.695\n",
      "[1,  1241] loss: 1.132\n",
      "[1,  1251] loss: 1.480\n",
      "[1,  1261] loss: 1.015\n",
      "[1,  1271] loss: 1.486\n",
      "[1,  1281] loss: 1.097\n",
      "[1,  1291] loss: 1.572\n",
      "[1,  1301] loss: 0.961\n",
      "[1,  1311] loss: 0.952\n",
      "[1,  1321] loss: 2.020\n",
      "[1,  1331] loss: 0.788\n",
      "[1,  1341] loss: 1.166\n",
      "[1,  1351] loss: 0.897\n",
      "[1,  1361] loss: 0.744\n",
      "[1,  1371] loss: 0.647\n",
      "[1,  1381] loss: 1.511\n",
      "[1,  1391] loss: 1.092\n",
      "[1,  1401] loss: 0.897\n",
      "[1,  1411] loss: 0.718\n",
      "[1,  1421] loss: 0.819\n",
      "[1,  1431] loss: 0.695\n",
      "[1,  1441] loss: 0.793\n",
      "[1,  1451] loss: 1.005\n",
      "[1,  1461] loss: 0.605\n",
      "[1,  1471] loss: 0.616\n",
      "[1,  1481] loss: 0.876\n",
      "[1,  1491] loss: 1.418\n",
      "[1,  1501] loss: 0.641\n",
      "[1,  1511] loss: 0.950\n",
      "[1,  1521] loss: 1.300\n",
      "[1,  1531] loss: 0.487\n",
      "[1,  1541] loss: 2.014\n",
      "[1,  1551] loss: 1.413\n",
      "[1,  1561] loss: 0.443\n",
      "[1,  1571] loss: 2.017\n",
      "[1,  1581] loss: 0.696\n",
      "[1,  1591] loss: 0.548\n",
      "[1,  1601] loss: 0.197\n",
      "[1,  1611] loss: 1.523\n",
      "[1,  1621] loss: 0.311\n",
      "[1,  1631] loss: 1.041\n",
      "[1,  1641] loss: 0.860\n",
      "[1,  1651] loss: 0.599\n",
      "[1,  1661] loss: 1.628\n",
      "[1,  1671] loss: 1.511\n",
      "[1,  1681] loss: 0.560\n",
      "[1,  1691] loss: 1.086\n",
      "[1,  1701] loss: 1.046\n",
      "[1,  1711] loss: 0.503\n",
      "[1,  1721] loss: 0.811\n",
      "[1,  1731] loss: 0.689\n",
      "[1,  1741] loss: 0.375\n",
      "[1,  1751] loss: 1.586\n",
      "[1,  1761] loss: 0.915\n",
      "[1,  1771] loss: 0.418\n",
      "[1,  1781] loss: 1.141\n",
      "[1,  1791] loss: 0.965\n",
      "[1,  1801] loss: 1.291\n",
      "[1,  1811] loss: 0.633\n",
      "[1,  1821] loss: 0.404\n",
      "[1,  1831] loss: 1.904\n",
      "[1,  1841] loss: 0.524\n",
      "[1,  1851] loss: 0.666\n",
      "[1,  1861] loss: 0.317\n",
      "[1,  1871] loss: 0.528\n",
      "[1,  1881] loss: 1.190\n",
      "[1,  1891] loss: 0.503\n",
      "[1,  1901] loss: 1.280\n",
      "[1,  1911] loss: 1.202\n",
      "[1,  1921] loss: 0.707\n",
      "[1,  1931] loss: 0.288\n",
      "[1,  1941] loss: 0.499\n",
      "[1,  1951] loss: 0.832\n",
      "[1,  1961] loss: 0.507\n",
      "[1,  1971] loss: 0.393\n",
      "[1,  1981] loss: 0.508\n",
      "[1,  1991] loss: 0.827\n",
      "[1,  2001] loss: 0.261\n",
      "[1,  2011] loss: 0.444\n",
      "[1,  2021] loss: 0.486\n",
      "[1,  2031] loss: 0.529\n",
      "[1,  2041] loss: 0.711\n",
      "[1,  2051] loss: 1.501\n",
      "[1,  2061] loss: 1.095\n",
      "[1,  2071] loss: 1.137\n",
      "[1,  2081] loss: 0.833\n",
      "[1,  2091] loss: 0.269\n",
      "[1,  2101] loss: 1.287\n",
      "[1,  2111] loss: 1.312\n",
      "[1,  2121] loss: 0.472\n",
      "[1,  2131] loss: 0.497\n",
      "[1,  2141] loss: 0.195\n",
      "[1,  2151] loss: 0.574\n",
      "[1,  2161] loss: 0.664\n",
      "[1,  2171] loss: 1.284\n",
      "[1,  2181] loss: 0.835\n",
      "[1,  2191] loss: 1.634\n",
      "[1,  2201] loss: 0.599\n",
      "[1,  2211] loss: 0.762\n",
      "[1,  2221] loss: 0.711\n",
      "[1,  2231] loss: 1.544\n",
      "[1,  2241] loss: 0.738\n",
      "[1,  2251] loss: 0.826\n",
      "[1,  2261] loss: 0.627\n",
      "[1,  2271] loss: 0.212\n",
      "[1,  2281] loss: 0.623\n",
      "[1,  2291] loss: 0.577\n",
      "[1,  2301] loss: 0.442\n",
      "[1,  2311] loss: 0.261\n",
      "[1,  2321] loss: 1.094\n",
      "[1,  2331] loss: 0.469\n",
      "[1,  2341] loss: 0.593\n",
      "[1,  2351] loss: 0.470\n",
      "[1,  2361] loss: 1.334\n",
      "[1,  2371] loss: 0.129\n",
      "[1,  2381] loss: 0.371\n",
      "[1,  2391] loss: 0.466\n",
      "[1,  2401] loss: 0.707\n",
      "[1,  2411] loss: 0.580\n",
      "[1,  2421] loss: 0.273\n",
      "[1,  2431] loss: 0.289\n",
      "[1,  2441] loss: 0.327\n",
      "[1,  2451] loss: 0.320\n",
      "[1,  2461] loss: 0.325\n",
      "[1,  2471] loss: 1.141\n",
      "[1,  2481] loss: 0.215\n",
      "[1,  2491] loss: 0.399\n",
      "[1,  2501] loss: 0.496\n",
      "[1,  2511] loss: 0.156\n",
      "[1,  2521] loss: 0.508\n",
      "[1,  2531] loss: 0.509\n",
      "[1,  2541] loss: 0.149\n",
      "[1,  2551] loss: 1.242\n",
      "[1,  2561] loss: 0.395\n",
      "[1,  2571] loss: 0.606\n",
      "[1,  2581] loss: 0.243\n",
      "[1,  2591] loss: 0.500\n",
      "[1,  2601] loss: 0.393\n",
      "[1,  2611] loss: 0.041\n",
      "[1,  2621] loss: 0.289\n",
      "[1,  2631] loss: 1.039\n",
      "[1,  2641] loss: 0.344\n",
      "[1,  2651] loss: 0.560\n",
      "[1,  2661] loss: 0.097\n",
      "[1,  2671] loss: 0.418\n",
      "[1,  2681] loss: 0.078\n",
      "[1,  2691] loss: 0.509\n",
      "[1,  2701] loss: 0.629\n",
      "[1,  2711] loss: 0.901\n",
      "[1,  2721] loss: 0.266\n",
      "[1,  2731] loss: 0.708\n",
      "[1,  2741] loss: 0.378\n",
      "[1,  2751] loss: 0.848\n",
      "[1,  2761] loss: 0.133\n",
      "[1,  2771] loss: 0.693\n",
      "[1,  2781] loss: 0.680\n",
      "[1,  2791] loss: 0.678\n",
      "[1,  2801] loss: 1.851\n",
      "[1,  2811] loss: 0.145\n",
      "[1,  2821] loss: 0.265\n",
      "[1,  2831] loss: 0.290\n",
      "[1,  2841] loss: 0.479\n",
      "[1,  2851] loss: 0.144\n",
      "[1,  2861] loss: 1.062\n",
      "[1,  2871] loss: 0.783\n",
      "[1,  2881] loss: 0.869\n",
      "[1,  2891] loss: 0.200\n",
      "[1,  2901] loss: 0.323\n",
      "[1,  2911] loss: 0.315\n",
      "[1,  2921] loss: 0.531\n",
      "[1,  2931] loss: 0.121\n",
      "[1,  2941] loss: 1.242\n",
      "[1,  2951] loss: 3.204\n",
      "[1,  2961] loss: 1.406\n",
      "[1,  2971] loss: 0.277\n",
      "[1,  2981] loss: 0.852\n",
      "[1,  2991] loss: 0.541\n",
      "[1,  3001] loss: 0.580\n",
      "[1,  3011] loss: 0.540\n",
      "[1,  3021] loss: 0.242\n",
      "[1,  3031] loss: 0.185\n",
      "[1,  3041] loss: 0.346\n",
      "[1,  3051] loss: 0.498\n",
      "[1,  3061] loss: 1.801\n",
      "[1,  3071] loss: 0.158\n",
      "[1,  3081] loss: 0.937\n",
      "[1,  3091] loss: 0.297\n",
      "[1,  3101] loss: 0.583\n",
      "[1,  3111] loss: 0.275\n",
      "[1,  3121] loss: 0.374\n",
      "[1,  3131] loss: 0.667\n",
      "[1,  3141] loss: 0.106\n",
      "[1,  3151] loss: 1.260\n",
      "[1,  3161] loss: 0.187\n",
      "[1,  3171] loss: 0.191\n",
      "[1,  3181] loss: 1.348\n",
      "[1,  3191] loss: 0.727\n",
      "[1,  3201] loss: 0.172\n",
      "[1,  3211] loss: 0.313\n",
      "[1,  3221] loss: 0.395\n",
      "[1,  3231] loss: 0.801\n",
      "[1,  3241] loss: 0.458\n",
      "[1,  3251] loss: 0.546\n",
      "[1,  3261] loss: 1.515\n",
      "[1,  3271] loss: 0.215\n",
      "[1,  3281] loss: 0.465\n",
      "[1,  3291] loss: 0.469\n",
      "[1,  3301] loss: 1.565\n",
      "[1,  3311] loss: 0.341\n",
      "[1,  3321] loss: 0.208\n",
      "[1,  3331] loss: 0.412\n",
      "[1,  3341] loss: 0.190\n",
      "[1,  3351] loss: 0.514\n",
      "[1,  3361] loss: 0.377\n",
      "[1,  3371] loss: 0.248\n",
      "[1,  3381] loss: 0.758\n",
      "[1,  3391] loss: 0.278\n",
      "[1,  3401] loss: 1.241\n",
      "[1,  3411] loss: 0.156\n",
      "[1,  3421] loss: 0.419\n",
      "[1,  3431] loss: 0.286\n",
      "[1,  3441] loss: 0.933\n",
      "[1,  3451] loss: 0.575\n",
      "[1,  3461] loss: 0.065\n",
      "[1,  3471] loss: 0.620\n",
      "[1,  3481] loss: 0.165\n",
      "[1,  3491] loss: 0.651\n",
      "[1,  3501] loss: 0.106\n",
      "[1,  3511] loss: 0.084\n",
      "[1,  3521] loss: 0.135\n",
      "[1,  3531] loss: 0.666\n",
      "[1,  3541] loss: 0.449\n",
      "[1,  3551] loss: 1.332\n",
      "[1,  3561] loss: 0.778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  3571] loss: 1.141\n",
      "[1,  3581] loss: 0.151\n",
      "[1,  3591] loss: 0.335\n",
      "[1,  3601] loss: 0.152\n",
      "[1,  3611] loss: 0.351\n",
      "[1,  3621] loss: 0.472\n",
      "[1,  3631] loss: 0.050\n",
      "[1,  3641] loss: 0.332\n",
      "[1,  3651] loss: 0.288\n",
      "[1,  3661] loss: 0.235\n",
      "[1,  3671] loss: 0.902\n",
      "[1,  3681] loss: 0.127\n",
      "[1,  3691] loss: 0.274\n",
      "[1,  3701] loss: 0.214\n",
      "[1,  3711] loss: 0.412\n",
      "[1,  3721] loss: 1.259\n",
      "[1,  3731] loss: 0.315\n",
      "[1,  3741] loss: 0.281\n",
      "[1,  3751] loss: 0.792\n",
      "[1,  3761] loss: 0.342\n",
      "[1,  3771] loss: 0.530\n",
      "[1,  3781] loss: 0.145\n",
      "[1,  3791] loss: 0.299\n",
      "[1,  3801] loss: 0.287\n",
      "[1,  3811] loss: 0.349\n",
      "[1,  3821] loss: 0.236\n",
      "[1,  3831] loss: 0.441\n",
      "[1,  3841] loss: 0.444\n",
      "[1,  3851] loss: 0.240\n",
      "[1,  3861] loss: 0.737\n",
      "[1,  3871] loss: 0.095\n",
      "[1,  3881] loss: 0.249\n",
      "[1,  3891] loss: 0.083\n",
      "[1,  3901] loss: 0.174\n",
      "[1,  3911] loss: 0.594\n",
      "[1,  3921] loss: 1.464\n",
      "[1,  3931] loss: 0.283\n",
      "[1,  3941] loss: 0.187\n",
      "[1,  3951] loss: 0.341\n",
      "[1,  3961] loss: 0.336\n",
      "[1,  3971] loss: 0.281\n",
      "[1,  3981] loss: 0.471\n",
      "[1,  3991] loss: 0.228\n",
      "[1,  4001] loss: 0.807\n",
      "[1,  4011] loss: 0.651\n",
      "[1,  4021] loss: 1.189\n",
      "[1,  4031] loss: 0.335\n",
      "[1,  4041] loss: 0.168\n",
      "[1,  4051] loss: 0.345\n",
      "[1,  4061] loss: 0.440\n",
      "[1,  4071] loss: 1.073\n",
      "[1,  4081] loss: 0.146\n",
      "[1,  4091] loss: 0.199\n",
      "[1,  4101] loss: 0.582\n",
      "[1,  4111] loss: 0.384\n",
      "[1,  4121] loss: 0.684\n",
      "[1,  4131] loss: 0.219\n",
      "[1,  4141] loss: 0.300\n",
      "[1,  4151] loss: 0.299\n",
      "[1,  4161] loss: 0.563\n",
      "[1,  4171] loss: 0.590\n",
      "[1,  4181] loss: 0.849\n",
      "[1,  4191] loss: 1.555\n",
      "[1,  4201] loss: 0.043\n",
      "[1,  4211] loss: 0.680\n",
      "[1,  4221] loss: 0.039\n",
      "[1,  4231] loss: 0.260\n",
      "[1,  4241] loss: 0.203\n",
      "[1,  4251] loss: 0.235\n",
      "[1,  4261] loss: 0.126\n",
      "[1,  4271] loss: 0.780\n",
      "[1,  4281] loss: 0.450\n",
      "[1,  4291] loss: 0.633\n",
      "[1,  4301] loss: 0.205\n",
      "[1,  4311] loss: 1.364\n",
      "[1,  4321] loss: 0.105\n",
      "[1,  4331] loss: 0.133\n",
      "[1,  4341] loss: 0.701\n",
      "[1,  4351] loss: 1.876\n",
      "[1,  4361] loss: 0.993\n",
      "[1,  4371] loss: 0.120\n",
      "[1,  4381] loss: 0.259\n",
      "[1,  4391] loss: 0.834\n",
      "[1,  4401] loss: 0.083\n",
      "[1,  4411] loss: 0.307\n",
      "[1,  4421] loss: 0.406\n",
      "[1,  4431] loss: 0.215\n",
      "[1,  4441] loss: 0.378\n",
      "[1,  4451] loss: 0.186\n",
      "[1,  4461] loss: 1.167\n",
      "[1,  4471] loss: 0.177\n",
      "[1,  4481] loss: 0.275\n",
      "[1,  4491] loss: 0.188\n",
      "[1,  4501] loss: 0.698\n",
      "[1,  4511] loss: 0.618\n",
      "[1,  4521] loss: 0.063\n",
      "[1,  4531] loss: 0.202\n",
      "[1,  4541] loss: 0.425\n",
      "[1,  4551] loss: 0.526\n",
      "[1,  4561] loss: 0.093\n",
      "[1,  4571] loss: 0.085\n",
      "[1,  4581] loss: 0.615\n",
      "[1,  4591] loss: 1.011\n",
      "[1,  4601] loss: 1.018\n",
      "[1,  4611] loss: 0.087\n",
      "[1,  4621] loss: 0.121\n",
      "[1,  4631] loss: 0.037\n",
      "[1,  4641] loss: 0.396\n",
      "[1,  4651] loss: 1.290\n",
      "[1,  4661] loss: 0.192\n",
      "[1,  4671] loss: 0.285\n",
      "[1,  4681] loss: 0.227\n",
      "[1,  4691] loss: 0.607\n",
      "[1,  4701] loss: 0.699\n",
      "[1,  4711] loss: 0.223\n",
      "[1,  4721] loss: 0.177\n",
      "[1,  4731] loss: 0.158\n",
      "[1,  4741] loss: 0.557\n",
      "[1,  4751] loss: 1.241\n",
      "[1,  4761] loss: 1.255\n",
      "[1,  4771] loss: 0.512\n",
      "[1,  4781] loss: 0.386\n",
      "[1,  4791] loss: 0.348\n",
      "[1,  4801] loss: 0.854\n",
      "[1,  4811] loss: 0.556\n",
      "[1,  4821] loss: 0.418\n",
      "[1,  4831] loss: 0.841\n",
      "[1,  4841] loss: 0.317\n",
      "[1,  4851] loss: 0.540\n",
      "[1,  4861] loss: 0.257\n",
      "[1,  4871] loss: 1.950\n",
      "[1,  4881] loss: 0.421\n",
      "[1,  4891] loss: 0.237\n",
      "[1,  4901] loss: 0.507\n",
      "[1,  4911] loss: 0.088\n",
      "[1,  4921] loss: 0.066\n",
      "[1,  4931] loss: 1.215\n",
      "[1,  4941] loss: 0.286\n",
      "[1,  4951] loss: 1.015\n",
      "[1,  4961] loss: 0.868\n",
      "[1,  4971] loss: 0.565\n",
      "[1,  4981] loss: 0.447\n",
      "[1,  4991] loss: 0.221\n",
      "[1,  5001] loss: 0.082\n",
      "[1,  5011] loss: 1.103\n",
      "[1,  5021] loss: 0.355\n",
      "[1,  5031] loss: 1.221\n",
      "[1,  5041] loss: 0.160\n",
      "[1,  5051] loss: 0.246\n",
      "[1,  5061] loss: 0.086\n",
      "[1,  5071] loss: 0.357\n",
      "[1,  5081] loss: 0.137\n",
      "[1,  5091] loss: 0.315\n",
      "[1,  5101] loss: 0.178\n",
      "[1,  5111] loss: 0.136\n",
      "[1,  5121] loss: 0.120\n",
      "[1,  5131] loss: 5.005\n",
      "[1,  5141] loss: 0.317\n",
      "[1,  5151] loss: 0.426\n",
      "[1,  5161] loss: 0.603\n",
      "[1,  5171] loss: 0.864\n",
      "[1,  5181] loss: 0.359\n",
      "[1,  5191] loss: 0.298\n",
      "[1,  5201] loss: 0.474\n",
      "[1,  5211] loss: 0.348\n",
      "[1,  5221] loss: 0.577\n",
      "[1,  5231] loss: 1.040\n",
      "[1,  5241] loss: 0.806\n",
      "[1,  5251] loss: 0.557\n",
      "[1,  5261] loss: 0.072\n",
      "[1,  5271] loss: 0.324\n",
      "[1,  5281] loss: 0.269\n",
      "[1,  5291] loss: 0.484\n",
      "[1,  5301] loss: 0.439\n",
      "[1,  5311] loss: 1.014\n",
      "[1,  5321] loss: 1.135\n",
      "[1,  5331] loss: 0.256\n",
      "[1,  5341] loss: 0.235\n",
      "[1,  5351] loss: 0.073\n",
      "[1,  5361] loss: 0.027\n",
      "[1,  5371] loss: 0.130\n",
      "[1,  5381] loss: 0.082\n",
      "[1,  5391] loss: 0.217\n",
      "[1,  5401] loss: 0.924\n",
      "[1,  5411] loss: 0.198\n",
      "[1,  5421] loss: 0.261\n",
      "[1,  5431] loss: 0.848\n",
      "[1,  5441] loss: 0.072\n",
      "[1,  5451] loss: 0.229\n",
      "[1,  5461] loss: 0.260\n",
      "[1,  5471] loss: 0.863\n",
      "[1,  5481] loss: 0.425\n",
      "[1,  5491] loss: 0.515\n",
      "[1,  5501] loss: 0.402\n",
      "[1,  5511] loss: 0.087\n",
      "[1,  5521] loss: 0.491\n",
      "[1,  5531] loss: 0.661\n",
      "[1,  5541] loss: 0.089\n",
      "[1,  5551] loss: 0.496\n",
      "[1,  5561] loss: 0.063\n",
      "[1,  5571] loss: 2.041\n",
      "[1,  5581] loss: 0.543\n",
      "[1,  5591] loss: 0.151\n",
      "[1,  5601] loss: 0.737\n",
      "[1,  5611] loss: 0.222\n",
      "[1,  5621] loss: 0.250\n",
      "[1,  5631] loss: 0.047\n",
      "[1,  5641] loss: 0.176\n",
      "[1,  5651] loss: 0.358\n",
      "[1,  5661] loss: 0.391\n",
      "[1,  5671] loss: 0.353\n",
      "[1,  5681] loss: 0.011\n",
      "[1,  5691] loss: 0.360\n",
      "[1,  5701] loss: 0.307\n",
      "[1,  5711] loss: 0.616\n",
      "[1,  5721] loss: 0.536\n",
      "[1,  5731] loss: 0.390\n",
      "[1,  5741] loss: 0.126\n",
      "[1,  5751] loss: 1.490\n",
      "[1,  5761] loss: 1.580\n",
      "[1,  5771] loss: 0.399\n",
      "[1,  5781] loss: 0.135\n",
      "[1,  5791] loss: 0.098\n",
      "[1,  5801] loss: 0.209\n",
      "[1,  5811] loss: 0.108\n",
      "[1,  5821] loss: 0.102\n",
      "[1,  5831] loss: 0.569\n",
      "[1,  5841] loss: 0.327\n",
      "[1,  5851] loss: 0.259\n",
      "[1,  5861] loss: 0.771\n",
      "[1,  5871] loss: 0.085\n",
      "[1,  5881] loss: 0.130\n",
      "[1,  5891] loss: 0.393\n",
      "[1,  5901] loss: 0.188\n",
      "[1,  5911] loss: 0.234\n",
      "[1,  5921] loss: 0.483\n",
      "[1,  5931] loss: 0.242\n",
      "[1,  5941] loss: 0.376\n",
      "[1,  5951] loss: 0.165\n",
      "[1,  5961] loss: 0.334\n",
      "[1,  5971] loss: 0.292\n",
      "[1,  5981] loss: 0.132\n",
      "[1,  5991] loss: 0.024\n",
      "[1,  6001] loss: 0.462\n",
      "[1,  6011] loss: 0.774\n",
      "[1,  6021] loss: 0.608\n",
      "[1,  6031] loss: 0.174\n",
      "[1,  6041] loss: 0.393\n",
      "[1,  6051] loss: 0.558\n",
      "[1,  6061] loss: 0.053\n",
      "[1,  6071] loss: 0.131\n",
      "[1,  6081] loss: 0.477\n",
      "[1,  6091] loss: 0.279\n",
      "[1,  6101] loss: 0.322\n",
      "[1,  6111] loss: 0.212\n",
      "[1,  6121] loss: 0.106\n",
      "[1,  6131] loss: 0.212\n",
      "[1,  6141] loss: 0.500\n",
      "[1,  6151] loss: 0.169\n",
      "[1,  6161] loss: 1.113\n",
      "[1,  6171] loss: 3.596\n",
      "[1,  6181] loss: 0.248\n",
      "[1,  6191] loss: 0.167\n",
      "[1,  6201] loss: 0.326\n",
      "[1,  6211] loss: 0.269\n",
      "[1,  6221] loss: 0.262\n",
      "[1,  6231] loss: 0.116\n",
      "[1,  6241] loss: 0.139\n",
      "[1,  6251] loss: 0.337\n",
      "[1,  6261] loss: 0.480\n",
      "[1,  6271] loss: 0.368\n",
      "[1,  6281] loss: 0.146\n",
      "[1,  6291] loss: 0.088\n",
      "[1,  6301] loss: 0.448\n",
      "[1,  6311] loss: 0.152\n",
      "[1,  6321] loss: 0.307\n",
      "[1,  6331] loss: 0.068\n",
      "[1,  6341] loss: 0.283\n",
      "[1,  6351] loss: 0.475\n",
      "[1,  6361] loss: 0.361\n",
      "[1,  6371] loss: 0.162\n",
      "[1,  6381] loss: 0.591\n",
      "[1,  6391] loss: 0.034\n",
      "[1,  6401] loss: 0.030\n",
      "[1,  6411] loss: 0.944\n",
      "[1,  6421] loss: 0.216\n",
      "[1,  6431] loss: 0.136\n",
      "[1,  6441] loss: 0.146\n",
      "[1,  6451] loss: 0.081\n",
      "[1,  6461] loss: 0.083\n",
      "[1,  6471] loss: 0.573\n",
      "[1,  6481] loss: 0.317\n",
      "[1,  6491] loss: 0.010\n",
      "[1,  6501] loss: 0.728\n",
      "[1,  6511] loss: 0.421\n",
      "[1,  6521] loss: 0.402\n",
      "[1,  6531] loss: 0.040\n",
      "[1,  6541] loss: 0.708\n",
      "[1,  6551] loss: 0.402\n",
      "[1,  6561] loss: 0.133\n",
      "[1,  6571] loss: 0.084\n",
      "[1,  6581] loss: 0.094\n",
      "[1,  6591] loss: 1.065\n",
      "[1,  6601] loss: 0.076\n",
      "[1,  6611] loss: 0.010\n",
      "[1,  6621] loss: 0.478\n",
      "[1,  6631] loss: 0.208\n",
      "[1,  6641] loss: 0.665\n",
      "[1,  6651] loss: 0.483\n",
      "[1,  6661] loss: 0.112\n",
      "[1,  6671] loss: 0.060\n",
      "[1,  6681] loss: 0.078\n",
      "[1,  6691] loss: 0.962\n",
      "[1,  6701] loss: 0.707\n",
      "[1,  6711] loss: 0.253\n",
      "[1,  6721] loss: 0.162\n",
      "[1,  6731] loss: 0.692\n",
      "[1,  6741] loss: 0.569\n",
      "[1,  6751] loss: 0.163\n",
      "[1,  6761] loss: 0.870\n",
      "[1,  6771] loss: 0.109\n",
      "[1,  6781] loss: 1.086\n",
      "[1,  6791] loss: 0.437\n",
      "[1,  6801] loss: 0.123\n",
      "[1,  6811] loss: 0.421\n",
      "[1,  6821] loss: 0.364\n",
      "[1,  6831] loss: 0.313\n",
      "[1,  6841] loss: 0.227\n",
      "[1,  6851] loss: 0.120\n",
      "[1,  6861] loss: 0.024\n",
      "[1,  6871] loss: 0.156\n",
      "[1,  6881] loss: 0.047\n",
      "[1,  6891] loss: 0.008\n",
      "[1,  6901] loss: 0.183\n",
      "[1,  6911] loss: 0.022\n",
      "[1,  6921] loss: 0.473\n",
      "[1,  6931] loss: 0.453\n",
      "[1,  6941] loss: 0.006\n",
      "[1,  6951] loss: 0.958\n",
      "[1,  6961] loss: 0.279\n",
      "[1,  6971] loss: 0.199\n",
      "[1,  6981] loss: 0.106\n",
      "[1,  6991] loss: 0.543\n",
      "[1,  7001] loss: 0.975\n",
      "[1,  7011] loss: 0.960\n",
      "[1,  7021] loss: 0.099\n",
      "[1,  7031] loss: 0.343\n",
      "[1,  7041] loss: 0.963\n",
      "[1,  7051] loss: 0.188\n",
      "[1,  7061] loss: 0.220\n",
      "[1,  7071] loss: 0.042\n",
      "[1,  7081] loss: 0.305\n",
      "[1,  7091] loss: 0.075\n",
      "[1,  7101] loss: 0.409\n",
      "[1,  7111] loss: 2.117\n",
      "[1,  7121] loss: 0.349\n",
      "[1,  7131] loss: 0.187\n",
      "[1,  7141] loss: 0.337\n",
      "[1,  7151] loss: 0.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  7161] loss: 0.423\n",
      "[1,  7171] loss: 0.916\n",
      "[1,  7181] loss: 0.313\n",
      "[1,  7191] loss: 0.017\n",
      "[1,  7201] loss: 0.601\n",
      "[1,  7211] loss: 0.132\n",
      "[1,  7221] loss: 1.578\n",
      "[1,  7231] loss: 0.940\n",
      "[1,  7241] loss: 0.134\n",
      "[1,  7251] loss: 0.379\n",
      "[1,  7261] loss: 0.382\n",
      "[1,  7271] loss: 0.034\n",
      "[1,  7281] loss: 0.441\n",
      "[1,  7291] loss: 0.810\n",
      "[1,  7301] loss: 0.368\n",
      "[1,  7311] loss: 0.810\n",
      "[1,  7321] loss: 0.367\n",
      "[1,  7331] loss: 0.304\n",
      "[1,  7341] loss: 0.030\n",
      "[1,  7351] loss: 0.378\n",
      "[1,  7361] loss: 0.712\n",
      "[1,  7371] loss: 0.085\n",
      "[1,  7381] loss: 0.013\n",
      "[1,  7391] loss: 0.073\n",
      "[1,  7401] loss: 0.220\n",
      "[1,  7411] loss: 0.775\n",
      "[1,  7421] loss: 0.027\n",
      "[1,  7431] loss: 0.193\n",
      "[1,  7441] loss: 0.102\n",
      "[1,  7451] loss: 0.134\n",
      "[1,  7461] loss: 0.076\n",
      "[1,  7471] loss: 0.016\n",
      "[1,  7481] loss: 0.053\n",
      "[1,  7491] loss: 0.548\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs): \n",
    "\n",
    "    # enumerate can be used to output iteration index i, as well as the data \n",
    "    for i, (data, labels) in enumerate(train_loader, 0):\n",
    "        \n",
    "        # Task 3.1 load data and labels to device\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # --------------------------------------------------task 2 ------------------------------------------------------------\n",
    "        # 3.2: implement training iteration here\n",
    "        # clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #3.3 feed the input and acquire the output from network\n",
    "        outputs = net(data)\n",
    "\n",
    "        #3.4 calculating the predicted and the expected loss\n",
    "        loss = loss_fun(outputs, labels)\n",
    "\n",
    "        #3.5 compute the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        #3.6 update the parameters\n",
    "        optimizer.step()\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # print statistics\n",
    "        ce_loss = loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, ce_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding PyTorch Hooks\n",
    "\n",
    "Hooks are functions with which you can modify or return different sub-components of your network. Returning the outputs of different layers (i.e. the activations - the goal of this section) is thus an excellent example. In general the point is that they are simply functions that are run whenever the `forward` or `backward` function of a `torch.Autograd.Function` object is called i.e. the `grad_fn` of a tensor (discussed in Lecture 2). \n",
    "\n",
    "You can register a function on a `Module` or a `Tensor` and are defined apriori as forward hooks or a backward hooks. Depending on which they are they will either be executed when a forward call is executed (forward hook) or a backward pass in run (backward hook). \n",
    "\n",
    "Let's look at using a forward and backward hook just for debugging (and thus printing) the output of a function (example taken from [the official PyTorch tutorials](https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html))\n",
    "\n",
    "A forward hook has the general form:\n",
    "\n",
    "```python\n",
    "model.conv_name.register_forward_hook(hook_function(module, input,output))\n",
    "```\n",
    "\n",
    "And a backward hook has a general form\n",
    "\n",
    "```python\n",
    "model.conv_name.register_backward_hook(hook_function(module,grad_input,grad_output))\n",
    "```\n",
    "\n",
    "Say we are interested in layer $l$. A forward hook function can look at inputs and outputs the layer during the forward pass i.e. the input activation from layer $l-1$ and the output activation for layer $l$. The backward pass can look at the inputs and outputs to the backward pass i.e. the incoming (input) gradient with respect to the parameters from the layer above $l+1$ and the outgoing (output) gradient with respect to the parameters of the current layer $l$.\n",
    "\n",
    "Thus if we wish to print information about the input and output activations we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.size tensor([9, 0, 0, 6, 7, 4, 9, 4, 0, 7, 8, 1, 1, 9, 5, 7, 6, 0, 8, 8, 3, 9, 9, 6,\n",
      "        0, 4, 6, 8, 7, 4, 8, 0, 0, 9, 1, 9, 1, 6, 3, 3, 2, 2, 7, 0, 6, 2, 6, 3,\n",
      "        3, 8, 3, 4, 1, 4, 4, 3, 6, 5, 0, 3, 7, 2, 0, 1, 4, 6, 8, 1, 4, 9, 2, 0,\n",
      "        0, 9, 4, 7, 1, 1, 6, 4, 6, 4, 5, 2, 0, 4, 8, 8, 9, 7, 5, 4, 2, 9, 0, 9]) torch.Size([96]) <built-in method size of Tensor object at 0x12018ca20>\n",
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([96, 1, 28, 28])\n",
      "output size: torch.Size([96, 10, 26, 26])\n",
      "output norm: tensor(180.4323)\n"
     ]
    }
   ],
   "source": [
    "def printnorm(self, input, output):\n",
    "    # input is a tuple of packed inputs\n",
    "    # output is a Tensor. output.data is the Tensor we are interested\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('')\n",
    "    print('input: ', type(input))\n",
    "    print('input[0]: ', type(input[0]))\n",
    "    print('output: ', type(output))\n",
    "    print('')\n",
    "    print('input size:', input[0].size())\n",
    "    print('output size:', output.data.size())\n",
    "    print('output norm:', output.data.norm())\n",
    "\n",
    "\n",
    "print_forward_handle=net.conv1.register_forward_hook(printnorm)\n",
    "\n",
    "#--------------------- ---- ----------------------------#\n",
    "# performing forward pass\n",
    "out = net(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to return backward pass outputs and inputs use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([96, 1, 28, 28])\n",
      "output size: torch.Size([96, 10, 26, 26])\n",
      "output norm: tensor(180.4323)\n",
      "tensor([[-2.2993, -2.2274, -2.3208, -2.3292, -2.2593, -2.2837, -2.2928, -2.2807,\n",
      "         -2.4033, -2.3398],\n",
      "        [-2.1939, -2.2452, -2.3210, -2.2736, -2.2734, -2.3717, -2.2523, -2.3966,\n",
      "         -2.2894, -2.4338],\n",
      "        [-2.0908, -2.4047, -2.3487, -2.2896, -2.3305, -2.2736, -2.1820, -2.3916,\n",
      "         -2.3479, -2.4161],\n",
      "        [-2.0121, -2.4353, -2.4093, -2.3913, -2.3051, -2.3513, -2.0803, -2.4280,\n",
      "         -2.3122, -2.4059],\n",
      "        [-2.2354, -2.2267, -2.3621, -2.4083, -2.2666, -2.3117, -2.2087, -2.3412,\n",
      "         -2.2694, -2.4213],\n",
      "        [-2.2688, -2.2200, -2.2548, -2.2989, -2.3428, -2.2850, -2.3334, -2.3523,\n",
      "         -2.3020, -2.3784],\n",
      "        [-2.2519, -2.3067, -2.2719, -2.3469, -2.2844, -2.4012, -2.2707, -2.3219,\n",
      "         -2.2769, -2.3022],\n",
      "        [-2.3012, -2.2314, -2.2369, -2.3846, -2.3553, -2.2481, -2.2480, -2.3697,\n",
      "         -2.2637, -2.4079],\n",
      "        [-2.1771, -2.2638, -2.3205, -2.2854, -2.2083, -2.3927, -2.1680, -2.4914,\n",
      "         -2.3568, -2.4133],\n",
      "        [-2.2781, -2.2701, -2.2256, -2.3997, -2.3116, -2.2732, -2.3558, -2.3051,\n",
      "         -2.2278, -2.3962],\n",
      "        [-2.1542, -2.2947, -2.2234, -2.3603, -2.3211, -2.3600, -2.2498, -2.4004,\n",
      "         -2.2870, -2.4043],\n",
      "        [-2.3109, -2.1810, -2.2966, -2.2835, -2.3418, -2.2889, -2.2799, -2.3441,\n",
      "         -2.3463, -2.3657],\n",
      "        [-2.2785, -2.1207, -2.3423, -2.3138, -2.3292, -2.2823, -2.3174, -2.3288,\n",
      "         -2.3438, -2.3935],\n",
      "        [-2.2553, -2.2891, -2.2616, -2.3387, -2.1968, -2.3625, -2.2843, -2.4360,\n",
      "         -2.3170, -2.3037],\n",
      "        [-2.1602, -2.2698, -2.3079, -2.2971, -2.3446, -2.3092, -2.2636, -2.3392,\n",
      "         -2.3539, -2.3996],\n",
      "        [-2.2274, -2.2827, -2.3776, -2.3175, -2.3363, -2.2661, -2.2943, -2.2516,\n",
      "         -2.2687, -2.4193],\n",
      "        [-2.1992, -2.2982, -2.2275, -2.3588, -2.3248, -2.2778, -2.2737, -2.3513,\n",
      "         -2.2703, -2.4701],\n",
      "        [-2.2039, -2.3249, -2.2718, -2.3612, -2.2767, -2.3280, -2.2412, -2.3692,\n",
      "         -2.2773, -2.3876],\n",
      "        [-2.2596, -2.1796, -2.2796, -2.3322, -2.3480, -2.2473, -2.2959, -2.3231,\n",
      "         -2.3622, -2.4188],\n",
      "        [-2.1466, -2.3513, -2.2500, -2.3702, -2.3193, -2.2178, -2.2348, -2.4608,\n",
      "         -2.2006, -2.5421],\n",
      "        [-2.2327, -2.2244, -2.2952, -2.2935, -2.3621, -2.2928, -2.3050, -2.2937,\n",
      "         -2.3431, -2.3959],\n",
      "        [-2.2848, -2.2315, -2.2952, -2.3240, -2.2685, -2.3260, -2.1945, -2.3451,\n",
      "         -2.3778, -2.3961],\n",
      "        [-2.2508, -2.2607, -2.2909, -2.3853, -2.3161, -2.2325, -2.2670, -2.3276,\n",
      "         -2.3187, -2.3892],\n",
      "        [-2.2442, -2.2686, -2.3295, -2.2801, -2.3323, -2.3622, -2.2554, -2.3240,\n",
      "         -2.2435, -2.3989],\n",
      "        [-2.2883, -2.2103, -2.3354, -2.3347, -2.3823, -2.2299, -2.2162, -2.2619,\n",
      "         -2.3846, -2.4069],\n",
      "        [-2.2814, -2.2006, -2.2844, -2.3244, -2.3795, -2.2639, -2.3271, -2.2622,\n",
      "         -2.3477, -2.3686],\n",
      "        [-2.1663, -2.3943, -2.1773, -2.4520, -2.3045, -2.2603, -2.2084, -2.4876,\n",
      "         -2.2560, -2.3772],\n",
      "        [-2.1927, -2.4475, -2.2081, -2.3141, -2.2472, -2.3654, -2.1863, -2.4529,\n",
      "         -2.2603, -2.3989],\n",
      "        [-2.3086, -2.1925, -2.2745, -2.2876, -2.3742, -2.2512, -2.4088, -2.2870,\n",
      "         -2.2713, -2.3909],\n",
      "        [-2.2456, -2.2898, -2.2594, -2.3188, -2.2885, -2.2474, -2.3044, -2.4044,\n",
      "         -2.2696, -2.4139],\n",
      "        [-2.1966, -2.2888, -2.3379, -2.4302, -2.2332, -2.4691, -2.1943, -2.3828,\n",
      "         -2.1511, -2.3975],\n",
      "        [-2.0627, -2.4723, -2.2796, -2.3166, -2.1884, -2.3208, -2.1422, -2.4809,\n",
      "         -2.3908, -2.4693],\n",
      "        [-2.2633, -2.1982, -2.3143, -2.3040, -2.3437, -2.2342, -2.3097, -2.3128,\n",
      "         -2.3195, -2.4459],\n",
      "        [-2.2949, -2.2771, -2.2799, -2.3495, -2.2542, -2.3221, -2.2784, -2.3316,\n",
      "         -2.2753, -2.3693],\n",
      "        [-2.3065, -2.1846, -2.2569, -2.3103, -2.3800, -2.2874, -2.3820, -2.2824,\n",
      "         -2.2968, -2.3550],\n",
      "        [-2.1855, -2.3360, -2.2096, -2.3824, -2.2854, -2.3272, -2.2357, -2.4271,\n",
      "         -2.2727, -2.3943],\n",
      "        [-2.3145, -2.1687, -2.3121, -2.2905, -2.3664, -2.2754, -2.3461, -2.2745,\n",
      "         -2.3147, -2.3792],\n",
      "        [-2.1789, -2.3234, -2.2405, -2.4147, -2.3181, -2.2159, -2.2699, -2.4279,\n",
      "         -2.1921, -2.4969],\n",
      "        [-2.1905, -2.2440, -2.2854, -2.2425, -2.3179, -2.3161, -2.2943, -2.4306,\n",
      "         -2.2731, -2.4622],\n",
      "        [-2.1134, -2.3317, -2.2394, -2.2598, -2.3043, -2.3502, -2.3304, -2.4374,\n",
      "         -2.2812, -2.4172],\n",
      "        [-2.1398, -2.3772, -2.2116, -2.4291, -2.2947, -2.3194, -2.2061, -2.4415,\n",
      "         -2.1551, -2.5296],\n",
      "        [-2.1929, -2.3843, -2.2660, -2.3551, -2.2672, -2.3276, -2.2033, -2.3739,\n",
      "         -2.2295, -2.4605],\n",
      "        [-2.3192, -2.1410, -2.3697, -2.3052, -2.4088, -2.2320, -2.3255, -2.2492,\n",
      "         -2.3521, -2.3514],\n",
      "        [-2.2879, -2.2202, -2.3765, -2.2939, -2.3278, -2.2176, -2.2987, -2.2545,\n",
      "         -2.3436, -2.4246],\n",
      "        [-1.9660, -2.4646, -2.2664, -2.3323, -2.1907, -2.4129, -2.0481, -2.6406,\n",
      "         -2.3187, -2.6025],\n",
      "        [-2.1391, -2.3116, -2.2191, -2.3893, -2.2896, -2.2973, -2.2967, -2.4378,\n",
      "         -2.2294, -2.4609],\n",
      "        [-2.2859, -2.2233, -2.2814, -2.3461, -2.3882, -2.2080, -2.3457, -2.2728,\n",
      "         -2.2831, -2.4113],\n",
      "        [-2.1469, -2.3527, -2.1419, -2.3846, -2.3866, -2.3814, -2.2930, -2.4284,\n",
      "         -2.0917, -2.5070],\n",
      "        [-2.0845, -2.3699, -2.1477, -2.2756, -2.3003, -2.2458, -2.3860, -2.5534,\n",
      "         -2.2108, -2.5620],\n",
      "        [-2.2052, -2.3790, -2.2786, -2.3573, -2.2635, -2.3109, -2.1702, -2.3984,\n",
      "         -2.2614, -2.4341],\n",
      "        [-2.1896, -2.2695, -2.3239, -2.2968, -2.3066, -2.3738, -2.2133, -2.3294,\n",
      "         -2.3758, -2.3660],\n",
      "        [-2.3004, -2.2018, -2.2412, -2.3710, -2.3843, -2.2490, -2.3175, -2.2857,\n",
      "         -2.3071, -2.3856],\n",
      "        [-2.2828, -2.1849, -2.2919, -2.3689, -2.3574, -2.2525, -2.3058, -2.3292,\n",
      "         -2.2815, -2.3875],\n",
      "        [-2.1661, -2.2524, -2.3313, -2.4094, -2.2125, -2.3088, -2.1236, -2.4585,\n",
      "         -2.4167, -2.4078],\n",
      "        [-2.3022, -2.2418, -2.2617, -2.3644, -2.2447, -2.2820, -2.2765, -2.4108,\n",
      "         -2.2806, -2.3765],\n",
      "        [-2.0948, -2.3048, -2.3184, -2.2588, -2.3248, -2.3390, -2.2416, -2.3999,\n",
      "         -2.3631, -2.4208],\n",
      "        [-2.3119, -2.1607, -2.3016, -2.3250, -2.3912, -2.2515, -2.3412, -2.2765,\n",
      "         -2.3320, -2.3530],\n",
      "        [-2.2977, -2.2089, -2.2876, -2.3269, -2.3547, -2.3007, -2.2994, -2.2928,\n",
      "         -2.3260, -2.3383],\n",
      "        [-1.8912, -2.7390, -2.2346, -2.3894, -2.2205, -2.4054, -1.9787, -2.7090,\n",
      "         -2.2267, -2.6005],\n",
      "        [-2.3081, -2.2040, -2.2933, -2.2810, -2.2704, -2.2822, -2.3106, -2.3463,\n",
      "         -2.3352, -2.4076],\n",
      "        [-2.2646, -2.2556, -2.3851, -2.3893, -2.2973, -2.2994, -2.2259, -2.2607,\n",
      "         -2.3174, -2.3442],\n",
      "        [-2.1531, -2.3406, -2.3133, -2.3752, -2.3271, -2.2421, -2.3082, -2.3698,\n",
      "         -2.1707, -2.4669],\n",
      "        [-2.3000, -2.1649, -2.2798, -2.3186, -2.3658, -2.2607, -2.3758, -2.2943,\n",
      "         -2.3145, -2.3695],\n",
      "        [-2.3359, -2.1872, -2.3313, -2.3664, -2.3745, -2.2587, -2.2969, -2.2468,\n",
      "         -2.2816, -2.3635],\n",
      "        [-2.3576, -2.1308, -2.3352, -2.3311, -2.3774, -2.2706, -2.3248, -2.2430,\n",
      "         -2.3275, -2.3528],\n",
      "        [-1.9766, -2.6173, -2.2685, -2.4228, -2.2610, -2.4343, -2.0372, -2.4610,\n",
      "         -2.2108, -2.5375],\n",
      "        [-2.3564, -2.1460, -2.2675, -2.4010, -2.2784, -2.3779, -2.2395, -2.3998,\n",
      "         -2.2063, -2.3910],\n",
      "        [-2.3702, -2.1767, -2.2352, -2.2389, -2.2332, -2.3470, -2.3367, -2.4150,\n",
      "         -2.2627, -2.4457],\n",
      "        [-2.2330, -2.3312, -2.2802, -2.3626, -2.3612, -2.1855, -2.2271, -2.3741,\n",
      "         -2.1933, -2.5262],\n",
      "        [-2.2692, -2.2685, -2.2532, -2.3810, -2.2490, -2.3658, -2.2363, -2.3992,\n",
      "         -2.2634, -2.3581],\n",
      "        [-2.3573, -2.1561, -2.3241, -2.3522, -2.2453, -2.3389, -2.2351, -2.3412,\n",
      "         -2.3287, -2.3691],\n",
      "        [-2.1298, -2.3273, -2.1801, -2.3179, -2.2428, -2.3219, -2.2511, -2.5401,\n",
      "         -2.2356, -2.5674],\n",
      "        [-2.1664, -2.2836, -2.3449, -2.2610, -2.3373, -2.2766, -2.2948, -2.3335,\n",
      "         -2.3041, -2.4467],\n",
      "        [-2.2811, -2.2704, -2.3358, -2.3249, -2.2168, -2.3307, -2.3197, -2.3528,\n",
      "         -2.2470, -2.3568],\n",
      "        [-2.1394, -2.3391, -2.2484, -2.4199, -2.1657, -2.2990, -2.3215, -2.4581,\n",
      "         -2.3172, -2.3640],\n",
      "        [-2.3335, -2.1753, -2.3521, -2.3293, -2.3677, -2.2398, -2.3125, -2.2119,\n",
      "         -2.3764, -2.3502],\n",
      "        [-2.3251, -2.1357, -2.3267, -2.3028, -2.3378, -2.2683, -2.3344, -2.2972,\n",
      "         -2.3358, -2.3826],\n",
      "        [-2.3287, -2.1523, -2.2701, -2.3150, -2.3573, -2.2863, -2.3482, -2.3154,\n",
      "         -2.3147, -2.3548],\n",
      "        [-2.2174, -2.2371, -2.1555, -2.3838, -2.3526, -2.3609, -2.1713, -2.4501,\n",
      "         -2.2502, -2.5113],\n",
      "        [-2.2403, -2.3676, -2.2821, -2.3581, -2.2701, -2.2466, -2.2384, -2.3470,\n",
      "         -2.2373, -2.4638],\n",
      "        [-2.3125, -2.1620, -2.2824, -2.2897, -2.2476, -2.2957, -2.2923, -2.4184,\n",
      "         -2.3960, -2.3536],\n",
      "        [-2.2782, -2.2279, -2.2740, -2.3340, -2.4121, -2.2536, -2.3007, -2.2734,\n",
      "         -2.3000, -2.3870],\n",
      "        [-2.3271, -2.1836, -2.1911, -2.3968, -2.3690, -2.2984, -2.3195, -2.3449,\n",
      "         -2.2232, -2.4019],\n",
      "        [-2.2924, -2.1928, -2.2610, -2.3739, -2.2896, -2.3087, -2.2826, -2.3479,\n",
      "         -2.2897, -2.4033],\n",
      "        [-2.2560, -2.2232, -2.2870, -2.3356, -2.3077, -2.2978, -2.2515, -2.3383,\n",
      "         -2.3536, -2.3870],\n",
      "        [-2.2417, -2.2303, -2.3499, -2.3192, -2.2873, -2.2509, -2.1961, -2.3323,\n",
      "         -2.3699, -2.4786],\n",
      "        [-2.2002, -2.2620, -2.3001, -2.3176, -2.3507, -2.3083, -2.2574, -2.3065,\n",
      "         -2.3581, -2.3779],\n",
      "        [-2.1717, -2.4182, -2.2540, -2.4409, -2.2486, -2.4380, -2.1248, -2.4822,\n",
      "         -2.1381, -2.3959],\n",
      "        [-1.9872, -2.5320, -2.2238, -2.2653, -2.2557, -2.4025, -2.2218, -2.5459,\n",
      "         -2.2173, -2.5205],\n",
      "        [-2.2065, -2.2984, -2.2391, -2.3497, -2.3127, -2.3346, -2.3164, -2.3579,\n",
      "         -2.2556, -2.3683],\n",
      "        [-2.1092, -2.3878, -2.2705, -2.3261, -2.3170, -2.3164, -2.2432, -2.3497,\n",
      "         -2.3273, -2.4120],\n",
      "        [-2.2435, -2.3291, -2.2116, -2.3842, -2.2156, -2.3187, -2.2340, -2.4435,\n",
      "         -2.2578, -2.4213],\n",
      "        [-2.2178, -2.2258, -2.2526, -2.3245, -2.4270, -2.2278, -2.3278, -2.3185,\n",
      "         -2.3288, -2.3990],\n",
      "        [-2.1371, -2.4094, -2.3077, -2.3973, -2.2188, -2.4096, -2.1797, -2.3662,\n",
      "         -2.2738, -2.3722],\n",
      "        [-2.0440, -2.4326, -2.2695, -2.3375, -2.3137, -2.3189, -2.1885, -2.4996,\n",
      "         -2.2323, -2.4771],\n",
      "        [-2.2947, -2.1865, -2.3058, -2.2932, -2.3532, -2.3174, -2.3330, -2.3208,\n",
      "         -2.2694, -2.3632]], grad_fn=<LogSoftmaxBackward>) <built-in method size of Tensor object at 0x12018ca20>\n",
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([96, 10, 13, 13])\n",
      "grad_output size: torch.Size([96, 20, 11, 11])\n",
      "grad_input norm: tensor(0.0179)\n"
     ]
    }
   ],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "    print('Inside class:' + self.__class__.__name__)\n",
    "    print('')\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output[0]))\n",
    "    print('')\n",
    "    print('grad_input size:', grad_input[0].size())\n",
    "    print('grad_output size:', grad_output[0].size())\n",
    "    print('grad_input norm:', grad_input[0].norm())\n",
    "\n",
    "\n",
    "print_backward_handle=net.conv2.register_backward_hook(printgradnorm)\n",
    "\n",
    "out = net(data)\n",
    "err = loss_fun(out,labels)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By naming your hooks e.g.\n",
    "\n",
    "```\n",
    "print_forward_handle=model.conv1.register_forward_hook(printnorm)\n",
    "\n",
    "```\n",
    "it is possible to remove them as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_forward_handle.remove()\n",
    "print_backward_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on hooks can be found in https://www.kaggle.com/sironghuang/understanding-pytorch-hooks and https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/ should you be interested.\n",
    "\n",
    "### Task 2.1. Register hook to get network activations for a given input\n",
    "\n",
    "Thus hooks are functions that can be applied to the inputs and outputs of our forwards and backwards layers and as such we can use them to return the activations of each layer.\n",
    "\n",
    "**To do ** Modify the below code to use the hook function `get_activation` to save the activation tensor for the first convolutional layer of your network:\n",
    "\n",
    "We define the function for you. All you need to do is:\n",
    "\n",
    "1. Create a (forward or backward) hook \n",
    "2. Pass it the hook function `get_activation`. Here, the argument `name` is expecting the name of the layer. Yhe name is what you call the variable in your `__init__` function i.e. `conv1,pool1... ` etc in this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set up the hook for activations\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "#--------------------- Task 2.1 ----------------------------#\n",
    "# Create a hook on the first convolutional layer\n",
    "#\n",
    "net.conv1.register_forward_hook(get_activation('conv1'))\n",
    "\n",
    "#--------------------- ---- ----------------------------#\n",
    "data, _ = mnist_train_dataset[0]\n",
    "data.unsqueeze_(0)\n",
    "\n",
    "# Run through model again, to save the relavent activation\n",
    "output = net(data)\n",
    "\n",
    "# Visualize the activation\n",
    "act = activation['conv1'].squeeze()\n",
    "\n",
    "print(act.size(0),min(act.size(0),10))\n",
    "fig, axarr = plt.subplots(1,min(act.size(0),10),figsize=(20,20))\n",
    "n_plots=min(act.size(0),10)\n",
    "for idx in np.arange(n_plots):\n",
    "    axarr[idx].imshow(act[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Visualise an activation of another convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------- Task 2 --------------------------------------------------------\n",
    "# write code here\n",
    "\n",
    "# Register the hook with the convolutional layer of interest\n",
    "net.conv2.register_forward_hook(get_activation('conv2'))\n",
    "\n",
    "# Run through model again, to save the relavent activation\n",
    "output = net(data)\n",
    "\n",
    "# Visualize the activation\n",
    "act = activation['conv2'].squeeze()\n",
    "fig, axarr = plt.subplots(1,min(act.size(0),10),figsize=(20,20))\n",
    "n_plots=min(act.size(0),10)\n",
    "for idx in np.arange(n_plots):\n",
    "    axarr[idx].imshow(act[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3 Explain \n",
    "\n",
    "1. How can you interpret the activations of different layers? What does that mean with respect to the relative importance of different parts of your image?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualisation and Attribution\n",
    "\n",
    "When it comes to techniques for visualising and interpretting what an individual network is learning there are two main sub-fields: feature visualisation and feature attribution:\n",
    "\n",
    "### Feature visualisation\n",
    "\n",
    "This represents the category of methods which attempt to understand through backwards designing inputs, which maximize the activation of individual units (neurons/channels/layers) of networks, whereas\n",
    "\n",
    "### Feature attribution (saliency mapping) \n",
    "Reflect methods which seek to backpropagate maps which highlight which parts of an image are important for activation of a specific unit\n",
    "\n",
    "We start by discussing saliency mapping though occlusion as this can be meaningfully tested with MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution (saliency mapping)\n",
    "\n",
    "### Exercise 3: Saliency by occlusion\n",
    "\n",
    "In a related sense we will now try to interpret what our network is doing by occluding different parts/proportions of our image to see what impact this has on classification. Let's return a batch of images from our validation DataLoader and visualise them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 torch.Size([1, 28, 28]) tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADuCAYAAAAgAly4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHztJREFUeJzt3Xl4FEXeB/BvJQGSgNwg4QhHQjhURFgQQTwWEeVQFPEAFQEVVkBFEHXXa3dZd0UFFZBDFAF18ZVjBcV7UUCMAsop9yUYEGFBjnAl6fePmq7qMJO5MpOZ6nw/zzMPP2p6OpVOp1Jdp7AsC0REZJ6EWGeAiIjCwwKciMhQLMCJiAzFApyIyFAswImIDMUCnIjIUCzAiYgM5doCXAixSwhxTQjH9xVCHHe8coUQlhCidTTzaaIwrm1zIcRKIcRhz+sLIUTzaObRZKFeX89nOgkhNnnu28VCiPrRyp/J3HZtXVuAh8qyrHcsy6pgvwA8AGAHgB9inDU3yAFwC4CqAKoDWABgdkxz5CJCiOoA5gF4CvIarwTwXkwz5RLxfm1dWYALIWYBSAew0FObHhXGafoBmGlxqmoh4Vxby7KOWJa1y3MtBYB8AJlRzqqRwrx3bwawwbKs9y3LOgXgWQAXCyGaRjGrxnHjtXVlAW5Z1l0AfgbQw1OjHgMAQoi1Qog+gT7veUS6AsDM6ObUPMW5tkKIIwBOARgP4LmoZ9ZAYV7fCwCscZzjBIDtnnTycOO1TYp1BkqSZVktgjz0bgBLLcvaGc38uEkw19ayrMpCiPKQTze7o58r9whwfSsA+O2ctN8BnBe9HLmHydfWlTXwCLgbwIxYZ8KNPDWYyQBmCiFqxjo/LnEcQMVz0ioCOBaDvLhNXF9bNxfgYbVdCyE6AKgNYE5ks+Mqxe0XSACQCqBOBPLiRqFe3w0ALrb/43nKyfCkU2GuurZuLsB/BdAojM/1AzDXsqy4+Asbp0K6tkKIzkKIS4QQiUKIigDGAjgMYGO0Mmi4UO/d+QAuFEL0EkIkA3gawFrLsjZFJXdmc9e1tSzLlS8AN0J2WBwBMNKTtgFAXz+fSfYc3ynW+Y/nV6jXFkBvAJsgH0d/A7AIQItYfx/x+grz3r3Gc41PAvgKQINYfx/x+HLbtRWeDBIRkWHc3IRCRORqLMCJiAzFApyIyFAswImIDFWiMzE7J/Rmj2kAnxe8L8L5HK9tYOFeW4DXNxi8d6OnqGvLGjgRkaFYgBMRGYoFOBGRoViAExEZigU4EZGhWIATERmKBTgRkaFYgBMRGYoFOBGRoUrVnphERE61s/XWltPTlwb1mYz3Bqs4c3h2xPMUCtbAiYgMxQKciMhQbEKhIuXedCkAIOcK32sUbb9tMgCg/88dVdqSby/we87aS+S6Ranzv4tEFksd0Vpe30aTt6u0nlVWqfjvjw4AAJysqutmx649oeLMUYcBAHm790Q1n/HIvp8BYOnEKWGfx77vAaD/Zfre3/Z8cwAle2+zBk5EZCgW4EREhmITChVSuFc+uMfMQr33gXryb/P8O1EnOZtgctodC+prlirtWqhw8Kx5AIAeqUd9Htp+/CsAgGm/N1VpwyrvUPHzC5sBAL7pmqnS8vb+Erm8xplt49qp2Nn0ESmF7v2JMu4yv2XEv05RWAMnIjKU62vgSXXrAAB23V3f73H5yXpTkA0DJ3q932bVHSqulHIKAHBmai2VVuF9d3TK2R0xAFSNItqctZiMcXKMbazH18aDLZPbAgD6tvtWpdk17y9PllNpK3MbqfixahsBAFPe76rSyty60Ov90R8lqrTvOlYHAOQf9V2rN5HdYRlKrdt+EizqKdA+Z6AOUOdTbLSfKFkDJyIyFAtwIiJDCcsquf1EI7V5aVKabro43jodAPDzDfrUD7T/r4prJMlHmLvO2x+JL11Ir23Xq/hMrzwAQP7BQ8U6ZzxtDBtoHLgtGp1DHYcMUnGkxtWasKnxlkltVbyux6sAgBRRVqW1+/F2AEDV0ckqbfuDuh7WtPavAACrn24d3dWnnooXP/ACAKBaQopKu2ronwAU/zrH0737ac7qkD9j33OBrkMo48mDPWcg3NSYiMhl4r4TM7FiRf2fFFnrOPaWrj0svjDytb9gzc38WMV/bCc735I/LF4NPJ7YtYbM+f6P6zLc/7CpcGbAOWv9gb6+6faNaK/ibTdMcLwja97PH2qmUqo/KX9lC1avVWkZjv7esz7Onz7uNxV32z8SANDkvo0qbfK4lwEAQ04/qNLKLVoR/DdgsHCe9JzHZVyhF7by9SSa+dhPAICcKN3DrIETERmKBTgRkaHivgnll5l1VPxDm3cieu5mS/qrOO9/ulOo/SWbAQAz6v/X6zMUOucjZ//H5FjbYNdedrOCy2XT04+P6GaTRKHrVPlWAQBg6d2t9WdW/xT61zl1SsVVp8sx5T+m6WabpkPkfV79iZ0q7diikL+MUewx38XtXHTOV7AXtnLe23Zsz2849zPFxRo4EZGhWIATERkqLptQnL3yi1qNcbyTCgC4bce1KuX3MykIVZmhsrkkY+dmleZ8zNx/dSsAwLo3P1VpF5Ut43Weq9f3UnH5xRvkeULOjTs5R57YPfEAm06S6usx2fdNn+P1vt1sAgCN5zwAAMja8EPE85E+Vp+zyYVyDfEX2+j8TK3SRufp8OGIf/1Yi8YUd7UMhY8lKJwjVAKN2goFa+BERIaKyxr4Xf11zTctMVXF9iy0Gn30rMqEowdDPn++j7TEKlVUfMPEzwH4rnU77d1XVcWNT+z0c2TpYS/fGe7sTLtzya2LWeVX1/MafC0J2yL7LhU3fUo+ueSfPRPxfDifOM+fLxfGurLjAZU28QK9+FvCMjNq4M6nPiD0mZjFpTpEvdfCixrWwImIDMUCnIjIUHHZhOLkXIe7/PTKAID8o1si/4UczSWDK+32e+iNW7sBAJoM2aTS3Nh56Wsxq8BNI8V7dHX7jjyHm1f0+37dXhtU7KupLxoSz8i1pH46q+dClP1FN5vklVA+iivQomtO9prdpt9vrIETERkqLmvgizumq/j8k7o2XHBqs6/DI+LIVY0CH+SxJbsBAKDhiW/9H2g4e/jf0lI+9C+SjveMv11vDrSWu/PUSDyp0goqlY9VdkpEtGdIlhTWwImIDMUCnIjIUHHZhFJSM79+79tOxa+OHu94J9Hr2KMFetxs8m9hb+xCAbilc6kozWr+6pXm3KA4FtKWy27K1Hv0xjhWGe/fATcq1Cl/m/wn3N2g9Dh07458e36DFLl7mzVwIiJDsQAnIjJUXDahlJReT3yu4tZl/T8ytl4wXMWNX1oetTzFE3+L80SLPTqgCyK34E88yOsk1/R+q6FznrXcMu3Jv9+rUqqghEY2tWuhwucnvQYAWHQiS6VZK9aVTD4i6IrLNgQ+KAjObf+cW6b5GqUS7HaBS769QJ8HXA+ciKjUK5U1cKv9xQCANimz/B7XbXMPFTceUrydO0xkd+B0ma9rw/ZiVQBQe4lV6LhgfJoT3ExNZ82muLumxIOCMrKulCLKer1nz4QsSTt76nHe9tPn8M36Z1sBO0o8T8XlrOUiQnMXfC0DW9RSyb5Ee3E21sCJiAzFApyIyFClpgkloWVzFT82SzaddEz2v0zP5h1pKs7CL9HJmGFMnG4cD1L2yCn02ad1WjvP8O8zFUtuXoFocxEA4O3bXnWkyiaUsi9Xc6SZ14RiN+kBUGO6A3GO+babQ5y7RjnHb+feJMsQf52V57KbdSLZcenEGjgRkaFYgBMRGarUNKFsGamnK/tqOtmXn6viHs+PAgA0m7VepZXU2szxxNd64ME2oYTSU+9kP7K6YeSJU/4GuZLmE8P1uOLFr8kRDt8/rceGd53SKuJf2242AYCkF+QWhM55D/b69infbdP5jXguoq/QPRPktmaBmkMKbcId5HwIZ7NLtJscWQMnIjKU62vgSfXrAQC6NV3v97ib1g5Qcc2JcqalibWQ4go0sywDwc1Mc9a6p4cwJteti1jZKmw8pOLxR+Qa9MMq6w7D3xdlqrjKzXsBFN6AOByHntE9p9mNPwIArDqj7+6CW+SmySW1iFxJsDsnQ+lwLK6M9+TvRkl29LMGTkRkKBbgRESGcn0TSk532YSyIO0Dr/fWnTmr4uQ3qpRYnuJZoI1hnVOL7eYU5yJC09NDf2QttP4y3NV5ea78LdtVPOW9rgCAYYMmqLRvLv4/FV/80FAAQL0Ja1RawYkTfs9vL5qVM/iMSlvR8nUVrzojOy/7TX9IpaUfdN/ibHaHpnMxqsAbcoeu0Djy+SU/R4I1cCIiQ7myBn5o4GUqnj5ynCcq43XcgDEPq7jGfHdvUBwNxanRhLvriZs0mrEHAJBZV1+Lbd30E8yaB2XNfO5A/XT4+p4rAAA71tZRaU9dP0/FbZLlfdy0jB42m31aL6D1zEC5dG36YvfVun1xdig6O+DDuXft4YHOjvZYPzGyBk5EZCgW4EREhnJlE8q7T7+o4oyklCKPq74mt8j3Sitfj5yR7PxRY2Vj0OETb/J2yyaU5n8rUGmZSfereMoVMwAAXVP1Rsi9mno645v6PudJS3ZC99v9R5W2aXozFVdbXHqbCotqTrH5us+dsyrtHapi3WzixBo4EZGhWIATERnKNU0ozq2+6iet8HtsouDfrWDYj5wdl3ivmQz4nyJvN5U4zwNEb11kk+Xt1WvNZw3Q8UuQa0mPvrGtSjubKu9d666DKu3YspoqrrFazm0ot0j/DlQrqY2SDeJruru9ZVph8TPixBeWZEREhnJNDbzJNL0Qz2+99OI9aYmpXsfmWwVeaVQ05zjtnPk6vQt81Vgk1rQjJ+WD73VsB//W71fCNlDpxBo4EZGhWIATERnKNU0o9o4nAHDVsqEq3nzlmwCAViv6qrS87+XU5AY79TrM/rc3JiKKP6yBExEZyjU1cKeMPqtV3BVyj8Fa2Oh1HGvdRGQy1sCJiAzFApyIyFDCsqxY54GIiMLAGjgRkaFYgBMRGYoFOBGRoViAExEZigU4EZGhWIATERmKBTgRkaFYgBMRGYoFOBGRoViAExEZigU4EZGhWIATERmKBTgRkaFYgBMRGYoFOBGRoViAExEZigU4EZGhWIATERmKBTgRkaFYgBMRGYoFOBGRoViAExEZigU4EZGhWIATERmKBTgRkaFYgBMRGYoFOBGRoViAExEZigU4EZGhWIATERmKBTgRkaFcW4ALIXYJIa4J8TO3CiE2CiGOCSF+EkL0jFb+TBbqtRVC9BVCHHe8coUQlhCidTTzaaowrm9zIcRKIcRhz+sLIUTzaObRVG67d11bgIdKCFEHwNsAHgFQEcCjAN4VQtSMacZcwLKsdyzLqmC/ADwAYAeAH2KcNbfIAXALgKoAqgNYAGB2THPkEvF+77qyABdCzAKQDmCh56/mqCA+VhfAEcuyPrakjwCcAJARzbyaJsxre65+AGZalmVFNnfmC+f6WpZ1xLKsXZ7rKQDkA8iMclaN48p717IsV74A7AJwzTlpawH0KeL4RABfA7jBE/cEsBdA+Vh/L/H2CvXannNcfcgCpmGsv494fYV7fQEcAZAHoADAk7H+PuLx5bZ7NynifxHimGVZLfy8ly+EmAngXQDJAM4A6G1Z1omSyp/J/F3bc9wNYKllWTujmR+3Ceb6WpZVWQhRHrKWuDv6uXIHk+9dVzahhMPTsTEGwFUAygK4EsA0IUTLWObLhe4GMCPWmXArT4VjMoCZ7L+JuLi7d91cgIfaRtUSwBLLslZallVgWdYKAN8BCGkkSykRVvufEKIDgNoA5kQ2O65T3PbVBACpAOpEIC9u46p7180F+K8AGoVw/AoAHe0atxDiEgAdIdvHqLBQr62tH4C5lmUdi3B+3Cak6yuE6CyEuEQIkSiEqAhgLIDDADZGK4MGc9e9G+tG+Ch2VtwI4GfIjp2RnrQNAPr6+cxQANsAHIMcKjQi1t9HPL7CvLbJnuM7xTr/8f4K9foC6A1gE4DjAH4DsAhAi1h/H/H4ctu9KzwZJCIiw7i5CYWIyNVYgBMRGYoFOBGRoViAExEZqkRnYnZO6M0e0wA+L3hfhPM5XtvAwr22AK9vMHjvRk9R15Y1cCIiQ7EAJyIyFAtwIiJDsQAnIjIUC3AiIkOxACciMhQLcCIiQ7EAJyIyFAtwIiJDlao9Mf1Jquu9eUne3l9UfGjgZSr+6xPTAQDdUk+ptHyrAADQYdQDKq3SO9kRzycRkY01cCIiQ7EAJyIyVKluQnE2m2T854CKL6+4BQCw7GiWSuteeZqKO6WcBgDk+1iC5+N/jVVxnw33qrhg9U/FzzCVKnmdWgMA9nQqq9Km3jYFAHBVSoFKy/zqHhVn9FldMpmjuMAaOBGRoViAExEZqlQ3oWweU0PFC9IWer3fq/x3Kj5pnVHxbTu6AwDWLG+s0j67/QUAQHpSqkrb9ZdEFTe4pzwAoODEieJmm1ws/+pWKj44LBcAsLHN697HOZrv5lw2RcWPtbtPBtlro5NBF0vMygAALPpqrkrL+G9/Fdf4uBwAoNL2XP2hGF9n1sCJiAxVKmvgu0bLMd2vtZ3m97iFuRVV/OcZd6u43ujlAID6V6ertJzesuad7riig5ovVfFnKfKvOwyqgYvWFwAAtjxYTqWV2aNjK1N+Lx0b7FBpb6QvC+rcX57UTycPTR2k4jrPLw8vswZKrFIFALBzal2VNuMPujbdumyi12d8uahsGRX/fG0FAEA6pyAEJbGZforuOe8bAHpOBwBsufoNffDV8p9DBSdVUk6e/oUfMOZhAEDNaav0+c+XT/nOOSWRxBo4EZGhWIATERmq1DShnO7aRsWr7hkHAEgRZX0euz1PPiL9ZfpQlVbvOe9H+/6TP1BxO0/LwtECPb3+laXXqjjr4Pdh5LrkJZQvr+IO0+Wj4CfVN0X863RKyVfx98NeVnGbRPkYWtfH9TaZff81fFpfy5rlDgMAFtb80nGkd7PJqjP6WvWZ8yAA4IPeer5B0zK6WWvo7bIzfsHfqhU/0y6WeEETAEDCxKMqbWDFvX4/M/eEbPKqmaiLzfpJ+vMrnpwIAJj9sB4cUSdpJQCg/+d6TkjW4MiVBayBExEZyvU18EP3yQ7Ltvf/qNJ81bw/OamH/0245U4AQN3VuhaYVL+einOnyb97nVO/cZwhBQDQfcOdKiWSf2lLinOY4xf7mwIAniyiBr4v7zgAYMSeHl7vfbejgYorZqeo+EiLswCAnT300LjUBP3zqHFVjgyeCzHjce7UUFnbnlbva6/38qBr2HOO11Lx2LG3AgAq7Tyr0jI++xYA0GfvCJX2w6gJKr63kuxQnjZE/0xqTnTX00y4khrWV3HX9+U1GVxpt9/PNJ73JxU3eXw9ACChSmWVlp9WVcW7esgO5DfunKjS7Cfzdd1fVWkdhj+i4lrjivezYQ2ciMhQLMCJiAzlyiaUhJbNVfzXx+Ta3del5BZ1OADg8XU3q7jevoMAgK2vtFNpIzp/pOI6ZeTjcLUE3TRgz9TMXagfgStAj482UflBcrpf5tDBKi35gP6bn77gNwBA/satXp/NxGGf50yrKMfWz76qikq7/Tzfx7rJ9XWKXsxs5WndcTmziW6qqw7ZXJJY3dEh6YmPZelmF6ckTyfo71l6LHPN0LPrGvbsSgDY8Q/dTOqv6aTDmltV3OTRNSouOCUHKBSaTe0Y311/hfz3yeV6XsMXb8hx/c5m2xeG6ObDl8ZdEPB78Ic1cCIiQ7EAJyIylCubUA5foKfAB2o6sa1u+7b+zw/BfR3nVPunJ8up9mku6vHP2ykfMzNG+H7c9P0QH0BKMoDS0Wzi9O2ASwAATW6/UqVdfYVcCGnn401UWqLj5rPHjk+dpMfJZyTZzXafRyurrmA3ndzz4RcqrVd573vOOW+j9WI576Px3fpnUOD1icB23ez//UGf6wWyslC8kWqsgRMRGco1NfCE5GQVn7jlqJ8ji8/+qz3prntUWlq2e2reJe1nz3hyACjzt8p+jjSXtWoDACBDr3OEPWVkx1biWd+PfL+2lYtU6Vo3BevkxDwAvmvdgF6Q6vJ3Rqq0xo9/W6yvuf3dlgCATVe+5kiVncq9tl2vUpoO10vQhlPDd2INnIjIUCzAiYgMZXwTimhzEQDgxfenqrSmZSLfnLH0lL5UY9r3lMGv3PUkVPtvzvBK23q2kooTlpWeTXmts2f8vj+j3yueKLh1wZ0+6fmSih9+truK8w+Xjs7j46fLeaWN2v8HFa8bJsuNhsuL12xyqntbFQ+4UC6TkOT4ednNrbvm6Pv+/FORK59YAyciMpSRNXDnLhovz5kMIPodPR2T81R8/8tpAICGdxyI6td0oyPNvLtttp6u5eNI+vqEXEysdVnvma6BOH8ftkzUizhlDZaDP/OPRrejP9ZqDpazJTs3v1+llV2sn5jF2TVenwmWs9b92oRXVOxc1tfW6iO5PHLW+OgMcmANnIjIUCzAiYgMZVQTSuL5clmeZm9vV2mBmk7s3Uwe3HiH13sHDuqZlGkL9caw+3rI9Ze3dvK96XGd6keCzDEBhddhfqv7FK/3X/hMr12dCe7Ga3t3UhcAQO793o/mRbnmPLlmdTvHRzZf+aaKG/9Trm/deMh3Echh/LI3ES7jWGzKKuY57UXF+r/4H5Xmq9kka/FAFTd7QjZ/hTVrOQisgRMRGYoFOBGRoYxqQtn050YAgIW1PvF73L179IJBa2ZcCACoMcl7vGclrxSPbq39nv/QJ3UAAGnwvx0TSVsH1VbxFZ4VD8Yf1s0qTUbrURbRetQ0kb0V2vKJvjff9uWr6+Ra1CMnzFJp16QcU/HYa98BAExpeYNKK1hd9FrlpZFz+8QdL+qlHRa1nQQASE9K9foMANy4tRsAIGvQFpWW71w7PApYAyciMpRRNfDuHVYV+d72vJMq3j9Y/wWtsTq4mVY/P91exX1aLvV6395xBwAq7WA9MRDn4mJdO6/wen9sdmcVZx1cWSJ5Kg3KfiKv9auZTVVa893LVNwjVY7/fuS+81Ra1sOyhh9oZqjbJbSQ1yz3JV2WrG8+w3GErHnbC2EBQPvZjsWwnpXjzAuiXOt2Yg2ciMhQLMCJiAxlVBOKPy8f6KTigJ0yCXKxmZwRl6qkDwa+oGJfY8sX5Z6v4tT57h5DGwmH5upmrJfT3lfx7GNyM+NmY3XHGhukSt7WnpNU3D57CACg8qziLexkIucchZpT5ZjxafW+9nmsvTDVpR8NV2nNntuk4mh3WPrCGjgRkaFYgBMRGSrum1CcjzhdKn9a5HGfZF+s4sbQTRxJdeWY7Zwb9Xn6PbAIADCs8gTHGfxPyf/L/D4qboTS96gZLPvn9c+m81RaboEe3fCvCXJJg/M3cAu6QAoul1t05XT0Hndcf+6vKs7fst3rfaeu00epeP19E/wcWXoc7y2bTx/6x2yV5mv7tVYr+qq45oty2nzWMr0Rcayb/1gDJyIyVNzXwAsqlVdxgyT7L6T3AjLZPceq+KbGd6n4veYzAQBpib5nT/nTZpVeACvzmR91nkI+U+lRbkYuAKBTiq6btF51p4rPj9K6yG609xp5z/qqNS+9V//qDvhQr3lddb3wOvaVO1+PQu7Mc/SOdioe9Ix8QvRV6+6w5lYV1759p4oLTp2KYu7Cwxo4EZGhWIATERkq/ptQHGO6b3lzBABg/SDvR8pqCboTcslFcxzvBNd04pwee92PAwAAte7cp9Ly4/DxKV4UXHmJit/LsNdQ1xu75n1R3XH0FlDxObf423rLa/qNW4L7/Kazp1WccijPz5FmOnut3MB48AQ9B6FX+R+8jnvjaF0Vv/Oo3Py50oe6kzLem0tZAyciMlTc18CdGiyQO+H8+aZWKu25mt5/VYM165jeTHf2XV1UXGPFOgCxHyJkih036U7lMkLWvJ1DB+t87BjyVnLZMl6Def8DAIzv3UilDau8o1jntBd9u3WV7visu8h7sTETOTc7r/HsNgC+OykBYPwReU3n/flalZbiqHmbgjVwIiJDsQAnIjKUUU0odofm2sv12PB2t8qFeE7U0eNfL+2+TsVLtmV6naf2XLn+ccVsvaOOtW+d13HkX0LL5gCAid2ne73Xarne2LX+Fl7bcBSslQslfeoYv5z7tmyu+lMVPS+hYkIy/HF20PfIlpsaN7htbcTyGWsHhsi1/KeMfEWltS6b6HVc4y/vVXGzx3IAACn7zGs2cWINnIjIUCzAiYgMZVQTis25ZVHV6XJhqaqO93NG6zgTP6Io7hv9WrI2DZFNWdelnvZ6b8wlc1U8EVkllic3sptSAODrFnK+w6xn9VZedTvuUfEnTT/w+vxlXw9VceadRf8+xDvnNn1HbmqpYrvpxNlsYo+26f5vfZ2yntJbMua5ZPs41sCJiAxlZA2c4kPikaJvn6deu0fFtcAFrCIt/Vnf17QrWnml+XsKNcnheXrW5DcXO2afemb9Zn6sx7Y3/7uce9Bwt1762Ypu9mKCNXAiIkOxACciMhSbUChsWVP2AwCW9NJpP52SOyDVeWujSuP0eYqESl23qdhXU1EWVqq4tAxQYA2ciMhQrIFT2PK3yd1K/tGopY93fS8iRESRwxo4EZGhWIATERlKWJYbR0cSEbkfa+BERIZiAU5EZCgW4EREhmIBTkRkKBbgRESGYgFORGQoFuBERIZiAU5EZCgW4EREhmIBTkRkKBbgRESGYgFORGQoFuBERIZiAU5EZCgW4EREhmIBTkRkKBbgRESGYgFORGQoFuBERIZiAU5EZCgW4EREhmIBTkRkKBbgRESG+n9mhBgfEU47IAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10])\n",
      "0.9997827410697937 tensor([7, 3, 1, 0, 5, 7, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "def plot_MNIST(images,labels):\n",
    "    rows = 2\n",
    "    columns = 4\n",
    "    classes = ('0', '1', '2', '3',\n",
    "          '4', '5', '6', '7', '8', '9')\n",
    "    # plot y_score - true label (t) vs predicted label (p)\n",
    "    fig2 = plt.figure()\n",
    "    for i in range(8):\n",
    "        fig2.add_subplot(rows, columns, i+1)\n",
    "        plt.title('t: ' + classes[labels[i].cpu()])\n",
    "        img = images[i] / 2 + 0.5     # this is to unnormalize the image\n",
    "        img = torchvision.transforms.ToPILImage()(img.cpu())\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "im_batch, lab_batch=next(iter(test_loader)) # view one batch\n",
    "\n",
    "plot_MNIST(im_batch,lab_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is run inference on the images without occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions =  tensor([7, 3, 0, 0, 0, 1, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "#running inference on the images without occlusion\n",
    "\n",
    "# pretrained model\n",
    "outputs = net(im_batch)\n",
    "\n",
    "# #passing the outputs through softmax to interpret them as probability\n",
    "# outputs = nn.functional.softmax(outputs, dim = 1)\n",
    "# print(outputs)\n",
    "\n",
    "#assigning the predicted label from the maximum softmax output\n",
    "prob_no_occ, pred = torch.max(outputs.data, 1)\n",
    "\n",
    "#get the first item\n",
    "prob_no_occ = prob_no_occ[0].item()\n",
    "\n",
    "print('Predictions = ', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to be able to do is zero (or grey out) block of pixels in our image. \n",
    "\n",
    "Similar to the patch based selection that we saw in lecture 4, we are constrained to select only patches which fit in our image (which means that number of points on which we can start each patch is constrained by the width and height of our patch). This means that the output size will be smaller than the original image size by a factor of: (h-p)/s; where, h is the height (or width), p is the patch size and s is the chosen stride.\n",
    "\n",
    "Let's create an image with an occluded patch in the centre. We start by first creating a copy of our image using `image.detach().clone()`.  Here, \" `tensor.detach()` creates a tensor that shares storage with the original tensor, but for which `requires_grad=False`; `tensor.clone()` creates a copy of tensor that imitates the original tensor's `requires_grad` field. Thus `detach()` should be used to remove a tensor from a computation graph, and `clone()` copies the tensor while still keeping the copy as a part of the computation graph it came from. \" quoted from https://discuss.pytorch.org/t/clone-and-detach-in-v0-4-0/16861.\n",
    "\n",
    "#### To do 3.1 Create a function which occuldes a patch from an image\n",
    "\n",
    "1. set all pixels of patch (starting at height: `heigh_start` and width: `width_start`, and of size: `patch_size` to 0.5\n",
    "2. Pass the oculded image through the network (`model`) to make a prediction\n",
    "3. Select the softmax output corresponding to the correct label for that image and print it out; \n",
    "  - note you will need to use `nn.functional.softmax()` on the output from your network in order to turn the log(softmax) output of the network back to a probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlude_image(image, model, height_start,width_start,patch_size):\n",
    "    ''' \n",
    "    Creates a copy of the image and occludes a patch \n",
    "    input:\n",
    "    image (Pytorch tensor): image to be occluded\n",
    "    model: Pytorch network model \n",
    "    height_start=starting index on height dimension\n",
    "    width_start=starting index on width dimension\n",
    "    patch_size: size of patch\n",
    "    \n",
    "    output: \n",
    "    probability\n",
    "    '''\n",
    "    occluded_image = im_batch[0].detach().clone()\n",
    "    height_end=height_start+patch_size\n",
    "    width_end=width_start+patch_size\n",
    "    occluded_image[:,height_start:height_end,width_start:width_end]=0.5\n",
    "    \n",
    "    output_occluded=net(occluded_image.unsqueeze(0))\n",
    "    occluded_prob=nn.functional.softmax(output_occluded, dim=1)[0,true_label]\n",
    "\n",
    "    \n",
    "    return occluded_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do 3.2 Compare  against prediction probability when the full image is used\n",
    "\n",
    "1. Get prediction probability when the full image is used and compare\n",
    "2. Compare against probability for different patch locations and sizes; plot the occluded and original image to help you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "True label=7; prediction probability for full image0.9995181560516357; prediction probability for occluded 0.2916991412639618\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_label=lab_batch[0].numpy()\n",
    "\n",
    "print(true_label)\n",
    "patch_size=20\n",
    "height_start=8\n",
    "width_start=8\n",
    "\n",
    "#--------------- Task 3.2.1 Estimate output of network for first image of the batch -----------------#\n",
    "# use nn.functional.softmax to return a probabiliyt\n",
    "output_full=net(im_batch[0].unsqueeze(0))\n",
    "full_prob=nn.functional.softmax(output_full,dim=1)[0,true_label]\n",
    "#--------------- Task 3.2.2 Estimate output of network for an occluded version of the same image -----------------#\n",
    "# use function defined above\n",
    "occluded_prob=occlude_image(image, net, height_start,width_start,patch_size)\n",
    "\n",
    "\n",
    "print('True label={}; prediction probability for full image{}; prediction probability for occluded {}'\n",
    "      .format(true_label,full_prob, occluded_prob))\n",
    "\n",
    "# plot\n",
    "fig2 = plt.figure(figsize=(15,5))\n",
    "fig2.add_subplot(1, 2, 1)\n",
    "#displaying the image using seaborn heatmap and also setting the maximum value of gradient to probability\n",
    "img = torchvision.transforms.ToPILImage()(occluded_image[0].cpu())\n",
    "plt.imshow(img)\n",
    "fig2.add_subplot(1, 2, 2)\n",
    "img = torchvision.transforms.ToPILImage()(im_batch[0].cpu())\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate, creating patches across our entire image in order to create a heatmap which shows how big an impact a patch, centred on each pixel centre has.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to conduct occlusion experiments\n",
    "\n",
    "def occlusion(model, image, label, occ_size = 50, occ_stride = 50, occ_pixel = 0.5):\n",
    "    print(image.shape,label)\n",
    "    #get the width and height of the image\n",
    "    width, height = image.shape[-2], image.shape[-1]\n",
    "  \n",
    "    #setting the output image width and height\n",
    "    output_height = int(np.ceil((height-occ_size)/occ_stride))\n",
    "    output_width = int(np.ceil((width-occ_size)/occ_stride))\n",
    "    #create a white image of sizes we defined\n",
    "    heatmap = torch.zeros((output_height, output_width))\n",
    "    \n",
    "    #iterate all the pixels in each column\n",
    "    for h in range(0, height):\n",
    "        for w in range(0, width):\n",
    "            \n",
    "            h_start = h*occ_stride\n",
    "            w_start = w*occ_stride \n",
    "            h_end = min(height, h_start + occ_size)\n",
    "            w_end = min(width, w_start + occ_size)\n",
    "            \n",
    "            if (w_end) >= width or (h_end) >= height:\n",
    "                continue\n",
    "            \n",
    "            occluded_image = image.detach().clone()\n",
    "            print(type(input_image),input_image.shape)\n",
    "            \n",
    "            #replacing all the pixel information in the image with occ_pixel(grey) in the specified location\n",
    "            occluded_image[:, :, w_start:w_end, h_start:h_end] = occ_pixel\n",
    "            \n",
    "            #run inference on modified image\n",
    "            output = model(occluded_image)\n",
    "            \n",
    "            # get the softmax output corresponding to the true label\n",
    "            prob = output.tolist()[0][label]\n",
    "            \n",
    "            #setting the heatmap location to probability value\n",
    "            heatmap[h, w] = prob \n",
    "\n",
    "    return heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) <built-in method type of Tensor object at 0x1241990d8>\n",
      "torch.Size([1, 1, 28, 28]) 7\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(pred[0],pred[0].type)\n",
    "image=im_batch[0].unsqueeze(0)\n",
    "heatmap = occlusion(net, image, lab_batch[0].item(),13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig2 = plt.figure(figsize=(15,5))\n",
    "fig2.add_subplot(1, 2, 1)\n",
    "#displaying the image using seaborn heatmap and also setting the maximum value of gradient to probability\n",
    "imgplot = sns.heatmap(heatmap, xticklabels=False, yticklabels=False, vmax=prob_no_occ)\n",
    "figure = imgplot.get_figure()    \n",
    "fig2.add_subplot(1, 2, 2)\n",
    "img = torchvision.transforms.ToPILImage()(image[0].cpu())\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "The web journal [Distill.pub](https://distill.pub/) is a particularly strong source of information for those interested in network visualisation. In partiocular [this article](https://distill.pub/2017/feature-visualization/) by Chris Olah has been a strong source of information for this section.\n",
    "\n",
    "### 3. CNN Layer Visualization\n",
    "\n",
    "We will go through the next examples using code from the following repository https://github.com/utkuozbulak/pytorch-cnn-visualizations, which implements several well known visualization techniques for deep learning networks.\n",
    "\n",
    "**CNN layer visualization** technique produces an image that minimizes the loss of a convolutional operation for a specific layer and filter - i.e. it learns the image that optimally activates a particular convolutional filter.\n",
    "\n",
    "D. Erhan, Y. Bengio, A. Courville, P. Vincent. Visualizing Higher-Layer Features of a Deep Network https://www.researchgate.net/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network\n",
    "\n",
    "**All the visualizations will be saved to** `/generated` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vgg model, and extract layers from the features modules only\n",
    "pretrained_model = models.vgg16(pretrained=True).features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss: 1.02\n",
      "Iteration: 2 Loss: 0.52\n",
      "Iteration: 3 Loss: -3.88\n",
      "Iteration: 4 Loss: -7.38\n",
      "Iteration: 5 Loss: -10.92\n",
      "Iteration: 6 Loss: -14.28\n",
      "Iteration: 7 Loss: -17.43\n",
      "Iteration: 8 Loss: -20.43\n",
      "Iteration: 9 Loss: -23.33\n",
      "Iteration: 10 Loss: -26.16\n",
      "Iteration: 11 Loss: -28.94\n",
      "Iteration: 12 Loss: -31.62\n",
      "Iteration: 13 Loss: -34.28\n",
      "Iteration: 14 Loss: -36.90\n",
      "Iteration: 15 Loss: -39.48\n",
      "Iteration: 16 Loss: -42.07\n",
      "Iteration: 17 Loss: -44.63\n",
      "Iteration: 18 Loss: -47.18\n",
      "Iteration: 19 Loss: -49.74\n",
      "Iteration: 20 Loss: -52.29\n",
      "Iteration: 21 Loss: -54.80\n",
      "Iteration: 22 Loss: -57.32\n",
      "Iteration: 23 Loss: -59.84\n",
      "Iteration: 24 Loss: -62.33\n",
      "Iteration: 25 Loss: -64.86\n",
      "Iteration: 26 Loss: -67.42\n",
      "Iteration: 27 Loss: -70.02\n",
      "Iteration: 28 Loss: -72.58\n",
      "Iteration: 29 Loss: -75.17\n",
      "Iteration: 30 Loss: -77.76\n"
     ]
    }
   ],
   "source": [
    "cnn_layer = 21\n",
    "filter_pos = 5\n",
    "# Fully connected layer is not needed\n",
    "layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)\n",
    "\n",
    "# Layer visualization with pytorch hooks\n",
    "layer_vis.visualise_layer_with_hooks()\n",
    "\n",
    "# Layer visualization without pytorch hooks\n",
    "#layer_vis.visualise_layer_without_hooks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Visualize different CNN layers and filters\n",
    "Change the CNN layer and filter to visualize the network at different depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------- Task 3 --------------------------------------------------------\n",
    "# write code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deep Dream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 34 is out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-2378481f0aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fully connected layer is not needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepDream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# This operation can also be done without Pytorch hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# See layer visualisation for the implementation without hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/TEACHING/LECTURES/AdvancedML/code/pytorch_tutorials/visualizations/src/deep_dream.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, selected_layer, selected_filter, im_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Hook the layers to get result of the convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Create the folder to export images if not exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./generated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/TEACHING/LECTURES/AdvancedML/code/pytorch_tutorials/visualizations/src/deep_dream.py\u001b[0m in \u001b[0;36mhook_layer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Hook the selected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m_get_item_by_idx\u001b[0;34m(self, iterator, idx)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index {} is out of range'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m%=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 34 is out of range"
     ]
    }
   ],
   "source": [
    "# THIS OPERATION IS MEMORY HUNGRY! #\n",
    "# Because of the selected image is very large\n",
    "# If it gives out of memory error or locks the computer\n",
    "# Try it with a smaller image\n",
    "cnn_layer = 34\n",
    "filter_pos = 94\n",
    "\n",
    "im_path = './visualizations/input_images/dd_tree.jpg'\n",
    "# Fully connected layer is not needed\n",
    "\n",
    "dd = DeepDream(pretrained_model, cnn_layer, filter_pos, im_path)\n",
    "# This operation can also be done without Pytorch hooks\n",
    "# See layer visualisation for the implementation without hooks\n",
    "dd.dream()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient visualization with Guided backpropagation\n",
    "\n",
    "In order to visualise what is learnt by neurons in higher layers, a deconvolutional approach was developed, which inverts the data flow of a CNN, going from a neuron of interest to an image. The resulting image is the one which most strongly activates this neuron.\n",
    "\n",
    "![guided_backprop](guided_backprop.png)\n",
    "\n",
    "Details of the backprop method is in the following reference:\n",
    "\n",
    "Springenberg, Jost Tobias, et al. \"Striving for simplicity: The all convolutional net.\" arXiv preprint arXiv:1412.6806 (2014)-\n",
    "https://arxiv.org/pdf/1412.6806.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the implementation of guided backpropagation in `/visualizations/src/guided_backprop.py`.\n",
    "\n",
    "First get input image, class label, and pretrained model (pretrained alexnet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_example = 0  \n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you create an instance of the guidedbackprop class using `GuidedBackprop(pretrained_model)`. \n",
    "This operation creates hooks on the model, which updates relu activation functions so that:\n",
    "1. it stores the output of the forward pass\n",
    "2. it imputes zero for gradient values that are less than zero, i.e. all gradients are clamped to zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------- Guided backprop---------------------------------------------------\n",
    "# Guided backprop\n",
    "GBP = GuidedBackprop(pretrained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then you can generate gradients that are specific to a particular input image, and class using the method `GP.generate_gradients()` with the following steps:\n",
    " 1. go through a forward pass with the image input, and generate an output\n",
    " 2. backprop through the output\n",
    " 3. get the gradients from the backprop\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gradients\n",
    "guided_grads = GBP.generate_gradients(prep_img, target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can save the gradients using the following plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided backprop completed\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------- Save images-------------------------------------------------------\n",
    "# Save colored gradients\n",
    "save_gradient_images(guided_grads, file_name_to_export + '_Guided_BP_color')\n",
    "# Convert to grayscale\n",
    "grayscale_guided_grads = convert_to_grayscale(guided_grads)\n",
    "# Save grayscale gradients\n",
    "save_gradient_images(grayscale_guided_grads, file_name_to_export + '_Guided_BP_gray')\n",
    "# Positive and negative saliency maps\n",
    "pos_sal, neg_sal = get_positive_negative_saliency(guided_grads)\n",
    "save_gradient_images(pos_sal, file_name_to_export + '_pos_sal')\n",
    "save_gradient_images(neg_sal, file_name_to_export + '_neg_sal')\n",
    "print('Guided backprop completed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Run guided backprop for different inputs, and classes\n",
    "You can do this by changing `target_example=` (there's 3 inputs available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------- Task 4 --------------------------------------------------------\n",
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradient Class Activation Mapping (grad-CAM)\n",
    "\n",
    "\n",
    "R. R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, and D. Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, https://arxiv.org/abs/1610.02391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad cam completed\n"
     ]
    }
   ],
   "source": [
    "# Get params\n",
    "target_example = 1\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n",
    "\n",
    "# Grad cam\n",
    "grad_cam = GradCam(pretrained_model, target_layer=11)\n",
    "# Generate cam mask\n",
    "cam = grad_cam.generate_cam(prep_img, target_class)\n",
    "# Save mask\n",
    "save_class_activation_images(original_image, cam, file_name_to_export)\n",
    "print('Grad cam completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
